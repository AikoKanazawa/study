{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(0.3752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(3.8239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(0.4493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.4379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.2908, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.4241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.3554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.2687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.2223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.2109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.1908, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.1741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.1652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.1547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.1433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.1318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.1190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.1210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.1179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.1139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.1080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.0892, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.0634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.0624, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-5, 15)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch regression', marker=\"o\", markersize=3)\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 20, 'Training Error=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 100)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.sin(2 * np.pi * 0.1 * x)  # 正弦波を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 60)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(60), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(0.9276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(5.4727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(1.8996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.6519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.6538, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.4629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.4130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.3921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.3809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.3720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.3633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.3606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.3579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.3468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.3408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.3378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.3335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.3353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.3212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.3163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.3139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.3082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.3097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.2978, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.2935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.2892, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.2849, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.2806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.2767, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.2743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.2774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.2674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.2647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.2632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.2669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.2570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.2541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.2518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.2496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.2460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.2449, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.2421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.2412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.2347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.2273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.2262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.2211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.2102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.2066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.2019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.2019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.2010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.2027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.2021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.2058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.2128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.2132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.2039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.2022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.1933, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.1887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.1866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.1842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.1835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.1801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.1785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.1777, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.1763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.1762, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.1747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.1748, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.1735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.1752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.1740, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.1788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.1773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.1841, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.1875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.1805, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.1829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.1736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.1733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.1657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.1649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.1598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.1589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.1557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.1561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.1527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.1505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.1515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.1490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.1504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.1480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.1498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.1476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.1499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.1475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.1501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.1497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.1481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.1360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.1313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.1245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.1219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.1247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.1207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.1247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.1204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.1193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.1177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.0939, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.0834, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.0845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.0803, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.0705, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.0634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.0624, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.1715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.1386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.3184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.2413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.1452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.1357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.1191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0431, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-5, 15)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch regression', marker=\"o\", markersize=3)\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 20, 'Training Error=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(-5, 15, 100)                                  # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.sin(2 * np.pi * 0.1 * x)  # 正弦波を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 60)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(60), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(25649946., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(25610884., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(25517054., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(25350250., grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(25107748., grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(24793980., grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(24419244., grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(23984802., grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(23511114., grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(22995888., grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(22462156., grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(21904760., grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(21343600., grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(20782970., grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(20230050., grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(19691122., grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(19173242., grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(18680076., grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(18218422., grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(17787654., grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(17388994., grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(17024894., grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(16698642., grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(16409864., grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(16151675., grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(15924084., grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(15723300., grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(15550120., grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(15403233., grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(15275835., grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(15164097., grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(15067975., grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(14983353., grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(14908724., grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(14848721., grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(14789782., grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(14736368., grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(14686094., grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(14643015., grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(14599694., grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(14560560., grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(14522001., grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(14485469., grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(14449505., grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(14414637., grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(14381664., grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(14347511., grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(14315729., grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(14285011., grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(14252927., grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(14222366., grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(14193107., grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(14162981., grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(14133166., grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(14104895., grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(14076767., grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(14048270., grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(14020043., grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(13992573., grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(13965573., grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(13938586., grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(13911944., grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(13885740., grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(13859519., grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(13833436., grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(13807791., grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(13782235., grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(13757259., grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(13732349., grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(13707534., grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(13682909., grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(13658374., grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(13634238., grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(13610083., grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(13586068., grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(13562249., grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(13538593., grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(13515043., grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(13491702., grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(13468424., grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(13445281., grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(13422181., grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(13399234., grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(13376408., grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(13353711., grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(13331054., grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(13308495., grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(13286035., grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(13263660., grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(13241362., grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(13219138., grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(13196987., grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(13174899., grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(13152873., grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(13130908., grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(13108984., grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(13087114., grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(13065290., grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(13043499., grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(13021749., grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(13000032., grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(12978345., grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(12956687., grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(12935056., grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(12913447., grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(12891859., grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(12870289., grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(12848731., grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(12827186., grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(12805652., grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(12784122., grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(12762599., grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(12741079., grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(12719564., grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(12698045., grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(12676522., grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(12654990., grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(12633448., grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(12611893., grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(12590316., grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(12568715., grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(12547092., grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(12525440., grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(12503762., grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(12482054., grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(12460313., grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(12438532., grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(12416710., grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(12394849., grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(12372942., grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(12350992., grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(12328994., grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(12306947., grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(12284847., grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(12262694., grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(12240487., grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(12218228., grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(12195911., grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(12173541., grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(12151112., grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(12128629., grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(12106086., grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(12083481., grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(12060815., grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(12038089., grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(12015293., grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(11992430., grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(11969495., grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(11946483., grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(11923397., grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(11900230., grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(11876985., grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(11853658., grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(11830252., grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(11806761., grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(11783191., grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(11759538., grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(11735805., grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(11711990., grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(11688093., grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(11664113., grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(11640052., grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(11615911., grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(11591688., grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(11567384., grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(11542999., grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(11518537., grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(11493997., grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(11469380., grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(11444683., grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(11419904., grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(11395039., grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(11370095., grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(11345069., grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(11319966., grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(11294779., grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(11269512., grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(11244155., grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(11218712., grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(11193181., grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(11167568., grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(11141870., grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(11116084., grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(11090218., grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(11064266., grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(11038234., grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(11012119., grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(10985922., grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(10959643., grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(10933283., grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(10906835., grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(10880301., grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(10853679., grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(10826965., grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(10800161., grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(10773265., grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(10746284., grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(10719215., grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(10692057., grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(10664815., grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(10637489., grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(10610080., grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(10582594., grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(10555027., grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(10527390., grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(10499680., grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(10471899., grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(10444047., grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(10416125., grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(10388130., grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(10360058., grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(10331912., grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(10303691., grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(10275394., grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(10247018., grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(10218565., grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(10190035., grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(10161427., grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(10132747., grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(10104001., grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(10075189., grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(10046325., grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(10017411., grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(9988456., grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(9959458., grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(9930417., grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(9901339., grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(9872221., grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(9843070., grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(9813885., grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(9784672., grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(9755440., grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(9726191., grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(9696928., grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(9667658., grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(9638381., grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(9609095., grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(9579807., grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(9550516., grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(9521227., grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(9491925., grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(9462612., grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(9433287., grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(9403948., grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(9374589., grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(9345202., grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(9315793., grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(9286362., grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(9256913., grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(9227441., grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(9197945., grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(9168432., grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(9138901., grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(9109353., grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(9079785., grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(9050204., grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(9020615., grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(8991020., grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(8961418., grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(8931815., grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(8902217., grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(8872627., grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(8843049., grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(8813482., grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(8783937., grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(8754407., grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(8724900., grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(8695413., grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(8665954., grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(8636528., grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(8607146., grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(8577865., grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(8548794., grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(8520269., grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(8493133., grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(8468848., grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(8447906., grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(8424909., grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(8395470., grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(8361867.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(8327543.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(8295088.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(8263963.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(8234030.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(8204714.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(8175853., grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(8147238.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(8118827., grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(8090533.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(8062345., grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(8034217., grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(8006180., grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(7978211., grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(7950330.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(7922518., grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(7894784., grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(7867114., grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(7839504.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(7811962.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(7784542., grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(7757257.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(7730161., grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(7703309., grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(7676849., grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(7650965.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(7625978.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(7602067.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(7579414.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(7556906., grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(7533738., grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(7507467.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(7479495.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(7449197., grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(7419603., grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(7390039.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(7361689., grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(7333875.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(7306756., grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(7280008., grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(7253633.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(7227443., grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(7201457., grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(7175594.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(7149874.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(7124229., grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(7098706., grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(7073268., grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(7047939.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(7022683.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(6997584., grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(6972608., grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(6947859., grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(6923344.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(6899238.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(6875579.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(6852574.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(6830035., grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(6808307.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(6786245., grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(6764626., grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(6741354., grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(6717551.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(6691986., grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(6665927.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(6639161.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(6612931., grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(6586623.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(6561164., grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(6535640.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(6510806.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(6486130.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(6461785.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(6437677., grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(6413773., grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(6390003., grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(6366472., grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(6343081.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(6319893.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(6296826.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(6274079., grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(6251400., grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(6229136., grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(6207092., grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(6185553.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(6164146., grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(6143316.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(6122635., grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(6102494., grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(6082010.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(6061531.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(6039881.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(6018083.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(5995090.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(5972296., grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(5948627.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(5925595., grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(5902312., grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(5879605., grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(5856893.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(5834846., grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(5812924.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(5791463., grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(5770067., grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(5749104., grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(5728224.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(5707688., grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(5687399.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(5667350., grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(5647513.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(5628032.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(5608507.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(5589593.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(5570688., grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(5552298.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(5533948.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(5516214.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(5498563.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(5481169., grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(5463804., grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(5446702.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(5428839., grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(5411122.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(5392380.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(5373958.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(5354276., grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(5335590.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(5315849.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(5297158.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(5277807.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(5259444., grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(5240795., grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(5222913., grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(5205106.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(5187694., grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(5170575., grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(5153790.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(5137060.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(5120741.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(5104393.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(5088627.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(5072668.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(5057252., grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(5041621., grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(5026594.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(5011522.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(4996977.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(4982096., grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(4967963., grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(4953712.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(4939970.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(4925902.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(4912453., grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(4898389.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(4885021.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(4870318.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(4856402.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(4841485.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(4827399., grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(4812251., grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(4797893.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(4782645., grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(4768174., grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(4753222.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(4739082., grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(4724556.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(4710692., grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(4696713., grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(4683354., grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(4669892., grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(4656835.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(4643706., grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(4630992.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(4618111., grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(4605747.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(4593178.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(4581340., grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(4568850.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(4557209., grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(4544576., grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(4532939., grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(4520604.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(4508979.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(4496893.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(4485558., grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(4473611., grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(4462548., grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(4451457., grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(4440461., grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(4429377., grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(4418614.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(4407792., grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(4397419., grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(4386448.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(4376321.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(4364514.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(4354074., grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(4342334.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(4331995.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(4320622.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(4310285.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(4298701., grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(4288019.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(4276269.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(4265678., grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(4254365., grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(4243821.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(4232264., grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(4221482., grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(4210359.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(4200005.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(4189458.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(4179610.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(4169716.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(4159961.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(4150535.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(4141379.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(4132645.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(4124086.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(4116070.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(4108033., grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(4101275.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(4093909., grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(4087254.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(4080263.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(4072867.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(4065851.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(4056619., grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(4048682.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(4038321.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(4029258.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(4017571.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(4007419., grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(3995437., grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(3985595.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(3973945.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(3964711.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(3954115., grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(3944862.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(3934996.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(3925843.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(3916281.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(3907464.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(3898210.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(3890067.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(3881344.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(3873215.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(3864969.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(3857064.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(3849201.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(3841359.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(3833705.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(3826021., grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(3818899.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(3812185., grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(3806018.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(3800254., grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(3796010.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(3792426.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(3791382., grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(3791221.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(3793728.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(3796418.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(3797503.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(3796850., grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(3789252.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(3781284.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(3766439.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(3754316.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(3738040.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(3726688.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(3713031.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(3703511.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(3692478.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(3684348.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(3675120.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(3667811.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(3659863., grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(3653322., grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(3646243., grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(3639913.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(3633462.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(3627553.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(3621253.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(3615377.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(3609581.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(3603649., grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(3597732.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(3592107.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(3586409.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(3581000.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(3575471., grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(3570225.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(3564883.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(3559583., grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(3554180., grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(3549085.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(3544080.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(3539280.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(3534688.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(3530610.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(3527188.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(3524518.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(3522644., grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(3522027., grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(3522308., grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(3524231., grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(3525946., grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(3530091.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(3530064.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(3531511., grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(3526847.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(3521627.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(3509696., grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(3500367., grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(3486510.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(3476103.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(3464244.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(3454983.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(3446232.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(3438550., grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(3431484., grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(3424920.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(3419405.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(3413611.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(3408548., grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(3403639.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(3398603., grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(3393874.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(3389135.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(3384609.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(3380326., grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(3375911., grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(3371746.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(3367736., grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(3364037.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(3360513.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(3357491.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(3354923., grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(3352796., grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(3351667.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(3351256.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(3351621., grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(3351943.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(3354281.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(3355447.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(3359296., grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(3359928., grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(3360790., grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(3354379., grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(3349975.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(3340051., grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(3333148.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(3322485.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(3314235.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(3305899.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(3298691.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(3291313.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(3285211., grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(3278482., grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(3273005., grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(3267308.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(3262239., grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(3257331.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(3253196.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(3248795.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(3244737.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(3240855., grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(3237541., grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(3233648.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(3230473.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(3226560.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(3223519.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(3220112.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(3217528.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(3214538.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(3212371., grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(3209523.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(3207938.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(3206199.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(3205535.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(3204461., grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(3204919.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(3205287.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(3206134., grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(3206988.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(3207983., grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(3207077., grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(3206601., grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(3203293.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(3200052.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(3192718.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(3186663., grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(3178429.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(3171823., grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(3164392., grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(3158634.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(3151843.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(3146072., grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(3140220.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(3135730.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(3130688.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(3126339.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(3122005.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(3118006.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(3114275., grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(3111156.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(3107810., grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(3105035.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(3102089., grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(3099243.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(3096648.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(3094461.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(3091515., grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(3089643.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(3086808.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(3085287.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(3082731., grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(3081541., grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(3078459.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(3077740.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(3075364.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(3075113.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(3073035.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(3073270.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(3072001., grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(3072911.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(3069110., grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(3069654.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(3064941., grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(3064275.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(3058772.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(3057546., grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(3051822., grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(3050051.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(3044182., grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(3041721.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(3035984.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(3033338.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(3028514.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(3025463.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(3020666.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(3017699., grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(3012915.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(3009585.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(3005216.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(3002059.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(2997840.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(2994956., grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(2991625.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(2989173.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(2986153.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(2984068.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(2981514., grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(2979786.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(2978407., grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(2977177.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(2976056.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(2975726.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(2974836.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(2974899.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(2974558.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(2975138.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(2974453.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(2973704.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(2969651.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(2968967.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(2964220.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(2962570., grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(2957806., grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(2955238.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(2948679.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(2944467., grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(2939503.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(2935953., grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(2931872.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(2928529., grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(2925539.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(2922924.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(2919928.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(2917446., grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(2914082.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(2911509.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(2908267.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(2906332.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(2902100.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(2900848.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(2896151.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(2895353.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(2890166.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(2888850.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(2883145.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(2882216.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(2877004.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(2875251.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(2871315.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(2868673.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(2865467.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(2862768.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(2860166.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(2857563.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(2856042.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(2854481.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(2852994.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(2851993.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(2850933.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(2850678., grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(2850395.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(2850776., grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(2850990., grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(2852565.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(2853160., grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(2855570., grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(2857930.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(2860248.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(2859933., grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(2860504.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(2857739.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(2856877.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(2850639.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(2846647.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(2839225.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(2835374.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(2828051., grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(2822737., grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(2816428.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(2812458.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(2807404.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(2804340.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(2800005.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(2796750., grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(2793461.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(2791474.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(2788137., grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(2785839.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(2782318.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(2780289., grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(2777261.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(2774860.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(2772857.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(2770745.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(2769139.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(2767855.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(2766590.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(2765835.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(2765043., grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(2764721.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(2764445.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(2764834.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(2764760., grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(2765710.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(2766373.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(2766832.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(2768002.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(2769239., grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(2770505.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(2772153.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(2774275., grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(2775721., grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(2777432.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(2777087.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(2778587.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(2775814.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(2773063.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(2768167., grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(2763758.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(2757265.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(2752817.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(2746724.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(2742759.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(2735439.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(2732009.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(2726255.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(2723087.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(2718325.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(2715096.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(2710818.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(2708821.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(2706049., grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(2705166.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(2703051.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(2702813.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(2701226.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(2701667.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(2700228., grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(2700648.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(2699950.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(2700890.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(2701328.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(2704375.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(2705484.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(2706479., grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(2707859.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(2708063.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(2709516., grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(2708025.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(2707676.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(2704010.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(2703075.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(2698560., grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(2697354.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(2692484.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(2692026.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(2686964., grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(2686757., grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(2681703.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(2680319.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(2675769.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(2674789.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(2670178.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(2669838.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(2665644., grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(2664960., grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(2661248.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(2661392.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(2657944.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(2658771., grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(2655069.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(2656358.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(2652925.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(2654339.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(2650840.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(2652762.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(2648869.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(2651311., grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(2647414.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(2650039.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(2645939.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(2649035., grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(2643616.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(2646419., grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(2640907.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(2644116., grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(2638468., grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(2642083.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(2636243.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(2640558.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(2634445., grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(2636882.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(2630818.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(2633069.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(2627132.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(2629765., grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(2623953.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(2624185.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(2619605.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(2619266., grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(2614787.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(2613273.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(2609560.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(2608307.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(2605196.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(2603701.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(2601317.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(2600387., grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(2598326., grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(2597632.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(2595860., grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(2595429.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(2593944.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(2594129.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(2592995.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(2593525.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(2593346.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(2594510.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(2595036.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(2598480.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(2601382.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(2611809.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(2621340.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(2646001.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(2646788.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(2674762.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(2663148.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(2680749., grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(2654831.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(2660414.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(2628617., grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(2628231.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(2601749., grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(2594703.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(2582798.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(2576453., grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(2570345.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(2565489.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(2561150., grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(2558536.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(2556103.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(2554362.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(2552768., grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(2551413.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(2550118., grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(2548835.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(2547478., grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(2546226.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(2545044., grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(2543863., grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(2542698.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(2541607.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(2540542.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(2539478.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(2538417.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(2537351.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(2536273.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(2535203.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(2534137., grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(2533061., grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(2531996.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(2530934.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(2529876., grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(2528820.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(2527772.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(2526732.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(2525705.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(2524760.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(2523881.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(2523092.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(2522367.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(2521755.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(2521390.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(2521411., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(2523265.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(2525588.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(2532884.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(2545332.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(2564435., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(2601126.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(2624725.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(2703167.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(2680741.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(2731882.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(2654360.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(2661693.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(2584121.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(2568445.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(2540974., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(2531461.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(2521622.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(2516166.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(2512380.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(2509803.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(2507498.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(2506044., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(2504629.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(2503643.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(2502568.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(2501491., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(2500680.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(2499815.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(2498858.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(2498109., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(2497125.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(2496465.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(2495728.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(2495167., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(2494668.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(2494234., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(2494006.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(2493760.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(2493470.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(2493440.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(2493404.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(2494153.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(2495266., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(2496708.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(2498182.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(2500982.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(2502336.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(2506574.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(2508803.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(2515287.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(2521821.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(2529347., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(2529962.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(2536592.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(2529816., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(2533770., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(2524311.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(2527443.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(2517028.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(2518538.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(2511941.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(2511756.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(2505838., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(2505258.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(2500544.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(2499903., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(2495553.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(2494992.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(2491093.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(2491353.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(2487175., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(2486991.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(2483255.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(2483492., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(2480234., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(2480915.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(2477997.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(2479086.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(2476868., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(2478357.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(2476007.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(2478442.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(2476106.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(2478970.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(2476981.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(2480257., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(2478101., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(2481563., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(2479139.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(2482857., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(2480668.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(2483780., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(2479633.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(2483130.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(2478664.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(2480746., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(2476287., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(2478340., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(2475275.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(2476007.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(2473073.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(2473108.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(2469914.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(2470066.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(2467254.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(2467524.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(2465061.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(2465551.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(2463381., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(2464480.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(2462502.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(2463856.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(2462554.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(2464124.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(2460935.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(2462663.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(2459679.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(2462357., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(2459022., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(2462415.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(2459082.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(2462667.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(2459518.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(2461571.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(2458491.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(2460594., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(2456132.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(2458311.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(2454125.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(2455598.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(2451797., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(2452578., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(2450116.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(2451075.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(2448040., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(2449190.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(2446493.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(2447423.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(2444520.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(2445639., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(2443089.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(2444425., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(2442179.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(2443764.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(2441783.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(2443626., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(2440331.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(2442322.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(2439112.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(2439855.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(2437089.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(2437913., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(2435553.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(2436498.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(2434529.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(2434757.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(2433176.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(2433528.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(2431044.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(2431928.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(2429866.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(2430852.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(2428775.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(2429870., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(2428422.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(2429766., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(2428780.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(2430530., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(2430451.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(2432927.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(2432765.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(2435691.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(2435830.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(2439172.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(2440995.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(2444722.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(2445257.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(2450217.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(2449935.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(2456065.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(2454028.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(2459262., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(2456535., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(2459934.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(2454568.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(2455930.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(2448857.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(2445213.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(2438589.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(2435167., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(2428011.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(2424301.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(2419439.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(2415137.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(2412791., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(2409143., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(2407301.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(2405111.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(2403957.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(2401878.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(2401249., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(2400187., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(2399807.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(2398726.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(2398513.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(2397962., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(2397921., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(2397819., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(2398814.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(2399948.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(2401606., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(2403245., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(2405478., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(2409415.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(2411089.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(2415549.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(2418696.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(2424294., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(2427379.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(2433835.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(2435721.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(2443852.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(2440154.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(2446307., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(2440358.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(2441949.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(2433432., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(2432359., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(2422851.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(2419737.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(2413479.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(2410581.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(2404886.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(2402742.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(2398547.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(2397202.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(2394035., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(2391774.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(2389547.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(2387408.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(2386126., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(2384491.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(2383910., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(2383397., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(2383181., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(2383189.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(2383318.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(2383745.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(2384210., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(2383407.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(2384194., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(2383851., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(2384984., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(2385239.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(2387064., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(2388690., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(2391360.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(2394579., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(2398058., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(2401906., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(2403170.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(2408094.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(2400140.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(2403368., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(2395722., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(2397900.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(2392132.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(2394346., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(2388480.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(2390733.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(2384256.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(2385245.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(2380788.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(2381595., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(2377566.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(2376741.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(2373376.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(2372573.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(2369365., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(2369777., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(2367059.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(2367601.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(2365331.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(2366036.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(2364175.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(2366536.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(2365070.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(2366434.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(2365368.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(2367125.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(2366492.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(2368736., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(2368536.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(2371378.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(2371544.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(2373141.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(2371648.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(2373263.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(2371763., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(2372963.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(2371402., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(2372450., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(2370793., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(2371620.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(2369846.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(2370129.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(2368544.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(2368495., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(2367465.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(2367225.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(2364378.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(2363817.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(2361089.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(2360774.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(2360170.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(2359862., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(2357418., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(2358331.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(2356053., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(2356956.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(2354442.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(2355318.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(2353014.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(2353081., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(2351032.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(2351436., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(2349628., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(2350119., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(2348555.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(2349178., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(2347860.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(2348640.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(2346498.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(2347333.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(2345479.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(2344430.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(2342850.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(2343452.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(2342152.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(2343152.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(2342276.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(2343646.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(2343044.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(2344379.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(2342217.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(2343767., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(2340966., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(2345502.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(2345341., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(2347616.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(2347038.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(2349396., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(2348987.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(2351495.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(2350503.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(2352370.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(2350656., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(2353330.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(2350732., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(2352034.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(2348621.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(2349218.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(2345239., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(2345197., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(2340962.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(2342526.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(2338470.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(2339953., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(2336140.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(2336618.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(2332842.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(2334247., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(2330717.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(2332222.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(2328731.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(2329908.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(2326533.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(2327894.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(2324649.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(2326239.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(2323121.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(2324980.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(2321981.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(2324145.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(2321247., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(2322629., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(2319863.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(2321544.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(2318900.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(2320928.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(2318790., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(2320947.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(2318774.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(2321355.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(2319223.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(2322194.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(2319519.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(2322819.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(2320113.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(2324591.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(2321310., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(2326611., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(2323606., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(2329196.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(2325568.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(2331324.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(2328770.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(2336228.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(2332242.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(2338894.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(2332655.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(2337659.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(2329995., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(2333084.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(2325412., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(2325497.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(2318532.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(2319157., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(2312712.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(2310231.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(2305298.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(2303492.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(2298072.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(2297423.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(2293359.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(2293224.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(2289935.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(2290165., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(2287995., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(2288631.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(2286727.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(2287402.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(2285573.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(2286540.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(2285155.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(2286265.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(2286153., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(2287986.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(2288063., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(2290619.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(2290404.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(2293987.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(2294525., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(2299721.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(2301387., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(2309779.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(2311637.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(2324736.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(2319672.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(2333949.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(2326324.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(2338785.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(2327045.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(2336904.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(2323103., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(2329447.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(2314920., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(2319265.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(2305874., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(2307657.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(2295682.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(2297127.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(2287371.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(2287510.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(2282579.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(2282932.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(2278941.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(2279604., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(2276571.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(2277668.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(2275145.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(2276567.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(2274334., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(2276129.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(2274176.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(2276436.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(2274824.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(2277946., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(2276789.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(2280221.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(2278271., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(2282511.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(2280609.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(2287592.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(2284009.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(2292935.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(2287373.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(2297138.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(2289739.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(2302035.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(2294128.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(2306854.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(2298196., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(2310732.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(2300542.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(2312142.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(2300235.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(2310516.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(2297178., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(2305855.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(2292173., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(2298439.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(2285150.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(2288607., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(2276937., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(2276449.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(2267749.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(2267130.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(2260906.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(2260823.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(2259470.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(2259607., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(2258578.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(2258947.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(2259297.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(2260153., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(2258413.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(2259444.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(2258137., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(2259447.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(2258653.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(2261034.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(2260978.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(2265868.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(2264946.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(2271371., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(2271671.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(2280213.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(2278745.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(2288354.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(2285720., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(2296307.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(2292994., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(2303729.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(2302998., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(2312213., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(2307903.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(2313820.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(2305531.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(2307540., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(2297331.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(2297322.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(2282654., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(2281661.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(2268796., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(2267837.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(2258581.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(2258687.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(2253254.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(2252250.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(2249181.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(2248383., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(2246335., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(2245507.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(2243662.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(2243012.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(2241650., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(2240513.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(2239361., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(2238547.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(2237682.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(2237111.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(2236458.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(2236320.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(2235878.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(2235877.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(2235692.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(2235706., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(2236477.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(2237960.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(2239328.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(2242332.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(2245781.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(2251491., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(2261990.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(2276441.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(2295173.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(2323011., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(2338621.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(2371176.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(2371818.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(2390989.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(2364058.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(2361246.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(2325258.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(2310064.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(2283288., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(2270570.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(2259918., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(2251783.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(2246021.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(2239252., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(2234774.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(2231181.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(2228691.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(2228132.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(2226776.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(2226503., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(2225485.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(2225378.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(2224612.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(2224630.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(2224088.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(2224230., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(2223919.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(2224248.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(2225914.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(2226773.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(2229151., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(2230987.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(2234424.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(2237840.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(2243308.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(2248021.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(2254380.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(2259656.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(2269736., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(2273879.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(2282433.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(2286162.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(2291689., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(2294993.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(2295112.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(2293787.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(2289370.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(2283598.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(2277733.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(2267464.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(2262545.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(2255458.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(2252110.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(2245768.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(2242595.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(2237294.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(2237097., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(2233318.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(2234007.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(2230786.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(2232124.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(2229764.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(2231508.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(2229559., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(2231605.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(2230130.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(2232424.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(2231342.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(2233799.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(2233101., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(2235651.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(2235311., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(2237871.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(2237830.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(2240268.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(2239369.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(2241693.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(2240667.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(2242744.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(2241702., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(2243530., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(2242402.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(2245871., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(2246198.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(2248926.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(2248819.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(2250464.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(2249683.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(2250489.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(2248906.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(2247776., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(2245563.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(2244433.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(2241849.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(2239152.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(2236553.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(2234610.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(2232191.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(2230993.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(2227497., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(2227565.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(2227309.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(2227986.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(2229443.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(2229941.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(2231651.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(2231887.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(2229896., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(2232009.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(2230145.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(2232173.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(2229482.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(2231557.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(2228999.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(2231103.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(2228679.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(2230783.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(2228489.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(2230583.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(2229539.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(2231410.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(2229702., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(2230762., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(2229149.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(2230146.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(2228678.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(2231383.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(2229947.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(2232321.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(2231844.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(2233708.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(2231884.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(2232889.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(2230897.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(2231779.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(2229655., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(2229527.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(2228547.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(2228426.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(2227451.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(2227368.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(2226429.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(2226400., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(2225527.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(2225531.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(2224748.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(2223125.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(2222519.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(2219602., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(2217742., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(2215660.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(2214327.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(2212896., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(2212702.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(2211697.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(2211949., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(2211271.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(2211962., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(2211534., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(2211997.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(2210726.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(2211595.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(2210178., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(2211460.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(2211867.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(2213580., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(2213262.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(2216184.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(2215732.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(2219065.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(2218573.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(2222234., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(2221587.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(2226682., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(2226439.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(2233588.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(2230934.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(2237626.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(2233526.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(2241026.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(2233723.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(2239907.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(2231607., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(2234428.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(2225599.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(2227688., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(2220637.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(2222750., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(2214948.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(2215281.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(2209873.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(2209876., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(2205687.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(2205223.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(2200747.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(2200181.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(2196910.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(2195963.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(2193677., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(2193198., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(2191886.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(2191765., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(2190915.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(2191774.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(2191273.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(2191820.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(2191680.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(2192658.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(2192892.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(2194428.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(2195075.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(2196790.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(2196721., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(2199673.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(2200228.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(2204064.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(2205314.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(2211073., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(2212792.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(2221894.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(2224863.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(2238049., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(2243001.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(2259452.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(2259414.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(2273402.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(2265608.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(2273178.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(2258650., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(2259811.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(2243322.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(2237674.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(2224781., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(2219963.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(2210403.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(2204973.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(2198049.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(2191843., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(2188491.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(2184635.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(2182194.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(2180865.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(2179433.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(2178531.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(2178200.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(2177533.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(2177572., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(2177569.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(2177882., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(2178151.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(2178774., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(2179400., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(2179762.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(2180154.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(2180888.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(2181583., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(2183363., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(2184004.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(2187653.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(2190232.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(2194776., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(2201822.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(2211444.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(2223480.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(2235395., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(2251976.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(2263101., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(2275837.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(2278237.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(2284001.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(2274346.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(2270212.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(2255514.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(2244415.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(2231045.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(2221848.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(2210874., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(2203721.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(2196621., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(2189256.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(2184001., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(2178892.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(2176824.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(2173902.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(2172272.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(2171750.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(2170710.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(2170653.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(2170511.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(2170795.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(2170884.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(2171519.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(2171828.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(2172319.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(2175018., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(2175673.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(2179038.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(2181224., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(2184664.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(2189016., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(2194353.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(2200386.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(2205407., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(2214571.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(2219892., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(2228505., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(2231987., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(2238625.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(2237956.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(2241064.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(2235874.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(2235184.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(2227808.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(2224530., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(2216644.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(2213814., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(2207874.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(2204744., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(2197063., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(2193254.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(2188494.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(2184708.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(2182202., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(2179676., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(2178678.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(2177666.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(2177284.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(2176863., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(2176843.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(2176878.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(2177091.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(2177659.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(2177984.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(2179065.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(2179410.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(2180984., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(2181276.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(2184332.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(2184199.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(2189390., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(2190309., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(2196922.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(2196725., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(2204489., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(2203587., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(2209831., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(2209113.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(2212511., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(2209893.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(2212011.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(2208041., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(2209078., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(2204486., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(2206509., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(2201397., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(2203903.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(2196571.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(2196817.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(2190697.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(2191179.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(2186191., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(2185593.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(2182081.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(2181213.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(2178036.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(2177989.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(2175668.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(2176330., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(2174521.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(2175783.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(2174298., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(2175213., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(2174735.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(2176155., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(2175711., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(2177601.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(2177097.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(2180377., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(2179609.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(2184332.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(2183092.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(2189835.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(2187732.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(2194488.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(2191135.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(2197633.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(2193243.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(2201363., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(2195615.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(2203084.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(2198154.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(2204831.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(2198475.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(2204288.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(2196944.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(2201992., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(2194179.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(2196854., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(2187624.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(2190711.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(2182777.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(2185315.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(2178542.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(2178986.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(2173709.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(2175087.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(2170795., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(2172915.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(2169246.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(2171999.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(2168708.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(2172021.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(2168939.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(2172767.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(2169771.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(2174080.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(2171071., grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(2175828.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(2172720.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(2178950.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(2175523.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(2182075.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(2178263.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(2186830.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(2182274.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(2190861.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(2185418.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(2193796.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(2187181., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(2195189.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(2187713.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(2195299.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(2187157.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(2194363.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(2185762.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(2192687.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(2184083.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(2190842.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(2182127.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(2188836.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(2180153., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(2186910.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(2178346.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(2183414.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(2175426., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(2176503.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(2170104.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(2170966.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(2165892.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(2167538.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(2163382.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(2164983.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(2161555.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(2163765.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(2160825.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(2163576.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(2160968.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(2164237.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(2161856., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(2165634., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(2163420., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(2168440.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(2166273.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(2171816.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(2169598.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(2180094.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(2177397., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(2191777.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(2186591.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(2201312.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(2205571.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(2223876., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(2233958.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(2249025.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(2245482.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(2252004.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(2239632.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(2238805.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(2224330.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(2220024.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(2199992.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(2196295.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(2175660.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(2172861.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(2159307.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(2157618.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(2150490.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(2149589.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(2145345.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(2144214.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(2142290.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(2141229., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(2140274.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(2139768.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(2139255.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(2139023.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(2138737., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(2138664.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(2138513.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(2138557.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(2138505.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(2138658.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(2138699.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(2138975.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(2139121.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(2139556., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(2139839.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(2140493.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(2140984., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(2143002.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(2143948.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(2148973.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(2150285.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(2157076.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(2158829.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(2165831.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(2169077.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(2189116., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(2198449.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(2234071., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(2262839.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(2306420.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(2308505.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(2332324.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(2310921.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(2307081.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(2263085.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(2249964.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(2221285.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(2209461.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(2190929.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(2183424., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(2163780.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(2161059.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(2149109., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(2147041.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(2141504.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(2139452.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(2137396., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(2136769.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(2135668., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(2135574., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(2134921.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(2135047., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(2134543.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(2134790.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(2134365.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(2134699., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(2134322.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(2134734.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(2134403.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(2134897.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(2134609.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(2135203.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(2134979.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(2135695.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(2135462., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(2136343.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(2136242.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(2137355., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(2137453.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(2138901.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(2138765.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(2140612.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(2140841., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(2143259., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(2143504.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(2147572., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(2148929.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(2158524.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(2162718.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(2174236.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(2180190.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(2212462.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(2246831., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(2300440., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(2327644.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(2370716.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(2328596.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(2334215.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(2289750.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(2275276.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(2231465.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(2218338.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(2195370.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(2185991.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(2165966.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(2155139.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(2144092., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(2139881.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(2135378.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(2134570., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(2132920.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(2132953.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(2131959.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(2131356., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(2130970.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(2130703.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(2130523.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(2130377.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(2130271.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(2130182.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(2130103.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(2130030.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(2129963., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(2129898.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(2129836., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(2129775.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(2129715.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(2129656.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(2129599., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(2129540.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(2129483.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(2129426.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(2129370., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(2129313.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(2129257., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(2129200.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(2129144.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(2129089., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(2129033.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(2128978.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(2128924.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(2128870.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(2128818.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(2128767.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(2128718.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(2128673.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(2128633.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(2128600., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(2128577.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(2128570.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(2128588.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(2128644.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(2128761.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(2128948.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(2129300.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(2129883.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(2130884.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(2132551., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(2135118.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(2142775.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(2152378.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(2183028.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(2254637., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(2397041.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(2494037.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(2639038.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(2387289.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(2419551.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(2264119.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(2267891.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(2240103., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(2236352.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(2206914.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(2201586.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(2182878.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(2168150.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(2162340.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(2154250.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(2142587.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(2138349.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(2133279.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(2131095.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(2129390.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(2128556., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(2128037.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(2127696.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(2127456., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(2127282.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(2127148., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(2127041.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(2126951.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(2126872.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(2126802., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(2126736.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(2126675., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(2126615.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(2126558.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(2126503.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(2126448.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(2126394.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(2126341.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(2126289.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(2126236.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(2126185.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(2126134.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(2126083.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(2126033.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(2125984., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(2125934.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(2125886.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(2125840.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(2125795.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(2125753.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(2125714., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(2125681.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(2125655.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(2125639.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(2125639.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(2125663.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(2125723.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(2125838.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(2126041.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(2126382., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(2126941.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(2127517.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(2129057.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(2130981.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(2134805.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(2140103., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(2154159.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(2173900., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(2224758.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(2314083., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(2474996.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(2390880.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(2500431.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(2324599.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(2368731.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(2257633.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(2276951.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(2237091.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(2245576.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(2221459.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(2224251.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(2202891., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(2190029., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(2173459.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(2162401.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(2157239.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(2147771.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(2137505.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(2132465.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(2129130.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(2127402.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(2126076.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(2125546., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(2124925.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(2124644.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(2124443., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(2124291.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(2124172.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(2124075.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(2123992.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(2123920.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(2123854., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(2123793., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(2123735.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(2123681., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(2123628.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(2123577.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(2123527., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(2123478.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(2123431.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(2123384.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(2123339., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(2123294., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(2123250., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(2123207., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(2123164.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(2123124.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(2123086.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(2123052., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(2123020.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(2122995.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(2122977., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(2122969.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(2122978.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(2123010., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(2123075., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(2123192.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(2123387., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(2123693., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(2123938.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(2124566.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(2125352.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(2127051.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(2129350.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(2133521.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(2139196.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(2150587.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(2191028., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(2259095.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(2365329., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(2528018.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(2381612., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(2459682.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(2282608.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(2318536.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(2270436., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(2285990., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(2233877.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(2239012.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(2208297.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(2195729.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(2175377.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(2160137.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(2155172., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(2146369.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(2145859.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(2139181.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(2131868., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(2128190.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(2125697.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(2124384.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(2123336.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(2122713.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(2122270.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(2122024.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(2121804., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(2121693.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(2121563.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(2121504.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(2121450., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(2121399.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(2121350.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(2121303.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(2121257.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(2121212.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(2121168.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(2121124.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(2121081.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(2121038.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(2120996.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(2120954.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(2120912.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(2120871.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(2120831.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(2120791.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(2120753., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(2120715.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(2120680.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(2120647.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(2120618.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(2120594.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(2120578., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(2120572., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(2120582.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(2120616.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(2120687., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(2120794.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(2120847.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(2121079., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(2121333., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(2122071.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(2122954.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(2124709.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(2127305., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(2131944.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(2138637.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(2153425.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(2196401.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(2275807., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(2366799., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(2532264.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(2383452.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(2463559.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(2285278.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(2322979.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(2221106.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(2225760., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(2211248.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(2210934.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(2197269.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(2190987.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(2175797.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(2165478.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(2159683.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(2153542.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(2150748.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(2141279., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(2141689.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(2134467., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(2133817.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(2129429.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(2126331., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(2124418.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(2122934.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(2122078.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(2121292.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(2120884.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(2120420., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(2120224.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(2119932., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(2119720.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(2119538.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(2119403.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(2119280.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(2119185.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(2119093.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(2119021.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(2118948.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(2118890.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(2118830., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(2118781.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(2118731., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(2118690., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(2118648.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(2118608.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(2118568.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(2118528.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(2118487.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(2118447.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(2118406.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(2118366., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(2118325.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(2118285., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(2118244.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(2118203.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(2118163., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(2118122.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(2118082.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(2118043., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(2118005., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(2117968.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(2117935.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(2117908.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(2117891.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(2117886., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(2117906.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(2117889.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(2117968.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(2118078., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(2118492., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(2119150.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(2120673.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(2123567.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(2130452.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(2159015.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(2220378.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(2355548., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(2597323.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(2440137., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(2583209., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(2317425.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(2373012.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(2233386., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(2252294.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(2217987.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(2215942., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(2198613.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(2190552.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(2183014., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(2174086.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(2165451.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(2156093., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(2152541.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(2144600.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(2144457.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(2138237., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(2140417.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(2135097., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(2137446.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(2132769.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(2136283., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(2131945.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(2136262.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(2132133.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(2137052.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(2133082., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(2139725.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(2135868., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(2142720.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(2138987.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(2146032.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(2146783., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(2154630.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(2155698.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(2162676.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(2165136.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(2169499.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(2171339.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(2174172.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(2174998.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(2176382.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(2183142.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(2181699., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(2185298.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(2181707.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(2183751.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(2178867., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(2179749.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(2174538.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(2168167.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(2165319., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(2161041., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(2159834.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(2156093.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(2156171., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(2152888.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(2153936.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(2149706.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(2152713., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(2148820.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(2152289., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(2148673.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(2152442.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(2149038.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(2152990.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(2149745.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(2152819.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(2149783., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(2153099.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(2150229.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(2153702.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(2152285.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(2155567.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(2154126.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(2157191.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(2155681.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(2158520.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(2156904.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(2159524.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(2157778.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(2160170., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(2158286.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(2160526.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(2158509.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(2160641.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(2158500.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(2160565.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(2158317.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(2160343.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(2158010.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(2160044.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(2157646., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(2159711.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(2157266., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(2159379., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(2156900.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(2159061.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(2156563.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(2158786.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(2156278.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(2158562.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(2156049.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(2158389.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(2155874.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(2158265.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(2155750.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(2158154.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(2155641.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(2158086.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(2155577.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(2158055., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(2155545.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(2158043.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(2155533.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(2158052.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(2155539.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(2158070.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(2155553., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(2158093.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(2155569.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(2158116.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(2155583.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(2158135.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(2155598.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(2158153., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(2155604.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(2158159.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(2155600.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(2158157.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(2155586.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(2158147., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(2155566.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(2158130.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(2155538.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(2158094.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(2155494., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(2158058., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(2155448.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(2158022., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(2155405.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(2157986., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(2155363., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(2157952.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(2155323.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(2157919., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(2155283.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(2157393.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(2154804.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(2157035., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(2154494., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(2156821., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(2154323.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(2156724., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(2154266., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(2156718.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(2154291.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(2156777., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(2154374.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(2156877., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(2154491.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(2156994., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(2154617.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(2157108., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(2154735., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(2157218.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(2154852., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(2157320.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(2154948.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(2157402., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(2155020.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(2157460., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(2155074.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(2157499.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(2155101.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(2157652.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(2155229.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(2157738.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(2154015., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(2156761.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(2154425.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(2157105., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(2153479.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(2156364.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(2152853.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(2155899.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(2152496.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(2155666.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(2152362.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(2155618., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(2152402.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(2155708.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(2152565.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(2155880., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(2152796.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(2156109.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(2153073., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(2156365.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(2153360.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(2156618.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(2153641.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(2156854.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(2153873., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(2157040.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(2154062.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(2157183.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(2154204., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(2157281., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(2154295.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(2157330.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(2153307.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(2156519.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(2152600.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(2155960.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(2152161.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(2154020.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(2151464., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(2153567.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(2151146., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(2153434.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(2151135., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(2153570.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(2151377.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(2153884.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(2151769.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(2154304., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(2152247.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(2154779.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(2151769., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(2154448.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(2151552.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(2154344.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(2151552.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(2154418.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(2151736.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(2154637.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(2152033., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(2154939.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(2152395.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(2155281.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(2152783.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(2155629.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(2153160.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(2155953.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(2153499., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(2156231.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(2153789.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(2156456.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(2154008.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(2156612., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(2154152., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(2156698., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(2154223.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(2156721.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(2154233.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(2156691., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(2154976.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(2157263.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(2155474.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(2157608.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(2155727.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(2157735.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(2155504.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(2157467., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(2155180., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(2157128.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(2154802.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(2156760., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(2154411.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(2156397.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(2154038.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(2156064.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(2153709.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(2155778.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(2153435.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(2155800., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(2153460.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(2155808.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(2153472., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(2155792.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(2153455., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(2155764.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(2153428.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(2155729.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(2153392.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(2155687., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(2153350.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(2155641.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(2153305.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(2155594.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(2153258.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(2155546.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(2153213.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(2155499.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(2153159.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(2155448., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(2153110.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(2155401., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(2153067.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(2155359.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(2153030., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(2155303.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(2152978.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(2155275.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(2152955.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(2155232.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(2152917.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(2155197., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(2152885., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(2155476.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(2153149.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(2155690.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(2153339., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(2155815.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(2153435.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(2155858.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(2153449.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(2155811.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(2153141.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(2155542.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(2152874.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(2155281., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(2152624.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(2155081.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(2152448., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(2154925.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(2152309., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(2154829.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(2152219., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(2154734.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(2152143.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(2154688.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(2152114.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(2154645.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(2151977.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(2154555., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(2151912., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(2154504.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(2151884.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(2154467., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(2151869.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(2154477.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(2151898.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(2154505., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(2151938.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(2154518.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(2151965., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(2154562., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(2152016.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(2154599.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(2152057.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(2154592.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(2152057.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(2154603.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(2152083., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(2154590.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(2152073.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(2154570.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(2152055.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(2154564., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(2152048.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(2154526.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(2152013., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(2154485.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(2151969.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(2154438.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(2151924.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(2154391., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(2151876.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(2154341.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(2151831., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(2154295.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(2151789.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(2154253., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(2151744., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(2154201.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(2151702.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(2154160.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(2151665.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(2154122.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(2151643.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(2154083.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(2151612., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(2154051.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(2151585.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(2154022.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(2151562.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(2153995.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(2151542.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(2153970.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(2151522.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(2153945.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(2151497.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(2153917.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(2151473.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(2153889.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(2151450.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(2153860.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(2151426.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(2153843.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(2151409.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(2153819.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(2151391., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(2153794., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(2151369., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(2153766., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(2151345.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(2153735.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(2151317.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(2153702.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(2151301.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(2153677.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(2151280.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(2153649.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(2151256., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(2153618.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(2151227.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(2153583., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(2151208.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(2153556., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(2151184.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(2153524.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(2151156.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(2153503.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(2151140.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(2153477.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(2151117., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(2153446.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(2151088.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(2153410.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(2151055.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(2153371., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(2151018.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(2153328.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(2150981., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(2153283.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(2150940.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(2153239.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(2150902., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(2153197., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(2151902.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(2154008., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(2152615., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(2154537., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(2152896.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(2154692., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(2152964.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(2154666.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(2152854., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(2154497.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(2152611.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(2154230., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(2151273.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(2153099.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(2150210., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(2152233.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(2149430.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(2151624.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(2148905.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(2151243.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(2148620.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(2151078.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(2148546.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(2151079., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(2148639., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(2151211.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(2148840.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(2151426.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(2149110.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(2151687.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(2149414., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(2151964.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(2150745.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(2153065.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(2151774.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(2153871.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(2152480.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(2154379.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(2152874., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(2154606.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(2152984.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(2154596., grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(2152864.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(2154400.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(2152578.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(2154071.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(2152178.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(2153680.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(2151736.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(2153266.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(2151289.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(2152867.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(2149835.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(2151681.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(2148758.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(2150830., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(2148027.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(2150294., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(2147613.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(2150030.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(2147466., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(2149989.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(2147530.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(2150119., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(2147751.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(2150368., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(2148076.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(2150692.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(2149474., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(2151875., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(2150613.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(2152787., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(2151448.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(2153424.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(2151987.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(2153785., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(2152272.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(2153928.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(2152310.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(2153865.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(2152151.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(2153646.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(2151854., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(2153326., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(2151495.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(2152969.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(2151096.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(2152596.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(2150697., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(2152228.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(2150317.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(2152942.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(2150955., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(2153411., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(2151233., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(2153553.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(2151301.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(2153522.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(2151197.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(2153350.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(2150965.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(2153088., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(2150678.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(2152792.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(2150350.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(2152452.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(2148961.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(2151309.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(2147928.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(2150492.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(2147229.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(2149970.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(2146827.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(2149703.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(2146672., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(2149642.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(2146712.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(2149736., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(2146895.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(2149943., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(2147174.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(2150208.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(2147495.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(2150507.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(2147836., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(2150811.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(2149187.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(2151923.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(2150220.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(2152726., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(2150918., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(2153221., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(2151294.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(2153443.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(2151399., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(2153427.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(2151279.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(2152540.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(2150360., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(2151747.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(2149572., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(2151094., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(2147913.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(2149773.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(2146739., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(2148884., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(2145999.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(2148371.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(2145633.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(2148173., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(2145570., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(2148222.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(2145741., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(2148459.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(2146078., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(2148821., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(2146519., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(2149243., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(2147001.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(2149693., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(2148512., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(2150969., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(2149724., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(2151940., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(2150594.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(2152588.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(2151123.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(2152928.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(2151336.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(2152996.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(2151286.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(2152848.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(2151033.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(2152785.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(2150871.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(2152553.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(2150558.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(2152211., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(2150155.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(2151812.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(2149716.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(2151402.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(2149283.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(2151015., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(2148895.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(2150679.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(2148563.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(2150400.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(2147262.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(2149362.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(2146350.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(2148669., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(2145787.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(2148275., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(2145518.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(2148133.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(2145492.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(2148191.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(2145652.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(2148396., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(2146951., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(2149520.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(2148053.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(2150438.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(2148918.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(2151097., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(2149503., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(2151524.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(2149844.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(2151735.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(2149969.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(2151761.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(2149915.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(2151643., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(2149727.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(2151421., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(2149447., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(2151135., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(2149121., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(2150823.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(2148784.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(2150516.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(2148491.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(2150257.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(2148228., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(2150028.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(2148003.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(2149838.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(2147821.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(2149921., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(2147898., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(2149975.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(2147945.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(2150003.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(2147964.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(2150007.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(2147959.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(2149991., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(2147935., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(2149967.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(2147807., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(2149851.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(2147694.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(2149751.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(2147596., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(2149667.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(2146500.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(2148895.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(2145835.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(2148388.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(2145437., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(2148110.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(2145272.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(2148967.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(2147173., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(2149579.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(2147755.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(2150053.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(2148183., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(2150371.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(2148447.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(2150545.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(2148565., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(2150591.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(2148557.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(2150559.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(2148474.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(2151408.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(2149218.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(2151917.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(2149600.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(2152112.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(2149671.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(2152048.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(2149499.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(2151787.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(2149150., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(2151387.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(2148688.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(2150934.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(2148195.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(2150475.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(2147717., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(2150045., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(2147283.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(2149677., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(2146922., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(2149373., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(2145607.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(2148330.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(2144699.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(2147646.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(2144151., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(2147270., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(2143912.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(2147169.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(2143923.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(2147254.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(2144102.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(2147469.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(2144396.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(2147767.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(2145772., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(2148931.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(2146884.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(2149833.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(2147704.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(2150468., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(2148239.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(2150836.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(2148503., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(2150969.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(2148535.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(2150901.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(2148383.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(2150699.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(2148102., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(2150403.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(2147753.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(2150059.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(2147373., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(2149711.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(2147005.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(2149388.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(2146673.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(2149107.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(2145363.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(2148064.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(2144443.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(2147368.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(2143871.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(2146970.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(2143592., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(2146818.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(2143547.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(2146858.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(2143679.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(2147037.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(2143933.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(2147307.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(2145280.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(2148450.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(2146370.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(2149336.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(2146911.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(2149738.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(2147232.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(2149948.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(2148388.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(2150807., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(2149088., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(2151265., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(2149276., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(2151290.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(2149162.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(2151074.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(2148828.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(2150695.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(2148359.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(2150226.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(2147813.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(2149718.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(2147255.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(2149223.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(2146743.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(2148787., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(2146306., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(2148424.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(2145952., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(2148279.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(2145811.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(2148168.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(2145707., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(2148089.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(2145633.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(2148038.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(2145588., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(2148011.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(2145566., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(2147993., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(2145551.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(2147990.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(2145551., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(2147998.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(2145566.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(2148013.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(2145579., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(2148028., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(2145591., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(2148041., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(2145599.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(2148050., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(2145603., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(2148053.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(2145600.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(2148051.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(2145592., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(2148044., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(2145570., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(2148025.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(2145545., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(2148004.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(2145518.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(2147981.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(2145493.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(2147959.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(2145468.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(2147940.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(2145449.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(2147923., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(2145425.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(2147902.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(2145410.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(2147887.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(2145390., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(2147867.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(2145364.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(2147836.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(2145330.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(2147803.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(2145275.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(2147758.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(2145238.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(2147728.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(2145205.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(2147702.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(2145172.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(2147675.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(2145144., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(2147652., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(2145119.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(2147633.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(2145099.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(2147616.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(2145081.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(2147602., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(2145071.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(2147592.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(2145059.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(2147581.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(2145045.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(2147567.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(2145028., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(2147551.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(2145009.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(2147533.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(2144988.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(2147609., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(2145053.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(2147649., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(2145081.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(2147661.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(2145083.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(2147650.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(2145062.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(2147620.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(2145024., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(2147580.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(2144974.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(2147529.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(2144920., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(2147477.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(2144847.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(2147412., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(2144781.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(2147353.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(2144722., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(2147303.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(2144672.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(2147261.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(2144631., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(2147227.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(2144597.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(2147198.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(2144569.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(2147176.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(2144547.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(2147149.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(2144524., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(2147129.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(2144503.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(2147103.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(2144478.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(2147083.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(2144458.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(2147066., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(2144441., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(2147052.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(2144426., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(2147038.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(2144427.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(2147038., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(2144424.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(2147034.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(2146062.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(2148329.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(2147190., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(2149156., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(2147832.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(2149558.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(2148052.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(2149609.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(2147938.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(2149397.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(2145914.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(2147721.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(2144336.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(2146460.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(2143189.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(2145582., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(2142429., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(2145013.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(2141978., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(2144729.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(2141800., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(2144669.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(2141828.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(2144771.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(2142008.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(2144989.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(2142288.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(2145276.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(2142621., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(2145594., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(2142968.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(2145909.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(2143300.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(2146200.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(2143595., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(2146448.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(2143839.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(2146645.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(2144033., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(2146799., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(2145816.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(2148201.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(2147040.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(2149096., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(2147734., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(2149521., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(2147961.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(2149555.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(2147819.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(2149295.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(2147412.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(2148854., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(2145195.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(2146281., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(2142832.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(2144455.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(2141226.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(2143281.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(2139290., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(2141872.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(2138187., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(2141158.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(2137743.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(2140982.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(2137804.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(2141212.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(2139199.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(2142513.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(2140581.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(2143759., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(2141867.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(2144879.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(2144616.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(2147919.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(2147444.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(2150119.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(2149341.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(2151438.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(2150316.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(2151951.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(2150491.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(2151804.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(2150048.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(2151183.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(2149195.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(2150268.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(2148117.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(2149234.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(2146991.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(2147448.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(2143605., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(2144787.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(2141223.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(2142992.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(2139698., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(2142006.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(2137985., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(2140803.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(2137101., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(2140258.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(2136834., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(2140227.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(2137992.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(2141352.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(2139237.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(2142511.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(2140475.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(2143618.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(2141497.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(2144547.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(2144056., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(2146652., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(2146009.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(2148168., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(2147323.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(2149096.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(2148014., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(2150270.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(2149162.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(2150954.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(2149534., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(2150991.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(2149292.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(2150523., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(2148602.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(2148968.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(2146970., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(2147548.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(2145281., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(2146154.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(2142327.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(2143853.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(2140301.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(2142345., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(2139050.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(2141484.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(2138418.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(2141125.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(2138267.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(2141161.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(2138482.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(2141485.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(2138956.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(2141997., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(2139588.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(2142624.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(2140307., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(2143303., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(2142650.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(2145264.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(2144509., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(2146757.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(2145837., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(2147746.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(2146645.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(2148264.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(2147234.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(2148589.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(2147363.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(2148532.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(2147133.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(2148196.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(2146468.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(2147534.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(2145726.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(2146845., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(2144741.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(2145995.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(2143902.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(2145300., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(2141636.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(2143523.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(2140086.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(2142371., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(2139154., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(2141736.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(2138718.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(2141512.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(2138673.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(2141603.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(2138925.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(2141926., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(2139374.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(2142395.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(2141523.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(2144217.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(2143283.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(2145650., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(2144605.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(2146669.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(2145736., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(2147484.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(2146376.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(2147868., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(2146584.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(2147892.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(2146452.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(2147646.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(2146076.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(2147221.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(2145554., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(2146693.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(2144959.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(2146140.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(2144367.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(2145615.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(2143824.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(2145148.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(2143117.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(2144575., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(2140986.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(2142921.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(2139557.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(2142114.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(2138943.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(2141715., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(2138721.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(2141652., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(2138812.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(2141923.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(2139209.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(2142340.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(2141300.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(2144000.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(2142897.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(2145302.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(2144344.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(2146416.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(2145307.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(2147093., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(2145818.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(2147372.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(2145939.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(2147436.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(2145859., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(2147236., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(2145535.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(2146854.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(2145059., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(2146371.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(2144511.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(2145855., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(2143955.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(2145354.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(2143437.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(2144906.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(2142987., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(2144528.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(2142619.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(2144231., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(2142338.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(2144012.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(2142139.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(2143867.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(2142014.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(2143784., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(2140360.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(2142514.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(2139287.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(2141739.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(2138463., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(2141185., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(2138105.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(2141013.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(2138102.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(2141128.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(2139917.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(2142692.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(2141700.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(2144169., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(2143092.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(2145270., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(2144076.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(2145994.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(2144668., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(2146376.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(2145926.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(2147260., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(2146589.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(2147618.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(2146736.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(2147560.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(2146494., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(2147206.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(2144968.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(2145881.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(2143649.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(2144768.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(2142577., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(2143900.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(2141764.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(2143270., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(2141203.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(2142857.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(2140859.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(2142629.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(2140696.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(2142551., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(2140676.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(2142585., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(2140757.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(2142697.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(2140908.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(2142859., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(2141097.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(2143042.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(2141300., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(2143221.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(2141489., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(2143390.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(2141661.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(2143537.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(2141806.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(2143657.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(2141920., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(2143754.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(2142007.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(2143813.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(2142056.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(2143844., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(2142076.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(2143849., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(2142071.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(2143836.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(2143032.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(2144575.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(2143671., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(2145033., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(2144021.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(2145237., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(2144123., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(2145235.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(2144032.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(2145087.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(2142819.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(2144077.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(2141862.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(2143307.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(2141158., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(2142766., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(2140688.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(2142426., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(2140418.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(2142254., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(2140311.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(2142216.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(2140330.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(2142275.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(2140437.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(2142395.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(2140595., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(2142556.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(2140783.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(2142733.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(2140984.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(2142915.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(2142151., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(2143844.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(2142991.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(2144475., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(2143521., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(2144838.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(2143782.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(2144967., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(2143817.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(2144911.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(2143682., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(2144730.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(2143442.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(2144471.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(2142149.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(2143418.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(2141172.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(2142646.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(2140486.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(2142131.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(2140058.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(2141835.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(2139845., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(2141716.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(2139799.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(2141733.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(2139879., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(2141846.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(2140043.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(2142018., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(2140254.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(2142223., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(2141457.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(2143198.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(2142363.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(2143895.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(2142971.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(2144325.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(2143309.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(2144523., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(2143418.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(2144533.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(2143351.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(2144404.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(2143153., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(2144177.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(2142881.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(2143905.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(2141597.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(2142865.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(2140646.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(2142131.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(2140007.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(2141660.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(2139630.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(2141409.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(2139466., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(2141334.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(2139466.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(2141389.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(2139586., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(2141536., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(2139784.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(2141738.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(2140995.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(2142735.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(2141929.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(2143460.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(2142573.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(2143925.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(2142951., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(2144173.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(2143113.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(2144228., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(2143091.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(2144136.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(2142930.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(2143939.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(2142684.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(2143684.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(2142392.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(2143400.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(2141114.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(2142376.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(2140188.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(2141662.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(2139578., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(2141221.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(2139235.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(2141004.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(2139108.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(2140962.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(2139147.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(2141052.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(2139302.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(2141228.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(2140492., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(2142208.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(2141417.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(2142939.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(2142078.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(2143429.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(2142491.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(2143702.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(2142688.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(2143794.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(2142710., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(2143748., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(2142604.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(2143613.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(2142421.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(2143411.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(2142185.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(2143176., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(2140954.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(2142185.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(2140057., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(2141487.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(2139458.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(2141052.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(2139111.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(2140829.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(2138977.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(2140779., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(2139003.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(2140855.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(2139145.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(2141022., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(2140320.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(2141990., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(2141237., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(2142712.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(2141890.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(2143196.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(2142296.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(2143463.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(2142487.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(2143551., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(2142504.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(2143498., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(2142392.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(2143345.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(2142195.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(2143133.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(2141951.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(2142893.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(2141681.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(2142644.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(2140454.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(2141669.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(2139573.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(2141002.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(2139012.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(2140606.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(2138717.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(2140431., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(2138643.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(2140434.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(2138723.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(2140557.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(2139864.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(2141507.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(2140775., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(2142235., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(2141443.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(2142740.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(2141881.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(2143043.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(2142113.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(2143172., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(2142166.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(2143153., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(2143715.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(2144296.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(2144656.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(2144905.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(2145054.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(2145061.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(2145016.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(2144874.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(2143033.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(2143219.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(2141476.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(2141962., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(2139358.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(2140331.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(2137941.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(2139297.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(2137106.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(2138745., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(2136724., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(2138561.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(2136696., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(2138659.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(2136920.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(2138950., grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(2137318.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(2139368., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(2138762.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(2140593.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(2139963.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(2141578.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(2140894.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(2142306.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(2141574.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(2142806.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(2143606., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(2144340., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(2144899.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(2145220., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(2144718.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(2144906.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(2144256.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(2144394., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(2142010.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(2142549.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(2141064., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(2141776.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(2140343.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(2141207.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(2139836., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(2140826., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(2139516.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(2140603.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(2139355.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(2140510.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(2139315.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(2140516.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(2139367.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(2140590.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(2139479.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(2140708.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(2139626.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(2140849., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(2139788.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(2140994.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(2139948.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(2141131.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(2140094.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(2141250.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(2140217.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(2141346.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(2140314.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(2141419.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(2141980.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(2142712.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(2143110.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(2143527., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(2143748., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(2143912.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(2143961.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(2143949.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(2143849.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(2143733.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(2143513.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(2143359.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(2141439., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(2141684.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(2139895.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(2140484.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(2137890., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(2138986.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(2136633.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(2138105.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(2135971., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(2137710., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(2135766.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(2137681.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(2135901.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(2137918.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(2136273.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(2138332.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(2137729.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(2139587.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(2138982., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(2140630.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(2139991.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(2141442.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(2142350., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(2143277.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(2143163.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(2143817., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(2143537., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(2143978.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(2143546.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(2143850., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(2143287.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(2143521.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(2141247., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(2141854.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(2139695.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(2140630.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(2138603.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(2139798., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(2138655.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(2139887.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(2138793.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(2140039.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(2138983.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(2140238.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(2139209.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(2140454.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(2139441.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(2140656.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(2139652., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(2140830.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(2139829.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(2140973., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(2139969., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(2141081.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(2141662.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(2142387.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(2142014., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(2142591., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(2142121.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(2142594.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(2142041.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(2142454.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(2140237.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(2141006.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(2138917.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(2139987.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(2138033., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(2139341.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(2137516.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(2139004.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(2137298.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(2138908.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(2137307., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(2138993.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(2137480.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(2139203., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(2137761.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(2139489.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(2138102.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(2139810., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(2138462., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(2140128.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(2138805.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(2140428., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(2139877., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(2141276.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(2140663.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(2141862., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(2141173., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(2142212., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(2141441., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(2142358.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(2139914., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(2141112.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(2138769.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(2140220., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(2137988.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(2139637., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(2137517., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(2139315.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(2137301., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(2139197., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(2137278.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(2139241.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(2137404.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(2139401., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(2137631., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(2139633., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(2137927.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(2139911.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(2138244.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(2140209.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(2138567.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(2140484.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(2138855., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(2140713.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(2139088.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(2140898.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(2139270.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(2141033.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(2139399.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(2141123.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(2141080.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(2142423.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(2142224.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(2143237., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(2142864., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(2143614.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(2143069.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(2143633.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(2142935.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(2143392.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(2140947.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(2141744.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(2139383.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(2140471.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(2138217.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(2139588.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(2137452.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(2139049.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(2137020., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(2138776., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(2136851.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(2138711.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(2136882., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(2138810.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(2137059.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(2139020.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(2137333.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(2139308.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(2137668.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(2139622., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(2138013.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(2139932.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(2138342.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(2140216., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(2138635., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(2140460.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(2138879.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(2140656.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(2139067.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(2140799.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(2139199.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(2140891.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(2139281.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(2140940., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(2139317., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(2140951.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(2139315.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(2140931., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(2139284.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(2140889.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(2139235.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(2140834.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(2139167.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(2140767.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(2139097.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(2140702.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(2139032., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(2140641.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(2138972.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(2140581.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(2138937.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(2140547.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(2138905.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(2140518.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(2138880., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(2140494.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(2138858.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(2140474.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(2138841.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(2140459.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(2138828., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(2140446.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(2138818.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(2140437., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(2138810., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(2140438.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(2138818., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(2140441., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(2138821.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(2140440.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(2138820.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(2140436.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(2138831.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(2140441., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(2138855.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(2140454.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(2138866.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(2140457.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(2138866.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(2140451.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(2138857., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(2140437.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(2138840., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(2140419., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(2138819.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(2140397., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(2138796.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(2140374., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(2138772.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(2140350.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(2138749.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(2140329., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(2138727.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(2140308.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(2138708., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(2140290.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(2138704.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(2140284.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(2138698., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(2140277., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(2138690., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(2140267.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(2138698.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(2140271.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(2138689.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(2140261.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(2138677.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(2140251., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(2138665.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(2140239., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(2138653.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(2140230.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(2138644.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(2140345.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(2138748., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(2140417.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(2138808.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(2140452., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(2138830.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(2140456.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(2138805.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(2140422.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(2138784.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(2140393., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(2138747.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(2140352.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(2138700.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(2140305.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(2138631.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(2140242.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(2138585.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(2140200.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(2138542.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(2140161.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(2138504., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(2140128.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(2138453.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(2140087.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(2138432.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(2140070.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(2138416.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(2140057.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(2138403.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(2140047.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(2138394., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(2140040.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(2138388., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(2140035.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(2138278.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(2139949., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(2138207.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(2139895.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(2138146.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(2139853.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(2138120.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(2139840.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(2138120., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(2139847., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(2138132.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(2139865.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(2138126., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(2139866.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(2138150.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(2139894.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(2138179.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(2139922.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(2138189.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(2139933.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(2138219.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(2139958.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(2138242.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(2139977.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(2138259.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(2139991.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(2138269., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(2139997.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(2138253.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(2139983.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(2138255., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(2139984.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(2138251.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(2139980.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(2138244.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(2139973.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(2139799.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(2141185.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(2140869., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(2141958.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(2141477., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(2142332.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(2141689., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(2142380.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(2139978.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(2140955.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(2138607., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(2139852.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(2137565.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(2139048.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(2136853., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(2138530.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(2136426., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(2138252.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(2136233.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(2138166.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(2136218., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(2138223.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(2136339.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(2138382.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(2136567.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(2138620.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(2136843., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(2138885.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(2137132.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(2139150.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(2137410.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(2139395.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(2137660.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(2139607.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(2137068.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(2139148.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(2136684.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(2138871.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(2136481.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(2138744.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(2136423., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(2138736.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(2136475.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(2138817., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(2136607., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(2138954.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(2136352.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(2138780.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(2136255.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(2138737.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(2136282.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(2138793.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(2136399.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(2138916.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(2136573.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(2139080.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(2136777.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(2139263., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(2136989.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(2139444., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(2137192.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(2139609.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(2137371.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(2139750., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(2137519.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(2139859.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(2137632.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(2139936.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(2137709., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(2139982., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(2137753., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(2139999.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(2137768.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(2139996.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(2137763.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(2139979.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(2137741.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(2139944.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(2137706., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(2139900.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(2137663., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(2139851., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(2137616.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(2139801.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(2137570.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(2139753.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(2137509.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(2139695.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(2137476.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(2139662.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(2136608.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(2138963.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(2135991.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(2138490.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(2135621.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(2138228., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(2135459.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(2138140.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(2135464.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(2138184.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(2135172.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(2137985.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(2135072.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(2137946., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(2135160.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(2138056.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(2135364.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(2138255.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(2135645., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(2138505.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(2135962.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(2138776., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(2136284.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(2139048.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(2136595.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(2139291.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(2136866.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(2139491.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(2137085., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(2139642.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(2137247., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(2139739.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(2137353., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(2139789., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(2137406.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(2139794.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(2137416.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(2139776.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(2137404., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(2139739.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(2137372.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(2139676.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(2137300.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(2139585.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(2137220., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(2139490.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(2137157., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(2139412.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(2137076.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(2139323., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(2137023., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(2139259., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(2136959., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(2139187.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(2136907.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(2139129.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(2136887.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(2139097.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(2136863., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(2138228.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(2136064.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(2137623., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(2135542., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(2137257.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(2135262.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(2137097.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(2135185.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(2137102., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(2135264.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(2137230.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(2135460., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(2137446.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(2135729.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(2137712.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(2136053.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(2138008.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(2136410.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(2138320.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(2136731.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(2138589.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(2137004.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(2138815.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(2137225.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(2138983.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(2137383., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(2139086., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(2137472.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(2139135., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(2137490.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(2139125., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(2137486.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(2139097., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(2137430., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(2139028.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(2137356.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(2138948.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(2137290.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(2138877., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(2137202.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(2138805.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(2137133., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(2138736.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(2137086.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(2138688.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(2135458.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(2137474.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(2134392.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(2136664.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(2133736., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(2136207., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(2133431.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(2136047.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(2133416.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(2136127.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(2135162.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(2137633., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(2136672.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(2138884.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(2137897.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(2139850., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(2138782., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(2140495.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(2139321.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(2140833.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(2139539.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(2140897.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(2139492.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(2140746., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(2139248., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(2140452.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(2138873.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(2140062.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(2138431.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(2139635.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(2137957., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(2139199.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(2137511.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(2138806.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(2137121.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(2138474.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(2136805.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(2138213.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(2136568.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(2138025.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(2136408.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(2137906.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(2134764., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(2136620., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(2133649., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(2135796.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(2133002., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(2135240.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(2132622., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(2135048.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(2132594.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(2135146.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(2134364., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(2136702., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(2135885.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(2138128.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(2137304.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(2139272.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(2138379.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(2140087.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(2139093.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(2140573., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(2139463.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(2140758.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(2139531.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(2140693.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(2139360.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(2140442.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(2139022.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(2139933.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(2138456.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(2139402.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(2137876., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(2138884.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(2137349., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(2138430., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(2136902.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(2138058.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(2136555.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(2136947.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(2135516., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(2136183.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(2133309.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(2134688.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(2132028.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(2134607.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(2132128.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(2134810., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(2132489.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(2135226., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(2134559., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(2136184., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(2135542.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(2137063.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(2136415.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(2137817.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(2137134.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(2138414.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(2137693.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(2138854.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(2138063.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(2139974.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(2139073., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(2140693.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(2139660., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(2141038., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(2139863.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(2141058.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(2139743., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(2139960., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(2138561.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(2138945., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(2137524.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(2138086.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(2136673.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(2137411., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(2136030.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(2136928.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(2135592.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(2136625.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(2135339., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(2137322.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(2136053.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(2137912.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(2136635.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(2138372.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(2137073.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(2138696.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(2137365.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(2138888.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(2137519., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(2138963., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(2137555.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(2138939., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(2137497.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(2138840.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(2137371.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(2138692., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(2137202.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(2138517.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(2137000.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(2139219.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(2137671., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(2139681., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(2138068., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(2139902.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(2138220.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(2139919.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(2138173.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(2139777., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(2137949., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(2139501.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(2137653.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(2139181., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(2137312., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(2138839.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(2136965., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(2138508.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(2136640.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(2138209.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(2136361.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(2137959.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(2136135.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(2137759.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(2135964.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(2137613.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(2135848.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(2137516.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(2134229.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(2136239.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(2133130.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(2135417.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(2132488.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(2134987.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(2132230.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(2134875.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(2132277., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(2135015.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(2134081.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(2136571., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(2135643.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(2137867., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(2136897.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(2138858.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(2137828., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(2139543.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(2138411.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(2139918.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(2138674.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(2140019., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(2138670., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(2139901., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(2138460.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(2139626., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(2138095.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(2139240.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(2137660.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(2138817., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(2137207.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(2138397.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(2136777., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(2138014.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(2136398.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(2137686.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(2136086., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(2137425., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(2135846.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(2137231.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(2135680., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(2137104.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(2134028.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(2135814.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(2132915.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(2134992.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(2132271.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(2134569.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(2132018.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(2134472.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(2132076.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(2134627.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(2133891.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(2136198., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(2135462.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(2137508.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(2136726.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(2138514., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(2137647.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(2139197.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(2138244.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(2139587.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(2138520., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(2139703., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(2138518.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(2139592.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(2138294.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(2139311.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(2137939., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(2138938., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(2137512.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(2138526., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(2137067.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(2138115.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(2136643.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(2137741.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(2136269.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(2137419.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(2135966.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(2137169., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(2135716.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(2136969.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(2135541.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(2136838., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(2133884.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(2135546.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(2132768.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(2134726., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(2132123.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(2134305., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(2131870., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(2134210., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(2131926.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(2134368.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(2133741.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(2135938.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(2135308.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(2137246.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(2136559.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(2138242.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(2137486.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(2138932.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(2138086.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(2139328.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(2138348., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(2139434.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(2138360.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(2139338.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(2138149., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(2139069., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(2137786., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(2138690.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(2137353.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(2138276., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(2136905.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(2137866.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(2136479.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(2137605., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(2136209.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(2137362., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(2135967.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(2137150.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(2135764.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(2136979.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(2135606.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(2136851., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(2135492.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(2137645.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(2136249., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(2138207.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(2136755.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(2138543.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(2137028.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(2138682.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(2137104.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(2138657., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(2137021.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(2139047.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(2137344.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(2139205.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(2138267.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(2139835.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(2138748.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(2140085., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(2138837.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(2140012.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(2138606., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(2139693.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(2138158.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(2139221.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(2137607.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(2138692.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(2135439., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(2136940., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(2133840.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(2135696.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(2132760., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(2134902., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(2132125., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(2134482.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(2131853.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(2134362.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(2131865.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(2134470.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(2132079.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(2134733., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(2132435.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(2135103.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(2134421.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(2136761.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(2136005., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(2138026., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(2137145.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(2138879., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(2137852.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(2139348.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(2138172.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(2139488.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(2138171.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(2139371.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(2137933., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(2139072.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(2137539., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(2138667., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(2137051.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(2139155.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(2137411.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(2139335.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(2137467.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(2139268.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(2137295.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(2139027.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(2136968.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(2139225., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(2137049.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(2139185., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(2136907.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(2138974., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(2136615.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(2138656.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(2134649.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(2137070.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(2133213.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(2135955., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(2132247.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(2135245.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(2131680.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(2134871., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(2131434.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(2134760.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(2131436.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(2134846.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(2131615.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(2135069.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(2131912.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(2135376.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(2132274.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(2135727.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(2134219.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(2137317., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(2135681.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(2138451.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(2136658., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(2139150.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(2137187.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(2139465.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(2137340.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(2139471., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(2137203.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(2139249.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(2136863., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(2138882.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(2136405.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(2138440.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(2135898.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(2137986.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(2133817.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(2136345., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(2132339., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(2135228.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(2131382.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(2134553.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(2130858.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(2134300.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(2130730.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(2134301.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(2130837.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(2134484.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(2131106.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(2134790.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(2131477.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(2135163.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(2131896., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(2135560.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(2133883.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(2137186.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(2135369., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(2138342., grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(2136355.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(2139048.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(2136884.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(2139361.7500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(2137027.5000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(2139358.5000, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-5, 15)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch regression', marker=\"o\", markersize=3)\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 20, 'Training Error=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 500)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.5, 1.5, 500) * np.exp(x)                    # 指数関数を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(500), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 60)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(60), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(0.3911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(7.3715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(48.9627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.0767, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-5, 15)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch regression', marker=\"o\", markersize=3)\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 20, 'Training Error=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(-5, 15, 100)                                  # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.tanh(x)                   # tanh関数を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 60)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(60), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(0.2245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(47.9881, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(0.3668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.7150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.3374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.2665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.2279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.2198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.2172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.2163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.2154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.2147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.2141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.2135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.2124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.2116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.2105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.2100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.2096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.2092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.2091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.2082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.2078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.2076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.2075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.2069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.2067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.2061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.2057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.2056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.2046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.2043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.2037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.2024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.2023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.2022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.2020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.2019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.2018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.2017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.2015, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.2015, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.2012, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.2013, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.2010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.2010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.2008, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.2008, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.2005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.2005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.2001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.2001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.1999, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.1998, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.1997, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.1998, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.1995, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.1994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.1994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.1992, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.1991, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.1990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.1990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.1987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.1987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.1988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.1985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.1985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.1984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.1983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.1983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.1986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.1985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.1989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.1994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.2008, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.2018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.2071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.2137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.2137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.2208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.2149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.2181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.2095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.2090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.2033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.2006, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.1999, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.1987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.1984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.1976, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.1973, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.1970, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.1965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.1963, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.1970, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.1975, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.1990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.1999, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.2024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.2072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.2079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.2094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.2053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.2054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.2017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.2012, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.1989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.1986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.1971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.1954, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.1954, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.1955, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.1978, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.1980, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.1995, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.1995, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.2009, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.2007, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.2019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.2009, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.2015, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.2001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.2004, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.1988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.1989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.1976, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.1978, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.1969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.1965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.1972, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.1970, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.1979, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.1976, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.1982, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.1978, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.1984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.1977, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.1979, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.1971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.1974, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.1966, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.1968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.1956, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.1961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.1959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.1964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.1960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.1962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.1957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.1954, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.1955, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.1949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.1949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.1946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.1946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.1945, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.1948, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.1948, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.1948, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.1948, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.1953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.1951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.1950, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.1952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.1949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.1947, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.1945, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.1945, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.1943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.1941, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.1940, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.1939, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.1938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.1937, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.1934, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.1936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.1935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.1933, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.1931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.1931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.1930, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.1929, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.1928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.1927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.1927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.1926, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.1924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.1922, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.1923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.1921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.1922, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.1920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.1922, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.1920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.1920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.1919, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.1919, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.1918, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.1917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.1914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.1914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.1911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.1910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.1906, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.1907, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.1904, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.1901, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.1905, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.1904, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.1903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.1900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.1902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.1900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.1900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.1896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.1896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.1895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.1892, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.1892, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.1892, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.1891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.1893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.1887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.1887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.1878, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.1871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.1871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.1867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.1868, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.1865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.1868, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.1867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.1873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.1871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.1877, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.1875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.1879, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.1874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.1865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.1866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.1853, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.1852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.1841, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.1829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.1828, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.1821, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.1818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.1820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.1817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.1822, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.1829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.1823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.1827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.1800, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.1792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.1762, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.1747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.1728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.1718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.1696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.1699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.1704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.1717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.1728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.1748, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.1793, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.1813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.1844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.1859, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.1874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.1866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.1856, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.1824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.1768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.1744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.1721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.1708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.1693, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.1687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.1680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.1682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.1702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.1724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.1743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.1774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.1832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.1836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.1840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.1819, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.1799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.1765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.1739, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.1706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.1689, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.1666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.1641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.1632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.1635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.1634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.1644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.1650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.1668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.1681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.1707, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.1727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.1753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.1763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.1779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.1770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.1761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.1736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.1717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.1686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.1667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.1641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.1628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.1611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.1607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.1597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.1600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.1597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.1608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.1611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.1629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.1638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.1663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.1674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.1697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.1700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.1700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.1695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.1669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.1625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.1613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.1590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.1582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.1562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.1560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.1548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.1551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.1545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.1555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.1552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.1564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.1566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.1581, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.1586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.1603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.1604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.1615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.1609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.1610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.1594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.1584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.1562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.1521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.1508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.1500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.1492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.1490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.1490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.1494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.1503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.1511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.1524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.1530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.1543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.1548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.1554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.1553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.1547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.1536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.1525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.1512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.1498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.1487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.1474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.1467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.1458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.1448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.1453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.1472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.1485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.1491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.1503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.1505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.1499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.1483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.1451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.1395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.1386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.1387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.1475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.1492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.1478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.1437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.1418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.1392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.1377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.1349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.1336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.1335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.1328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.1333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.1348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.1435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.1452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.1471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.1472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.1447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.1432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.1343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.1316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.1303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.1299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.1309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.1329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.1347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.1359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.1382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.1390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.1394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.1390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.1363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.1353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.1328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.1319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.1297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.1288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.1307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.1314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.1329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.1332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.1345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.1345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.1350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.1325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.1301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.1309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.1261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.1284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.1273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.1237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.1147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.4960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(1.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.3222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.1537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.1383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.1339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.1305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.1190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.1166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.1142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.1135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.1128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.1097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.1078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.1036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.1031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.1021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.1012, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.1208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.1350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.1433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.1171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.1175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.1145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.1139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.1133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.1156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.1173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.1152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.1135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.1137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.1107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.1109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.1100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.1112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.1104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.1128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.1092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.1092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.1121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.1090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.1035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.1149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.1118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.1082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.1094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0998, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.1043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.1033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.1019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.1010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0992, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0973, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0993, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0978, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.1009, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0991, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0958, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0882, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0853, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0950, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0868, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0879, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0762, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0776, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0795, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0841, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0783, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0782, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0814, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0906, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0799, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0800, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0812, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0754, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0925, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0713, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0821, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0705, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0759, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0828, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.1279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0766, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0609, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0711, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0431, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0431, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0559, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0431, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# GIFアニメーションを作成\n",
    "def create_gif(in_dir, out_filename):\n",
    "    path_list = sorted(glob.glob(os.path.join(*[in_dir, '*'])))  # ファイルパスをソートしてリストする\n",
    "    imgs = []  # 画像をappendするための空配列を定義\n",
    "\n",
    "    # ファイルのフルパスからファイル名と拡張子を抽出\n",
    "    for i in range(len(path_list)):\n",
    "        img = Image.open(path_list[i])  # 画像ファイルを1つずつ開く\n",
    "        imgs.append(img)  # 画像をappendで配列に格納していく\n",
    "\n",
    "    # appendした画像配列をGIFにする。durationで持続時間、loopでループ数を指定可能。\n",
    "    imgs[0].save(out_filename,\n",
    "                 save_all=True, append_images=imgs[1:], optimize=False, duration=100, loop=0)\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "\n",
    "        #グラフ描画\n",
    "        X1 = np.arange(0, 11, 0.5)                                                # x軸を作成\n",
    "        X2 = np.arange(0, 11, 0.5)                                                # y軸を作成\n",
    "        X, Y = np.meshgrid(X1, X2)                                                # x軸とy軸からグリッドデータを作成\n",
    "\n",
    "        X2 = torch.from_numpy(X.ravel().astype(np.float32)).float()  # xをテンソルに変換\n",
    "        Y2 = torch.from_numpy(Y.ravel().astype(np.float32)).float() # xをテンソルに変換\n",
    "        Input = torch.stack([torch.ones(len(X.ravel())), X2, Y2], 1)  # xに切片用の定数1配列を結合\n",
    "\n",
    "        # 50計算毎にプロットを保存\n",
    "        if (i + 1) % 50 == 0:\n",
    "            Z = test(model, Input).reshape(X.shape)\n",
    "            plot_3d(x.T[1], x.T[2], y, X, Y, Z, losses, 'out', i+1)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy()  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot_3d(x1, x2, z, X, Y, Z, losses, dir, index):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x1')\n",
    "    ax1.set_ylabel('x2')\n",
    "    ax1.set_zlabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(0, 10)\n",
    "    ax1.set_ylim(0, 10)\n",
    "    ax1.set_zlim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 10)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter3D(x1, x2, z, label='dataset')\n",
    "    ax1.plot_wireframe(X, Y, Z, color='red', label='PyTorch result')\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.scatter(len(losses), losses[len(losses) - 1], color='red')\n",
    "    ax2.text(600, 0.3, 'Loss=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 0.5, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend(bbox_to_anchor=(0, 1), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # dirフォルダが無い時に新規作成\n",
    "    if os.path.exists(dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(dir)\n",
    "\n",
    "    # 画像保存パスを準備\n",
    "    path = os.path.join(*[dir, str(\"{:05}\".format(index)) + '.png'])\n",
    "\n",
    "    # 画像を保存する\n",
    "    plt.savefig(path)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x1 = np.random.uniform(0, 10, 30)                                     # ノイズを含んだx軸を作成\n",
    "x2 = np.random.uniform(0, 10, 30)                                     # ノイズを含んだy軸を作成\n",
    "grid_x, grid_y = np.meshgrid(x1, x2)                                  # Gridデータを作成\n",
    "z = np.sin(grid_x.ravel()) * np.cos(grid_y.ravel())                   # ノイズを含んだ平面点列データを作成\n",
    "\n",
    "grid_x = torch.from_numpy(grid_x.ravel().astype(np.float32)).float()  # grid_xをテンソルに変換\n",
    "grid_y = torch.from_numpy(grid_y.ravel().astype(np.float32)).float()  # grid_yをテンソルに変換\n",
    "z = torch.from_numpy(z.astype(np.float32)).float()                    # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(len(grid_x)), grid_x, grid_y], 1)  # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=z)\n",
    "\n",
    "# GIFアニメーションを作成する関数を実行する\n",
    "create_gif(in_dir='out', out_filename='pytorch-2d-sincos-regression.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(338.9090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(47.3075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(25.7988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(24.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(23.7143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(23.5018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(23.2987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(23.0980, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(22.8990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(22.7018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(22.5063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(22.3125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(22.1204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(21.9299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(21.7411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(21.5540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(21.3684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(21.1845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(21.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(20.8215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(20.6423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(20.4647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(20.2887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(20.1141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(19.9411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(19.7696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(19.5996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(19.4311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(19.2640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(19.0984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(18.9342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(18.7715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(18.6102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(18.4502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(18.2917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(18.1345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(17.9787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(17.8243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(17.6712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(17.5194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(17.3690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(17.2199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(17.0720, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(16.9255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(16.7802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(16.6362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(16.4934, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(16.3519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(16.2116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(16.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(15.9346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(15.7980, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(15.6625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(15.5282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(15.3951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(15.2631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(15.1323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(15.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(14.8740, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(14.7466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(14.6203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(14.4950, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(14.3709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(14.2478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(14.1258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(14.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(13.8850, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(13.7661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(13.6483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(13.5316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(13.4158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(13.3010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(13.1873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(13.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(12.9627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(12.8519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(12.7420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(12.6331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(12.5251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(12.4181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(12.3120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(12.2069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(12.1026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(11.9993, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(11.8968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(11.7953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(11.6946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(11.5948, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(11.4959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(11.3978, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(11.3006, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(11.2042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(11.1087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(11.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(10.9201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(10.8271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(10.7348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(10.6434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(10.5527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(10.4628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(10.3737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(10.2854, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(10.1979, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(10.1111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(10.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(9.9398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(9.8553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(9.7715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(9.6884, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(9.6060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(9.5244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(9.4435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(9.3633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(9.2837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(9.2049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(9.1267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(9.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(8.9725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(8.8964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(8.8209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(8.7461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(8.6719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(8.5984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(8.5255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(8.4533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(8.3817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(8.3107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(8.2403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(8.1706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(8.1014, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(8.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(7.9649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(7.8975, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(7.8308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(7.7646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(7.6989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(7.6339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(7.5694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(7.5055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(7.4421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(7.3793, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(7.3170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(7.2553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(7.1941, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(7.1334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(7.0733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(7.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(6.9546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(6.8960, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(6.8379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(6.7804, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(6.7233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(6.6667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(6.6106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(6.5551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(6.4999, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(6.4453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(6.3912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(6.3375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(6.2843, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(6.2315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(6.1792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(6.1274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(6.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(6.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(5.9746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(5.9245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(5.8749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(5.8257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(5.7769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(5.7286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(5.6807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(5.6332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(5.5861, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(5.5394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(5.4931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(5.4472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(5.4018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(5.3567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(5.3120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(5.2677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(5.2238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(5.1803, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(5.1371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(5.0943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(5.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(5.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(4.9682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(4.9269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(4.8860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(4.8454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(4.8051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(4.7652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(4.7257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(4.6865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(4.6476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(4.6091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(4.5709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(4.5331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(4.4956, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(4.4584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(4.4215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(4.3849, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(4.3487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(4.3128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(4.2772, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(4.2419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(4.2069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(4.1722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(4.1378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(4.1037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(4.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(4.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(4.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(3.9703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(3.9377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(3.9053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(3.8732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(3.8415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(3.8099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(3.7787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(3.7477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(3.7171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(3.6866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(3.6565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(3.6266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(3.5969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(3.5675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(3.5384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(3.5095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(3.4809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(3.4525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(3.4244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(3.3965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(3.3689, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(3.3415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(3.3143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(3.2874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(3.2607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(3.2342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(3.2080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(3.1820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(3.1562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(3.1307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(3.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(3.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(3.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(3.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(3.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(2.9819, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(2.9579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(2.9341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(2.9105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(2.8870, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(2.8638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(2.8408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(2.8180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(2.7954, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(2.7730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(2.7508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(2.7287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(2.7069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(2.6853, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(2.6638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(2.6425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(2.6214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(2.6005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(2.5798, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(2.5593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(2.5389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(2.5187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(2.4987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(2.4789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(2.4592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(2.4397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(2.4204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(2.4013, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(2.3823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(2.3634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(2.3448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(2.3263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(2.3079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(2.2898, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(2.2718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(2.2539, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(2.2362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(2.2186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(2.2012, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(2.1840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(2.1669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(2.1499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(2.1331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(2.1165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(2.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(2.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(2.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(2.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(2.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(2.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(2.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(1.9883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(1.9729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(1.9577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(1.9425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(1.9275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(1.9127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(1.8979, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(1.8833, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(1.8688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(1.8545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(1.8402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(1.8261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(1.8122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(1.7983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(1.7845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(1.7709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(1.7574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(1.7440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(1.7307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(1.7176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(1.7045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(1.6916, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(1.6788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(1.6661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(1.6535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(1.6410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(1.6286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(1.6164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(1.6042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(1.5921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(1.5802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(1.5683, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(1.5566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(1.5450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(1.5334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(1.5220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(1.5106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(1.4994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(1.4882, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(1.4772, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(1.4662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(1.4554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(1.4446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(1.4339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(1.4234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(1.4129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(1.4025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(1.3922, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(1.3820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(1.3718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(1.3618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(1.3519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(1.3420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(1.3322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(1.3225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(1.3129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(1.3034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(1.2940, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(1.2846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(1.2753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(1.2661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(1.2570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(1.2480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(1.2390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(1.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(1.2213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(1.2126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(1.2039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(1.1954, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(1.1869, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(1.1784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(1.1701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(1.1618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(1.1536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(1.1454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(1.1374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(1.1294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(1.1214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(1.1136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(1.1058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(1.0981, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(1.0904, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(1.0828, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(1.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(1.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(1.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(1.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(1.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(1.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(1.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(1.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(1.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(1.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(1.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.9967, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.9900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.9832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.9766, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.9700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.9634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.9570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.9505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.9442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.9378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.9316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.9254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.9192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.9131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.9071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.9011, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.8951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.8892, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.8834, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.8776, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.8719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.8662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.8605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.8549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.8494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.8439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.8385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.8331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.8277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.8224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.8171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.8119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.8068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.8016, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.7966, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.7915, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.7865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.7816, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.7767, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.7718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.7670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.7622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.7575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.7528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.7481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.7435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.7389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.7344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.7299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.7255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.7210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.7167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.7123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.7080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.7038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.6995, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.6953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.6912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.6871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.6830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.6789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.6749, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.6710, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.6670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.6631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.6592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.6554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.6516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.6478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.6441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.6404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.6367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.6330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.6294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.6258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.6223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.6188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.6153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.6118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.6084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.6050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.6016, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.5983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.5950, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.5917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.5884, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.5852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.5820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.5788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.5757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.5726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.5695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.5664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.5634, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.5604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.5574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.5545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.5515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.5486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.5458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.5429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.5401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.5373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.5345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.5317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.5290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.5263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.5236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.5209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.5183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.5157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.5131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.5105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.5080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.5055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.5030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.5005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.4980, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.4956, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.4932, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.4908, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.4884, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.4860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.4837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.4814, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.4791, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.4768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.4746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.4723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.4701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.4679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.4657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.4636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.4614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.4593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.4572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.4551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.4531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.4510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.4490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.4470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.4450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.4430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.4410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.4391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.4372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.4353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.4334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.4315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.4296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.4278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.4260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.4241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.4223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.4206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.4188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.4171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.4153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.4136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.4119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.4102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.4085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.4069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.4052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.4036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.4020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.4004, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.3988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.3972, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.3956, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.3941, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.3926, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.3910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.3895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.3880, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.3865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.3851, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.3836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.3822, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.3807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.3793, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.3779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.3765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.3751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.3738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.3724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.3711, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.3697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.3684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.3671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.3658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.3645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.3632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.3620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.3607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.3595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.3582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.3570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.3558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.3546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.3534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.3522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.3510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.3499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.3487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.3476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.3465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.3453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.3442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.3431, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.3420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.3410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.3399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.3388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.3378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.3367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.3357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.3347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.3336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.3326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.3316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.3306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.3297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.3287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.3277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.3268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.3258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.3249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.3239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.3230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.3221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.3212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.3203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.3194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.3185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.3176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.3167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.3159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.3150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.3142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.3133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.3125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.3117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.3109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.3101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.3093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.3085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.3077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.3069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.3061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.3053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.3046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.3038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.3031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.3023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.3016, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.3009, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.3001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.2994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.2987, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.2980, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.2973, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.2966, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.2959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.2952, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.2946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.2939, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.2932, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.2926, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.2919, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.2913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.2906, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.2900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.2894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.2887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.2881, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.2875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.2869, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.2863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.2857, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.2851, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.2845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.2839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.2834, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.2828, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.2822, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.2816, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.2811, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.2805, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.2800, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.2794, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.2789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.2784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.2778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.2773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.2768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.2763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.2758, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.2753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.2748, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.2743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.2738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.2733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.2728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.2723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.2718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.2714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.2709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.2704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.2700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.2695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.2691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.2686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.2682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.2677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.2673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.2669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.2664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.2660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.2656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.2652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.2648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.2644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.2639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.2635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.2631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.2627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.2624, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.2620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.2616, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.2612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.2608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.2604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.2601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.2597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.2593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.2590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.2586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.2583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.2579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.2575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.2572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.2569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.2565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.2562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.2558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.2555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.2552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.2548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.2545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.2542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.2539, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.2536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.2533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.2529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.2526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.2523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.2520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.2517, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.2514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.2511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.2508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.2506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.2503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.2497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.2494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.2491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.2489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.2486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.2483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.2481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.2475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.2473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.2470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.2468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.2465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.2462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.2460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.2458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.2455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.2448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.2445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.2443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.2441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.2438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.2436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.2434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.2432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.2429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.2425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.2423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.2421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.2419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.2416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.2414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.2412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.2410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.2404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.2402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.2394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.2393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.2391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.2389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.2387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.2383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.2374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.2373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.2371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.2369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.2361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.2359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.2353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.2350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.2347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.2311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.2284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.2282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.2282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.2281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.2280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.2279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.2278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.2277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.2276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.2275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.2274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.2273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.2273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.2272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.2271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.2270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.2269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.2268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.2268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.2267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.2266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.2265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.2265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.2264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.2263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.2262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.2261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.2261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.2260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.2259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.2257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.2256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.2255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.2254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.2253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.2252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.2252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.2251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.2250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.2249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.2247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.2246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.2246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.2245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.2245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.2244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.2243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.2243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.2242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.2241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.2240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.2240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.2238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.2237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.2237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.2235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.2235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.2234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.2234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.2233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.2231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.2231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.2230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.2229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.2229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.2228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.2228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.2226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.2226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.2225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.2225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.2225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.2224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.2224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.2223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.2223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.2223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.2222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.2222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.2221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.2221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.2221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.2220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.2220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.2218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.2218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.2217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.2217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.2217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.2215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.2215, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class LinearRegression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "# テスト関数\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-10, 20)\n",
    "    ax1.set_ylim(0, 30)\n",
    "    ax2.set_xlim(0, 1000)\n",
    "    ax2.set_ylim(0.1, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch result', marker=\"o\")\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 30, 'Loss=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 100)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.2, 1.9, 100) + x + 10                       # yを分散した線形データとして作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 15)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(15), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = LinearRegression(in_features=2, out_features=1)\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)                    # 最適化にSGDを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=1000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
