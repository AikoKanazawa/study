{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class LinearRegression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "    \n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(377.9245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(74.9872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(34.9381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(29.4102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(28.4178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(28.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(27.7114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(27.4124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(27.1180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(26.8270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(26.5391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(26.2543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(25.9727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(25.6940, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(25.4184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(25.1458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(24.8761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(24.6094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(24.3455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(24.0845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(23.8263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(23.5709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(23.3183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(23.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(22.8212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(22.5767, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(22.3348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(22.0955, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(21.8589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(21.6248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(21.3932, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(21.1641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(20.9376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(20.7134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(20.4917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(20.2724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(20.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(19.8409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(19.6286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(19.4187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(19.2110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(19.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(18.8023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(18.6013, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(18.4024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(18.2057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(18.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(17.8187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(17.6283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(17.4400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(17.2537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(17.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(16.8872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(16.7069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(16.5286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(16.3521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(16.1776, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(16.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(15.8343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(15.6654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(15.4983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(15.3330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(15.1696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(15.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(14.8479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(14.6897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(14.5331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(14.3783, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(14.2252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(14.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(13.9239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(13.7756, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(13.6290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(13.4840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(13.3405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(13.1986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(13.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(12.9194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(12.7820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(12.6461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(12.5117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(12.3788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(12.2473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(12.1172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(11.9885, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(11.8613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(11.7354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(11.6108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(11.4876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(11.3658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(11.2452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(11.1260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(11.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(10.8914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(10.7760, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(10.6618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(10.5489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(10.4372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(10.3267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(10.2174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(10.1093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(10.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(9.8966, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(9.7919, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(9.6884, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(9.5860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(9.4848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(9.3846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(9.2855, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(9.1875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(9.0905, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(8.9946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(8.8997, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(8.8058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(8.7130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(8.6212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(8.5303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(8.4405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(8.3516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(8.2637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(8.1767, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(8.0907, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(8.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(7.9214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(7.8382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(7.7558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(7.6743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(7.5937, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(7.5140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(7.4352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(7.3572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(7.2800, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(7.2037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(7.1282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(7.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(6.9796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(6.9066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(6.8343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(6.7628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(6.6921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(6.6221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(6.5529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(6.4845, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(6.4167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(6.3498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(6.2835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(6.2180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(6.1531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(6.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(6.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(5.9628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(5.9008, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(5.8394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(5.7787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(5.7186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(5.6592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(5.6004, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(5.5422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(5.4847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(5.4278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(5.3716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(5.3159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(5.2608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(5.2064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(5.1525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(5.0992, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(5.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(4.9943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(4.9427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(4.8917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(4.8412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(4.7913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(4.7419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(4.6931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(4.6447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(4.5969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(4.5496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(4.5029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(4.4566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(4.4108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(4.3656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(4.3208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(4.2765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(4.2327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(4.1893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(4.1465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(4.1041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(4.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(4.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(3.9796, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(3.9390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(3.8988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(3.8591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(3.8198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(3.7809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(3.7425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(3.7044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(3.6668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(3.6296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(3.5928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(3.5563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(3.5203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(3.4847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(3.4494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(3.4146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(3.3801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(3.3460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(3.3122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(3.2789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(3.2458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(3.2132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(3.1809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(3.1489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(3.1173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(3.0860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(3.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(3.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(2.9942, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(2.9643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(2.9347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(2.9054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(2.8764, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(2.8477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(2.8194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(2.7913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(2.7636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(2.7362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(2.7090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(2.6822, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(2.6556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(2.6293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(2.6033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(2.5776, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(2.5522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(2.5271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(2.5022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(2.4776, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(2.4532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(2.4291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(2.4053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(2.3817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(2.3584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(2.3354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(2.3126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(2.2900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(2.2677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(2.2456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(2.2238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(2.2022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(2.1808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(2.1597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(2.1388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(2.1181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(2.0976, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(2.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(2.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(2.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(2.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(1.9986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(1.9795, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(1.9605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(1.9418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(1.9232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(1.9049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(1.8867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(1.8688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(1.8510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(1.8334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(1.8161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(1.7989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(1.7819, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(1.7651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(1.7484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(1.7320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(1.7157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(1.6996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(1.6837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(1.6679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(1.6523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(1.6369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(1.6217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(1.6066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(1.5917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(1.5769, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(1.5623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(1.5479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(1.5336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(1.5194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(1.5055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(1.4916, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(1.4780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(1.4644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(1.4511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(1.4378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(1.4247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(1.4118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(1.3990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(1.3863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(1.3738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(1.3614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(1.3491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(1.3370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(1.3249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(1.3131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(1.3013, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(1.2897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(1.2782, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(1.2669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(1.2556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(1.2445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(1.2335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(1.2226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(1.2118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(1.2012, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(1.1907, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(1.1802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(1.1699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(1.1597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(1.1497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(1.1397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(1.1298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(1.1201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(1.1104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(1.1009, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(1.0914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(1.0821, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(1.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(1.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(1.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(1.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(1.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(1.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(1.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(1.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(1.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.9940, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.9857, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.9775, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.9694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.9614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.9534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.9456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.9378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.9301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.9225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.9150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.9076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.9002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.8930, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.8858, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.8786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.8716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.8646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.8577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.8509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.8442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.8375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.8309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.8244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.8179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.8116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.8052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.7990, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.7928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.7867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.7806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.7747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.7687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.7629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.7571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.7514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.7457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.7401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.7346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.7291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.7237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.7183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.7130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.7077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.7026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.6974, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.6923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.6873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.6823, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.6774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.6726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.6677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.6630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.6583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.6536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.6490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.6445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.6399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.6355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.6311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.6267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.6224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.6181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.6139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.6097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.6056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.6015, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.5975, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.5935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.5895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.5856, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.5817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.5779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.5741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.5704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.5667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.5630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.5594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.5558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.5522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.5487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.5453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.5418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.5384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.5351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.5317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.5285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.5252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.5220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.5188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.5157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.5125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.5095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.5064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.5034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.5004, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.4975, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.4946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.4917, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.4888, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.4860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.4832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.4804, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.4777, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.4750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.4723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.4697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.4671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.4645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.4619, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.4594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.4569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.4544, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.4520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.4495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.4471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.4448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.4424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.4401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.4378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.4355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.4333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.4311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.4289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.4267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.4245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.4224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.4203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.4182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.4162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.4141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.4121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.4101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.4082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.4062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.4043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.4024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.4005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.3986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.3968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.3949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.3931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.3913, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.3896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.3878, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.3861, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.3844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.3827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.3810, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.3794, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.3777, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.3761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.3745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.3729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.3713, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.3698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.3683, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.3667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.3652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.3638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.3623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.3608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.3594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.3580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.3566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.3552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.3538, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.3524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.3511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.3498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.3484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.3471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.3458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.3446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.3433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.3421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.3408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.3396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.3384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.3372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.3360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.3348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.3337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.3325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.3314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.3303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.3292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.3281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.3270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.3259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.3249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.3238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.3228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.3218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.3207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.3197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.3187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.3178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.3168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.3158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.3149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.3139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.3130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.3121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.3112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.3103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.3094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.3085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.3076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.3068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.3059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.3051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.3042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.3034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.3026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.3018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.3010, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.3002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.2994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.2986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.2979, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.2971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.2964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.2956, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.2949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.2942, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.2935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.2928, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.2921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.2914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.2907, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.2900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.2893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.2887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.2880, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.2874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.2867, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.2861, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.2854, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.2848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.2842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.2836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.2830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.2824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.2818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.2812, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.2807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.2801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.2795, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.2790, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.2784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.2779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.2773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.2768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.2763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.2757, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.2752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.2747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.2742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.2737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.2732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.2727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.2722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.2718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.2713, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.2708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.2704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.2699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.2694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.2690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.2685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.2681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.2677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.2672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.2668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.2664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.2660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.2656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.2652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.2648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.2644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.2640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.2636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.2632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.2628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.2624, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.2621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.2617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.2613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.2610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.2606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.2603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.2599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.2596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.2592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.2589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.2585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.2582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.2579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.2576, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.2572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.2569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.2566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.2563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.2560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.2557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.2554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.2551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.2548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.2545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.2542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.2539, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.2537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.2534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.2531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.2528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.2526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.2523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.2520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.2518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.2515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.2513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.2510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.2508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.2505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.2503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.2500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.2498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.2496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.2493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.2491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.2489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.2486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.2484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.2482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.2480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.2475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.2473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.2471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.2469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.2467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.2465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.2463, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.2461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.2459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.2457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.2455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.2453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.2451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.2450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.2448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.2446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.2444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.2442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.2441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.2439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.2437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.2435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.2434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.2432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.2429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.2427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.2426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.2424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.2422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.2421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.2419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.2418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.2416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.2415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.2413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.2412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.2411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.2409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.2408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.2406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.2405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.2404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.2402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.2401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.2400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.2398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.2397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.2395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.2393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.2392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.2391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.2390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.2388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.2387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.2386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.2385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.2384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.2383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.2382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.2379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.2378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.2377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.2376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.2375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.2374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.2373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.2372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.2371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.2369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.2368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.2367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.2363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.2362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.2361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.2360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.2359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.2358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.2357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.2356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.2354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.2353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.2351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.2350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.2349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.2348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.2347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.2346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.2346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.2343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.2342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.2341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.2339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.2337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.2336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.2335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.2334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.2333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.2332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.2332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.2330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.2328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.2327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.2326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.2325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.2324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.2322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.2321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.2320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.2319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.2317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.2316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.2315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.2313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.2312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.2311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.2311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.2310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.2309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.2307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.2306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.2305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.2304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.2303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.2302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.2301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.2300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.2298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.2297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.2296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.2295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.2294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.2293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.2290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.2289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.2288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.2287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.2286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.2285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.2285, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class LinearRegression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self, in_features, out_features, bias=False):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "# テスト関数\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-10, 20)\n",
    "    ax1.set_ylim(0, 30)\n",
    "    ax2.set_xlim(0, 1000)\n",
    "    ax2.set_ylim(0.1, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch result', marker=\"o\")\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 30, 'Loss=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 100)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.2, 1.9, 100) + x + 10                       # yを分散した線形データとして作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 15)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(15), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = LinearRegression(in_features=2, out_features=1)\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)                    # 最適化にSGDを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=1000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 100)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.sin(2 * np.pi * 0.1 * x)  # 正弦波を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(1.0989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(1.1563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(3.4123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.5520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.4800, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.3860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.2884, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.1381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.1971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.2227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.0850, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.1669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.1040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.1102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.1331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.0996, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.0779, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.0725, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.0701, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.1380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.1213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.0764, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.0827, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.1025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.0954, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.1181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.1034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.0930, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.0925, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.0921, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.0957, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.0775, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.0744, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.0432, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.0473, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.0602, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-5, 15)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch regression', marker=\"o\", markersize=3)\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.text(600, 20, 'Training Error=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 100)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.sin(2 * np.pi * 0.1 * x)  # 正弦波を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 60)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(60), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=y)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "plot(x, y, X_test.data.numpy().T[1], y_pred, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(0.7252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(4.2278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(2.3543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.5191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.3808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.2758, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.2213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.2365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.2314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.1555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.1385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.1257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.1183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.0869, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.0805, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.0791, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.0544, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.0523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.0485, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.0449, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.0384, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.0373, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.0381, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0094, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0080, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0043, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# GIFアニメーションを作成\n",
    "def create_gif(in_dir, out_filename):\n",
    "    path_list = sorted(glob.glob(os.path.join(*[in_dir, '*'])))  # ファイルパスをソートしてリストする\n",
    "    imgs = []  # 画像をappendするための空配列を定義\n",
    "\n",
    "    # ファイルのフルパスからファイル名と拡張子を抽出\n",
    "    for i in range(len(path_list)):\n",
    "        img = Image.open(path_list[i])  # 画像ファイルを1つずつ開く\n",
    "        imgs.append(img)  # 画像をappendで配列に格納していく\n",
    "\n",
    "    # appendした画像配列をGIFにする。durationで持続時間、loopでループ数を指定可能。\n",
    "    imgs[0].save(out_filename,\n",
    "                 save_all=True, append_images=imgs[1:], optimize=False, duration=100, loop=0)\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class LinearRegression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y, X_test, x_plot):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "\n",
    "        # 50計算毎にプロットを保存\n",
    "        if (i + 1) % 50 == 0:\n",
    "            # グラフ描画\n",
    "            y_test = test(model, X_test)\n",
    "            plot(x_plot, y.data.numpy(), X_test.data.numpy().T[1], y_test, losses, 'out', i+1)\n",
    "\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy().T[0]  # 予測\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot(x, y, x_new, y_pred, losses, dir, index):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(-5, 15)\n",
    "    ax1.set_ylim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 100)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter(x, y, label='dataset')\n",
    "    ax1.plot(x_new, y_pred, color='red', label='PyTorch regression', marker=\"o\", markersize=3)\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.scatter(len(losses), losses[len(losses) - 1], color='red')\n",
    "    ax2.text(600, 20, 'Training Error=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 50, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend(bbox_to_anchor=(0, 1), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # dirフォルダが無い時に新規作成\n",
    "    if os.path.exists(dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(dir)\n",
    "\n",
    "    # 画像保存パスを準備\n",
    "    path = os.path.join(*[dir, str(\"{:05}\".format(index)) + '.png'])\n",
    "\n",
    "    # 画像を保存する\n",
    "    plt.savefig(path)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 100)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.sin(2 * np.pi * 0.1 * x)  # 正弦波を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合\n",
    "\n",
    "# テストデータ\n",
    "x_test = np.linspace(-5, 15, 60)                                    # x軸を作成\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).float()        # xをテンソルに変換\n",
    "X_test = torch.stack([torch.ones(60), x_test], 1)                   # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = LinearRegression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=y,\n",
    "                    X_test=X_test, x_plot=x)\n",
    "\n",
    "# テスト\n",
    "y_pred = test(net, X_test)\n",
    "\n",
    "# グラフ描画\n",
    "#plot(x, y, X_test.data.numpy().T[1], y_pred, losses, 'out2', 0)\n",
    "\n",
    "# GIFアニメーションを作成する関数を実行する\n",
    "create_gif(in_dir='out', out_filename='pytorch-sinewave-regression.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ\n",
    "x = np.random.uniform(-5, 15, 100)                                  # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.sin(2 * np.pi * 0.1 * x)  # 正弦波を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ\n",
    "x = np.random.uniform(0, 10, 500)                                   # x軸をランダムで作成\n",
    "y = np.random.uniform(0.5, 1.5, 500) * np.exp(x)                    # 指数関数を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(500), x], 1)                            # xに切片用の定数1配列を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ\n",
    "x = np.random.uniform(-5, 15, 100)                                  # x軸をランダムで作成\n",
    "y = np.random.uniform(0.9, 1.1, 100) * np.tanh(x)                   # tanh関数を作成\n",
    "x = torch.from_numpy(x.astype(np.float32)).float()                  # xをテンソルに変換\n",
    "y = torch.from_numpy(y.astype(np.float32)).float()                  # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(100), x], 1)                            # xに切片用の定数1配列を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ\n",
    "x1 = np.random.uniform(0, 10, 30)                                     # ノイズを含んだx軸を作成\n",
    "x2 = np.random.uniform(0, 10, 30)                                     # ノイズを含んだy軸を作成\n",
    "grid_x, grid_y = np.meshgrid(x1, x2)                                  # Gridデータを作成\n",
    "z = np.sin(grid_x.ravel()) * np.cos(grid_y.ravel())                   # ノイズを含んだ平面点列データを作成\n",
    "\n",
    "grid_x = torch.from_numpy(grid_x.ravel().astype(np.float32)).float()  # grid_xをテンソルに変換\n",
    "grid_y = torch.from_numpy(grid_y.ravel().astype(np.float32)).float()  # grid_yをテンソルに変換\n",
    "z = torch.from_numpy(z.astype(np.float32)).float()                    # zをテンソルに変換\n",
    "X = torch.stack([torch.ones(len(grid_x)), grid_x, grid_y], 1)  # xに切片用の定数1配列を結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 loss= tensor(0.1428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2 loss= tensor(11.2704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3 loss= tensor(7.4635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4 loss= tensor(0.1925, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5 loss= tensor(0.1771, grad_fn=<MseLossBackward0>)\n",
      "epoch= 6 loss= tensor(0.1682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 7 loss= tensor(0.1623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 8 loss= tensor(0.1582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 9 loss= tensor(0.1550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 10 loss= tensor(0.1523, grad_fn=<MseLossBackward0>)\n",
      "epoch= 11 loss= tensor(0.1501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 12 loss= tensor(0.1482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 13 loss= tensor(0.1465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 14 loss= tensor(0.1449, grad_fn=<MseLossBackward0>)\n",
      "epoch= 15 loss= tensor(0.1436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 16 loss= tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 17 loss= tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 18 loss= tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 19 loss= tensor(0.1396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 20 loss= tensor(0.1389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 21 loss= tensor(0.1382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 22 loss= tensor(0.1376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 23 loss= tensor(0.1371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 24 loss= tensor(0.1366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 25 loss= tensor(0.1361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 26 loss= tensor(0.1356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 27 loss= tensor(0.1352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 28 loss= tensor(0.1348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 29 loss= tensor(0.1344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 30 loss= tensor(0.1340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 31 loss= tensor(0.1337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 32 loss= tensor(0.1334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 33 loss= tensor(0.1330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 34 loss= tensor(0.1327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 35 loss= tensor(0.1324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 36 loss= tensor(0.1322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 37 loss= tensor(0.1319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 38 loss= tensor(0.1317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 39 loss= tensor(0.1314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 40 loss= tensor(0.1312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 41 loss= tensor(0.1310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 42 loss= tensor(0.1308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 43 loss= tensor(0.1306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 44 loss= tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 45 loss= tensor(0.1302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 46 loss= tensor(0.1301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 47 loss= tensor(0.1299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 48 loss= tensor(0.1298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 49 loss= tensor(0.1296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 50 loss= tensor(0.1295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 51 loss= tensor(0.1294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 52 loss= tensor(0.1293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 53 loss= tensor(0.1292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 54 loss= tensor(0.1291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 55 loss= tensor(0.1290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 56 loss= tensor(0.1289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 57 loss= tensor(0.1288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 58 loss= tensor(0.1287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 59 loss= tensor(0.1286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 60 loss= tensor(0.1285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 61 loss= tensor(0.1284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 62 loss= tensor(0.1283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 63 loss= tensor(0.1282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 64 loss= tensor(0.1281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 65 loss= tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 66 loss= tensor(0.1280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 67 loss= tensor(0.1279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 68 loss= tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 69 loss= tensor(0.1278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 70 loss= tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 71 loss= tensor(0.1277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 72 loss= tensor(0.1276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 73 loss= tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 74 loss= tensor(0.1275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 75 loss= tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 76 loss= tensor(0.1274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 77 loss= tensor(0.1273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 78 loss= tensor(0.1273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 79 loss= tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 80 loss= tensor(0.1272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 81 loss= tensor(0.1271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 82 loss= tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 83 loss= tensor(0.1270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 84 loss= tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 85 loss= tensor(0.1269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 86 loss= tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 87 loss= tensor(0.1268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 88 loss= tensor(0.1267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 89 loss= tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 90 loss= tensor(0.1266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 91 loss= tensor(0.1265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 92 loss= tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 93 loss= tensor(0.1264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 94 loss= tensor(0.1263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 95 loss= tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 96 loss= tensor(0.1262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 97 loss= tensor(0.1261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 98 loss= tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 99 loss= tensor(0.1260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 100 loss= tensor(0.1259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 101 loss= tensor(0.1258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 102 loss= tensor(0.1257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 103 loss= tensor(0.1256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 104 loss= tensor(0.1255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 105 loss= tensor(0.1255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 106 loss= tensor(0.1254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 107 loss= tensor(0.1253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 108 loss= tensor(0.1252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 109 loss= tensor(0.1251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 110 loss= tensor(0.1250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 111 loss= tensor(0.1249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 112 loss= tensor(0.1248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 113 loss= tensor(0.1247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 114 loss= tensor(0.1246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 115 loss= tensor(0.1245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 116 loss= tensor(0.1244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 117 loss= tensor(0.1243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 118 loss= tensor(0.1242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 119 loss= tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 120 loss= tensor(0.1241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 121 loss= tensor(0.1240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 122 loss= tensor(0.1239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 123 loss= tensor(0.1238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 124 loss= tensor(0.1237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 125 loss= tensor(0.1236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 126 loss= tensor(0.1235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 127 loss= tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 128 loss= tensor(0.1233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 129 loss= tensor(0.1232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 130 loss= tensor(0.1232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 131 loss= tensor(0.1231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 132 loss= tensor(0.1230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 133 loss= tensor(0.1229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 134 loss= tensor(0.1228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 135 loss= tensor(0.1227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 136 loss= tensor(0.1226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 137 loss= tensor(0.1225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 138 loss= tensor(0.1224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 139 loss= tensor(0.1223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 140 loss= tensor(0.1222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 141 loss= tensor(0.1221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 142 loss= tensor(0.1220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 143 loss= tensor(0.1219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 144 loss= tensor(0.1216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 145 loss= tensor(0.1214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 146 loss= tensor(0.1211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 147 loss= tensor(0.1205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 148 loss= tensor(0.1203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 149 loss= tensor(0.1202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 150 loss= tensor(0.1199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 151 loss= tensor(0.1197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 152 loss= tensor(0.1196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 153 loss= tensor(0.1192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 154 loss= tensor(0.1191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 155 loss= tensor(0.1188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 156 loss= tensor(0.1186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 157 loss= tensor(0.1184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 158 loss= tensor(0.1182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 159 loss= tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 160 loss= tensor(0.1178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 161 loss= tensor(0.1176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 162 loss= tensor(0.1174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 163 loss= tensor(0.1172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 164 loss= tensor(0.1170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 165 loss= tensor(0.1168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 166 loss= tensor(0.1167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 167 loss= tensor(0.1164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 168 loss= tensor(0.1162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 169 loss= tensor(0.1161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 170 loss= tensor(0.1159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 171 loss= tensor(0.1157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 172 loss= tensor(0.1155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 173 loss= tensor(0.1153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 174 loss= tensor(0.1151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 175 loss= tensor(0.1150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 176 loss= tensor(0.1148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 177 loss= tensor(0.1146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 178 loss= tensor(0.1144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 179 loss= tensor(0.1143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 180 loss= tensor(0.1141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 181 loss= tensor(0.1139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 182 loss= tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 183 loss= tensor(0.1136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 184 loss= tensor(0.1134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 185 loss= tensor(0.1132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 186 loss= tensor(0.1131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 187 loss= tensor(0.1129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 188 loss= tensor(0.1127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 189 loss= tensor(0.1125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 190 loss= tensor(0.1124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 191 loss= tensor(0.1122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 192 loss= tensor(0.1120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 193 loss= tensor(0.1119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 194 loss= tensor(0.1117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 195 loss= tensor(0.1116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 196 loss= tensor(0.1114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 197 loss= tensor(0.1113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 198 loss= tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 199 loss= tensor(0.1110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 200 loss= tensor(0.1108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 201 loss= tensor(0.1106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 202 loss= tensor(0.1105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 203 loss= tensor(0.1103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 204 loss= tensor(0.1101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 205 loss= tensor(0.1099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 206 loss= tensor(0.1098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 207 loss= tensor(0.1096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 208 loss= tensor(0.1095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 209 loss= tensor(0.1093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 210 loss= tensor(0.1092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 211 loss= tensor(0.1091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 212 loss= tensor(0.1089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 213 loss= tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 214 loss= tensor(0.1087, grad_fn=<MseLossBackward0>)\n",
      "epoch= 215 loss= tensor(0.1085, grad_fn=<MseLossBackward0>)\n",
      "epoch= 216 loss= tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 217 loss= tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 218 loss= tensor(0.1083, grad_fn=<MseLossBackward0>)\n",
      "epoch= 219 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 220 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 221 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 222 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 223 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 224 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 225 loss= tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 226 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 227 loss= tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 228 loss= tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 229 loss= tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 230 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 231 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 232 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 233 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 234 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 235 loss= tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 236 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 237 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 238 loss= tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 239 loss= tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 240 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 241 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 242 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 243 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 244 loss= tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 245 loss= tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 246 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 247 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 248 loss= tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 249 loss= tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 250 loss= tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 251 loss= tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 252 loss= tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 253 loss= tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 254 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 255 loss= tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 256 loss= tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 257 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 258 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 259 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 260 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 261 loss= tensor(0.1051, grad_fn=<MseLossBackward0>)\n",
      "epoch= 262 loss= tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 263 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 264 loss= tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 265 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 266 loss= tensor(0.1046, grad_fn=<MseLossBackward0>)\n",
      "epoch= 267 loss= tensor(0.1049, grad_fn=<MseLossBackward0>)\n",
      "epoch= 268 loss= tensor(0.1047, grad_fn=<MseLossBackward0>)\n",
      "epoch= 269 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 270 loss= tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 271 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 272 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 273 loss= tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 274 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 275 loss= tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 276 loss= tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 277 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 278 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 279 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 280 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 281 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 282 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 283 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 284 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 285 loss= tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 286 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 287 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 288 loss= tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 289 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 290 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 291 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 292 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 293 loss= tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 294 loss= tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 295 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 296 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 297 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 298 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 299 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 300 loss= tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 301 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 302 loss= tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 303 loss= tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 304 loss= tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 305 loss= tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 306 loss= tensor(0.1075, grad_fn=<MseLossBackward0>)\n",
      "epoch= 307 loss= tensor(0.1078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 308 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 309 loss= tensor(0.1088, grad_fn=<MseLossBackward0>)\n",
      "epoch= 310 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 311 loss= tensor(0.1081, grad_fn=<MseLossBackward0>)\n",
      "epoch= 312 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 313 loss= tensor(0.1086, grad_fn=<MseLossBackward0>)\n",
      "epoch= 314 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 315 loss= tensor(0.1078, grad_fn=<MseLossBackward0>)\n",
      "epoch= 316 loss= tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 317 loss= tensor(0.1084, grad_fn=<MseLossBackward0>)\n",
      "epoch= 318 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 319 loss= tensor(0.1073, grad_fn=<MseLossBackward0>)\n",
      "epoch= 320 loss= tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 321 loss= tensor(0.1079, grad_fn=<MseLossBackward0>)\n",
      "epoch= 322 loss= tensor(0.1071, grad_fn=<MseLossBackward0>)\n",
      "epoch= 323 loss= tensor(0.1072, grad_fn=<MseLossBackward0>)\n",
      "epoch= 324 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 325 loss= tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 326 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 327 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 328 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 329 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 330 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 331 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 332 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 333 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 334 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 335 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 336 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 337 loss= tensor(0.1076, grad_fn=<MseLossBackward0>)\n",
      "epoch= 338 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 339 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 340 loss= tensor(0.1068, grad_fn=<MseLossBackward0>)\n",
      "epoch= 341 loss= tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "epoch= 342 loss= tensor(0.1069, grad_fn=<MseLossBackward0>)\n",
      "epoch= 343 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 344 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 345 loss= tensor(0.1074, grad_fn=<MseLossBackward0>)\n",
      "epoch= 346 loss= tensor(0.1067, grad_fn=<MseLossBackward0>)\n",
      "epoch= 347 loss= tensor(0.1064, grad_fn=<MseLossBackward0>)\n",
      "epoch= 348 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 349 loss= tensor(0.1070, grad_fn=<MseLossBackward0>)\n",
      "epoch= 350 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 351 loss= tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "epoch= 352 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 353 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 354 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 355 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 356 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 357 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 358 loss= tensor(0.1056, grad_fn=<MseLossBackward0>)\n",
      "epoch= 359 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 360 loss= tensor(0.1054, grad_fn=<MseLossBackward0>)\n",
      "epoch= 361 loss= tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 362 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 363 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 364 loss= tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 365 loss= tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 366 loss= tensor(0.1041, grad_fn=<MseLossBackward0>)\n",
      "epoch= 367 loss= tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 368 loss= tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 369 loss= tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 370 loss= tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 371 loss= tensor(0.1048, grad_fn=<MseLossBackward0>)\n",
      "epoch= 372 loss= tensor(0.1044, grad_fn=<MseLossBackward0>)\n",
      "epoch= 373 loss= tensor(0.1057, grad_fn=<MseLossBackward0>)\n",
      "epoch= 374 loss= tensor(0.1053, grad_fn=<MseLossBackward0>)\n",
      "epoch= 375 loss= tensor(0.1063, grad_fn=<MseLossBackward0>)\n",
      "epoch= 376 loss= tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 377 loss= tensor(0.1066, grad_fn=<MseLossBackward0>)\n",
      "epoch= 378 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 379 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 380 loss= tensor(0.1055, grad_fn=<MseLossBackward0>)\n",
      "epoch= 381 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 382 loss= tensor(0.1045, grad_fn=<MseLossBackward0>)\n",
      "epoch= 383 loss= tensor(0.1042, grad_fn=<MseLossBackward0>)\n",
      "epoch= 384 loss= tensor(0.1032, grad_fn=<MseLossBackward0>)\n",
      "epoch= 385 loss= tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 386 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 387 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 388 loss= tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 389 loss= tensor(0.1020, grad_fn=<MseLossBackward0>)\n",
      "epoch= 390 loss= tensor(0.1018, grad_fn=<MseLossBackward0>)\n",
      "epoch= 391 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 392 loss= tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 393 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 394 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 395 loss= tensor(0.1037, grad_fn=<MseLossBackward0>)\n",
      "epoch= 396 loss= tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 397 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 398 loss= tensor(0.1050, grad_fn=<MseLossBackward0>)\n",
      "epoch= 399 loss= tensor(0.1060, grad_fn=<MseLossBackward0>)\n",
      "epoch= 400 loss= tensor(0.1058, grad_fn=<MseLossBackward0>)\n",
      "epoch= 401 loss= tensor(0.1065, grad_fn=<MseLossBackward0>)\n",
      "epoch= 402 loss= tensor(0.1059, grad_fn=<MseLossBackward0>)\n",
      "epoch= 403 loss= tensor(0.1061, grad_fn=<MseLossBackward0>)\n",
      "epoch= 404 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 405 loss= tensor(0.1052, grad_fn=<MseLossBackward0>)\n",
      "epoch= 406 loss= tensor(0.1039, grad_fn=<MseLossBackward0>)\n",
      "epoch= 407 loss= tensor(0.1038, grad_fn=<MseLossBackward0>)\n",
      "epoch= 408 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 409 loss= tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 410 loss= tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 411 loss= tensor(0.1016, grad_fn=<MseLossBackward0>)\n",
      "epoch= 412 loss= tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "epoch= 413 loss= tensor(0.1013, grad_fn=<MseLossBackward0>)\n",
      "epoch= 414 loss= tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "epoch= 415 loss= tensor(0.1015, grad_fn=<MseLossBackward0>)\n",
      "epoch= 416 loss= tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "epoch= 417 loss= tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 418 loss= tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 419 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 420 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 421 loss= tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 422 loss= tensor(0.1023, grad_fn=<MseLossBackward0>)\n",
      "epoch= 423 loss= tensor(0.1027, grad_fn=<MseLossBackward0>)\n",
      "epoch= 424 loss= tensor(0.1026, grad_fn=<MseLossBackward0>)\n",
      "epoch= 425 loss= tensor(0.1029, grad_fn=<MseLossBackward0>)\n",
      "epoch= 426 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 427 loss= tensor(0.1030, grad_fn=<MseLossBackward0>)\n",
      "epoch= 428 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 429 loss= tensor(0.1028, grad_fn=<MseLossBackward0>)\n",
      "epoch= 430 loss= tensor(0.1024, grad_fn=<MseLossBackward0>)\n",
      "epoch= 431 loss= tensor(0.1022, grad_fn=<MseLossBackward0>)\n",
      "epoch= 432 loss= tensor(0.1017, grad_fn=<MseLossBackward0>)\n",
      "epoch= 433 loss= tensor(0.1014, grad_fn=<MseLossBackward0>)\n",
      "epoch= 434 loss= tensor(0.1011, grad_fn=<MseLossBackward0>)\n",
      "epoch= 435 loss= tensor(0.1008, grad_fn=<MseLossBackward0>)\n",
      "epoch= 436 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 437 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 438 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 439 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 440 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 441 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 442 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 443 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 444 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 445 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 446 loss= tensor(0.1000, grad_fn=<MseLossBackward0>)\n",
      "epoch= 447 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 448 loss= tensor(0.1003, grad_fn=<MseLossBackward0>)\n",
      "epoch= 449 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 450 loss= tensor(0.1006, grad_fn=<MseLossBackward0>)\n",
      "epoch= 451 loss= tensor(0.1007, grad_fn=<MseLossBackward0>)\n",
      "epoch= 452 loss= tensor(0.1005, grad_fn=<MseLossBackward0>)\n",
      "epoch= 453 loss= tensor(0.1004, grad_fn=<MseLossBackward0>)\n",
      "epoch= 454 loss= tensor(0.1002, grad_fn=<MseLossBackward0>)\n",
      "epoch= 455 loss= tensor(0.1001, grad_fn=<MseLossBackward0>)\n",
      "epoch= 456 loss= tensor(0.0997, grad_fn=<MseLossBackward0>)\n",
      "epoch= 457 loss= tensor(0.0994, grad_fn=<MseLossBackward0>)\n",
      "epoch= 458 loss= tensor(0.0989, grad_fn=<MseLossBackward0>)\n",
      "epoch= 459 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 460 loss= tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 461 loss= tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 462 loss= tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 463 loss= tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 464 loss= tensor(0.0982, grad_fn=<MseLossBackward0>)\n",
      "epoch= 465 loss= tensor(0.0986, grad_fn=<MseLossBackward0>)\n",
      "epoch= 466 loss= tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 467 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 468 loss= tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 469 loss= tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 470 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 471 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 472 loss= tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 473 loss= tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 474 loss= tensor(0.0985, grad_fn=<MseLossBackward0>)\n",
      "epoch= 475 loss= tensor(0.0983, grad_fn=<MseLossBackward0>)\n",
      "epoch= 476 loss= tensor(0.0988, grad_fn=<MseLossBackward0>)\n",
      "epoch= 477 loss= tensor(0.0984, grad_fn=<MseLossBackward0>)\n",
      "epoch= 478 loss= tensor(0.0979, grad_fn=<MseLossBackward0>)\n",
      "epoch= 479 loss= tensor(0.0972, grad_fn=<MseLossBackward0>)\n",
      "epoch= 480 loss= tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "epoch= 481 loss= tensor(0.0968, grad_fn=<MseLossBackward0>)\n",
      "epoch= 482 loss= tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "epoch= 483 loss= tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 484 loss= tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 485 loss= tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 486 loss= tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 487 loss= tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 488 loss= tensor(0.0962, grad_fn=<MseLossBackward0>)\n",
      "epoch= 489 loss= tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 490 loss= tensor(0.0971, grad_fn=<MseLossBackward0>)\n",
      "epoch= 491 loss= tensor(0.0964, grad_fn=<MseLossBackward0>)\n",
      "epoch= 492 loss= tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 493 loss= tensor(0.0967, grad_fn=<MseLossBackward0>)\n",
      "epoch= 494 loss= tensor(0.0974, grad_fn=<MseLossBackward0>)\n",
      "epoch= 495 loss= tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 496 loss= tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "epoch= 497 loss= tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "epoch= 498 loss= tensor(0.0965, grad_fn=<MseLossBackward0>)\n",
      "epoch= 499 loss= tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 500 loss= tensor(0.0963, grad_fn=<MseLossBackward0>)\n",
      "epoch= 501 loss= tensor(0.0958, grad_fn=<MseLossBackward0>)\n",
      "epoch= 502 loss= tensor(0.0961, grad_fn=<MseLossBackward0>)\n",
      "epoch= 503 loss= tensor(0.0955, grad_fn=<MseLossBackward0>)\n",
      "epoch= 504 loss= tensor(0.0959, grad_fn=<MseLossBackward0>)\n",
      "epoch= 505 loss= tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 506 loss= tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 507 loss= tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "epoch= 508 loss= tensor(0.0953, grad_fn=<MseLossBackward0>)\n",
      "epoch= 509 loss= tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 510 loss= tensor(0.0951, grad_fn=<MseLossBackward0>)\n",
      "epoch= 511 loss= tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 512 loss= tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "epoch= 513 loss= tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "epoch= 514 loss= tensor(0.0948, grad_fn=<MseLossBackward0>)\n",
      "epoch= 515 loss= tensor(0.0946, grad_fn=<MseLossBackward0>)\n",
      "epoch= 516 loss= tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "epoch= 517 loss= tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 518 loss= tensor(0.0947, grad_fn=<MseLossBackward0>)\n",
      "epoch= 519 loss= tensor(0.0944, grad_fn=<MseLossBackward0>)\n",
      "epoch= 520 loss= tensor(0.0945, grad_fn=<MseLossBackward0>)\n",
      "epoch= 521 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 522 loss= tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "epoch= 523 loss= tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "epoch= 524 loss= tensor(0.0941, grad_fn=<MseLossBackward0>)\n",
      "epoch= 525 loss= tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "epoch= 526 loss= tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "epoch= 527 loss= tensor(0.0942, grad_fn=<MseLossBackward0>)\n",
      "epoch= 528 loss= tensor(0.0940, grad_fn=<MseLossBackward0>)\n",
      "epoch= 529 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 530 loss= tensor(0.0937, grad_fn=<MseLossBackward0>)\n",
      "epoch= 531 loss= tensor(0.0934, grad_fn=<MseLossBackward0>)\n",
      "epoch= 532 loss= tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "epoch= 533 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 534 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 535 loss= tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 536 loss= tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 537 loss= tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 538 loss= tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch= 539 loss= tensor(0.0919, grad_fn=<MseLossBackward0>)\n",
      "epoch= 540 loss= tensor(0.0922, grad_fn=<MseLossBackward0>)\n",
      "epoch= 541 loss= tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "epoch= 542 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 543 loss= tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
      "epoch= 544 loss= tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "epoch= 545 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 546 loss= tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 547 loss= tensor(0.0924, grad_fn=<MseLossBackward0>)\n",
      "epoch= 548 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 549 loss= tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch= 550 loss= tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 551 loss= tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 552 loss= tensor(0.0903, grad_fn=<MseLossBackward0>)\n",
      "epoch= 553 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 554 loss= tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 555 loss= tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "epoch= 556 loss= tensor(0.0891, grad_fn=<MseLossBackward0>)\n",
      "epoch= 557 loss= tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "epoch= 558 loss= tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 559 loss= tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 560 loss= tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 561 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 562 loss= tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "epoch= 563 loss= tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "epoch= 564 loss= tensor(0.0923, grad_fn=<MseLossBackward0>)\n",
      "epoch= 565 loss= tensor(0.0931, grad_fn=<MseLossBackward0>)\n",
      "epoch= 566 loss= tensor(0.0943, grad_fn=<MseLossBackward0>)\n",
      "epoch= 567 loss= tensor(0.0938, grad_fn=<MseLossBackward0>)\n",
      "epoch= 568 loss= tensor(0.0949, grad_fn=<MseLossBackward0>)\n",
      "epoch= 569 loss= tensor(0.0936, grad_fn=<MseLossBackward0>)\n",
      "epoch= 570 loss= tensor(0.0933, grad_fn=<MseLossBackward0>)\n",
      "epoch= 571 loss= tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 572 loss= tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 573 loss= tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "epoch= 574 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 575 loss= tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 576 loss= tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "epoch= 577 loss= tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "epoch= 578 loss= tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 579 loss= tensor(0.0884, grad_fn=<MseLossBackward0>)\n",
      "epoch= 580 loss= tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "epoch= 581 loss= tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 582 loss= tensor(0.0899, grad_fn=<MseLossBackward0>)\n",
      "epoch= 583 loss= tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "epoch= 584 loss= tensor(0.0912, grad_fn=<MseLossBackward0>)\n",
      "epoch= 585 loss= tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 586 loss= tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 587 loss= tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch= 588 loss= tensor(0.0926, grad_fn=<MseLossBackward0>)\n",
      "epoch= 589 loss= tensor(0.0918, grad_fn=<MseLossBackward0>)\n",
      "epoch= 590 loss= tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 591 loss= tensor(0.0910, grad_fn=<MseLossBackward0>)\n",
      "epoch= 592 loss= tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "epoch= 593 loss= tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 594 loss= tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 595 loss= tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 596 loss= tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "epoch= 597 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 598 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 599 loss= tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 600 loss= tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "epoch= 601 loss= tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "epoch= 602 loss= tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "epoch= 603 loss= tensor(0.0885, grad_fn=<MseLossBackward0>)\n",
      "epoch= 604 loss= tensor(0.0896, grad_fn=<MseLossBackward0>)\n",
      "epoch= 605 loss= tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "epoch= 606 loss= tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 607 loss= tensor(0.0915, grad_fn=<MseLossBackward0>)\n",
      "epoch= 608 loss= tensor(0.0929, grad_fn=<MseLossBackward0>)\n",
      "epoch= 609 loss= tensor(0.0916, grad_fn=<MseLossBackward0>)\n",
      "epoch= 610 loss= tensor(0.0920, grad_fn=<MseLossBackward0>)\n",
      "epoch= 611 loss= tensor(0.0904, grad_fn=<MseLossBackward0>)\n",
      "epoch= 612 loss= tensor(0.0901, grad_fn=<MseLossBackward0>)\n",
      "epoch= 613 loss= tensor(0.0887, grad_fn=<MseLossBackward0>)\n",
      "epoch= 614 loss= tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 615 loss= tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 616 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 617 loss= tensor(0.0871, grad_fn=<MseLossBackward0>)\n",
      "epoch= 618 loss= tensor(0.0873, grad_fn=<MseLossBackward0>)\n",
      "epoch= 619 loss= tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "epoch= 620 loss= tensor(0.0875, grad_fn=<MseLossBackward0>)\n",
      "epoch= 621 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 622 loss= tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 623 loss= tensor(0.0883, grad_fn=<MseLossBackward0>)\n",
      "epoch= 624 loss= tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 625 loss= tensor(0.0895, grad_fn=<MseLossBackward0>)\n",
      "epoch= 626 loss= tensor(0.0909, grad_fn=<MseLossBackward0>)\n",
      "epoch= 627 loss= tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 628 loss= tensor(0.0914, grad_fn=<MseLossBackward0>)\n",
      "epoch= 629 loss= tensor(0.0902, grad_fn=<MseLossBackward0>)\n",
      "epoch= 630 loss= tensor(0.0908, grad_fn=<MseLossBackward0>)\n",
      "epoch= 631 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 632 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 633 loss= tensor(0.0878, grad_fn=<MseLossBackward0>)\n",
      "epoch= 634 loss= tensor(0.0877, grad_fn=<MseLossBackward0>)\n",
      "epoch= 635 loss= tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 636 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 637 loss= tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "epoch= 638 loss= tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "epoch= 639 loss= tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 640 loss= tensor(0.0865, grad_fn=<MseLossBackward0>)\n",
      "epoch= 641 loss= tensor(0.0864, grad_fn=<MseLossBackward0>)\n",
      "epoch= 642 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 643 loss= tensor(0.0874, grad_fn=<MseLossBackward0>)\n",
      "epoch= 644 loss= tensor(0.0890, grad_fn=<MseLossBackward0>)\n",
      "epoch= 645 loss= tensor(0.0889, grad_fn=<MseLossBackward0>)\n",
      "epoch= 646 loss= tensor(0.0907, grad_fn=<MseLossBackward0>)\n",
      "epoch= 647 loss= tensor(0.0900, grad_fn=<MseLossBackward0>)\n",
      "epoch= 648 loss= tensor(0.0911, grad_fn=<MseLossBackward0>)\n",
      "epoch= 649 loss= tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 650 loss= tensor(0.0893, grad_fn=<MseLossBackward0>)\n",
      "epoch= 651 loss= tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 652 loss= tensor(0.0872, grad_fn=<MseLossBackward0>)\n",
      "epoch= 653 loss= tensor(0.0858, grad_fn=<MseLossBackward0>)\n",
      "epoch= 654 loss= tensor(0.0856, grad_fn=<MseLossBackward0>)\n",
      "epoch= 655 loss= tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 656 loss= tensor(0.0846, grad_fn=<MseLossBackward0>)\n",
      "epoch= 657 loss= tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 658 loss= tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 659 loss= tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 660 loss= tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "epoch= 661 loss= tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "epoch= 662 loss= tensor(0.0870, grad_fn=<MseLossBackward0>)\n",
      "epoch= 663 loss= tensor(0.0876, grad_fn=<MseLossBackward0>)\n",
      "epoch= 664 loss= tensor(0.0898, grad_fn=<MseLossBackward0>)\n",
      "epoch= 665 loss= tensor(0.0894, grad_fn=<MseLossBackward0>)\n",
      "epoch= 666 loss= tensor(0.0905, grad_fn=<MseLossBackward0>)\n",
      "epoch= 667 loss= tensor(0.0888, grad_fn=<MseLossBackward0>)\n",
      "epoch= 668 loss= tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "epoch= 669 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 670 loss= tensor(0.0859, grad_fn=<MseLossBackward0>)\n",
      "epoch= 671 loss= tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 672 loss= tensor(0.0843, grad_fn=<MseLossBackward0>)\n",
      "epoch= 673 loss= tensor(0.0835, grad_fn=<MseLossBackward0>)\n",
      "epoch= 674 loss= tensor(0.0838, grad_fn=<MseLossBackward0>)\n",
      "epoch= 675 loss= tensor(0.0832, grad_fn=<MseLossBackward0>)\n",
      "epoch= 676 loss= tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 677 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 678 loss= tensor(0.0855, grad_fn=<MseLossBackward0>)\n",
      "epoch= 679 loss= tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "epoch= 680 loss= tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "epoch= 681 loss= tensor(0.0880, grad_fn=<MseLossBackward0>)\n",
      "epoch= 682 loss= tensor(0.0897, grad_fn=<MseLossBackward0>)\n",
      "epoch= 683 loss= tensor(0.0881, grad_fn=<MseLossBackward0>)\n",
      "epoch= 684 loss= tensor(0.0886, grad_fn=<MseLossBackward0>)\n",
      "epoch= 685 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 686 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 687 loss= tensor(0.0857, grad_fn=<MseLossBackward0>)\n",
      "epoch= 688 loss= tensor(0.0848, grad_fn=<MseLossBackward0>)\n",
      "epoch= 689 loss= tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 690 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 691 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 692 loss= tensor(0.0839, grad_fn=<MseLossBackward0>)\n",
      "epoch= 693 loss= tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 694 loss= tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 695 loss= tensor(0.0851, grad_fn=<MseLossBackward0>)\n",
      "epoch= 696 loss= tensor(0.0860, grad_fn=<MseLossBackward0>)\n",
      "epoch= 697 loss= tensor(0.0863, grad_fn=<MseLossBackward0>)\n",
      "epoch= 698 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 699 loss= tensor(0.0861, grad_fn=<MseLossBackward0>)\n",
      "epoch= 700 loss= tensor(0.0862, grad_fn=<MseLossBackward0>)\n",
      "epoch= 701 loss= tensor(0.0852, grad_fn=<MseLossBackward0>)\n",
      "epoch= 702 loss= tensor(0.0849, grad_fn=<MseLossBackward0>)\n",
      "epoch= 703 loss= tensor(0.0840, grad_fn=<MseLossBackward0>)\n",
      "epoch= 704 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 705 loss= tensor(0.0829, grad_fn=<MseLossBackward0>)\n",
      "epoch= 706 loss= tensor(0.0826, grad_fn=<MseLossBackward0>)\n",
      "epoch= 707 loss= tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "epoch= 708 loss= tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "epoch= 709 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 710 loss= tensor(0.0822, grad_fn=<MseLossBackward0>)\n",
      "epoch= 711 loss= tensor(0.0819, grad_fn=<MseLossBackward0>)\n",
      "epoch= 712 loss= tensor(0.0830, grad_fn=<MseLossBackward0>)\n",
      "epoch= 713 loss= tensor(0.0831, grad_fn=<MseLossBackward0>)\n",
      "epoch= 714 loss= tensor(0.0842, grad_fn=<MseLossBackward0>)\n",
      "epoch= 715 loss= tensor(0.0837, grad_fn=<MseLossBackward0>)\n",
      "epoch= 716 loss= tensor(0.0844, grad_fn=<MseLossBackward0>)\n",
      "epoch= 717 loss= tensor(0.0833, grad_fn=<MseLossBackward0>)\n",
      "epoch= 718 loss= tensor(0.0836, grad_fn=<MseLossBackward0>)\n",
      "epoch= 719 loss= tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch= 720 loss= tensor(0.0824, grad_fn=<MseLossBackward0>)\n",
      "epoch= 721 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 722 loss= tensor(0.0816, grad_fn=<MseLossBackward0>)\n",
      "epoch= 723 loss= tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 724 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 725 loss= tensor(0.0808, grad_fn=<MseLossBackward0>)\n",
      "epoch= 726 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 727 loss= tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 728 loss= tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 729 loss= tensor(0.0809, grad_fn=<MseLossBackward0>)\n",
      "epoch= 730 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 731 loss= tensor(0.0807, grad_fn=<MseLossBackward0>)\n",
      "epoch= 732 loss= tensor(0.0820, grad_fn=<MseLossBackward0>)\n",
      "epoch= 733 loss= tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 734 loss= tensor(0.0815, grad_fn=<MseLossBackward0>)\n",
      "epoch= 735 loss= tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 736 loss= tensor(0.0813, grad_fn=<MseLossBackward0>)\n",
      "epoch= 737 loss= tensor(0.0806, grad_fn=<MseLossBackward0>)\n",
      "epoch= 738 loss= tensor(0.0817, grad_fn=<MseLossBackward0>)\n",
      "epoch= 739 loss= tensor(0.0811, grad_fn=<MseLossBackward0>)\n",
      "epoch= 740 loss= tensor(0.0825, grad_fn=<MseLossBackward0>)\n",
      "epoch= 741 loss= tensor(0.0810, grad_fn=<MseLossBackward0>)\n",
      "epoch= 742 loss= tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "epoch= 743 loss= tensor(0.0801, grad_fn=<MseLossBackward0>)\n",
      "epoch= 744 loss= tensor(0.0804, grad_fn=<MseLossBackward0>)\n",
      "epoch= 745 loss= tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 746 loss= tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "epoch= 747 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 748 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 749 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 750 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 751 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 752 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 753 loss= tensor(0.0785, grad_fn=<MseLossBackward0>)\n",
      "epoch= 754 loss= tensor(0.0798, grad_fn=<MseLossBackward0>)\n",
      "epoch= 755 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 756 loss= tensor(0.0802, grad_fn=<MseLossBackward0>)\n",
      "epoch= 757 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 758 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 759 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 760 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 761 loss= tensor(0.0781, grad_fn=<MseLossBackward0>)\n",
      "epoch= 762 loss= tensor(0.0790, grad_fn=<MseLossBackward0>)\n",
      "epoch= 763 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 764 loss= tensor(0.0792, grad_fn=<MseLossBackward0>)\n",
      "epoch= 765 loss= tensor(0.0787, grad_fn=<MseLossBackward0>)\n",
      "epoch= 766 loss= tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 767 loss= tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 768 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 769 loss= tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "epoch= 770 loss= tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "epoch= 771 loss= tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 772 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 773 loss= tensor(0.0771, grad_fn=<MseLossBackward0>)\n",
      "epoch= 774 loss= tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 775 loss= tensor(0.0780, grad_fn=<MseLossBackward0>)\n",
      "epoch= 776 loss= tensor(0.0797, grad_fn=<MseLossBackward0>)\n",
      "epoch= 777 loss= tensor(0.0778, grad_fn=<MseLossBackward0>)\n",
      "epoch= 778 loss= tensor(0.0786, grad_fn=<MseLossBackward0>)\n",
      "epoch= 779 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 780 loss= tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "epoch= 781 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 782 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 783 loss= tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 784 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 785 loss= tensor(0.0761, grad_fn=<MseLossBackward0>)\n",
      "epoch= 786 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 787 loss= tensor(0.0756, grad_fn=<MseLossBackward0>)\n",
      "epoch= 788 loss= tensor(0.0765, grad_fn=<MseLossBackward0>)\n",
      "epoch= 789 loss= tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 790 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 791 loss= tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 792 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 793 loss= tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 794 loss= tensor(0.0758, grad_fn=<MseLossBackward0>)\n",
      "epoch= 795 loss= tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 796 loss= tensor(0.0763, grad_fn=<MseLossBackward0>)\n",
      "epoch= 797 loss= tensor(0.0755, grad_fn=<MseLossBackward0>)\n",
      "epoch= 798 loss= tensor(0.0774, grad_fn=<MseLossBackward0>)\n",
      "epoch= 799 loss= tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 800 loss= tensor(0.0793, grad_fn=<MseLossBackward0>)\n",
      "epoch= 801 loss= tensor(0.0789, grad_fn=<MseLossBackward0>)\n",
      "epoch= 802 loss= tensor(0.0794, grad_fn=<MseLossBackward0>)\n",
      "epoch= 803 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 804 loss= tensor(0.0772, grad_fn=<MseLossBackward0>)\n",
      "epoch= 805 loss= tensor(0.0747, grad_fn=<MseLossBackward0>)\n",
      "epoch= 806 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 807 loss= tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch= 808 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 809 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 810 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 811 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 812 loss= tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch= 813 loss= tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 814 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 815 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 816 loss= tensor(0.0753, grad_fn=<MseLossBackward0>)\n",
      "epoch= 817 loss= tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 818 loss= tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 819 loss= tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 820 loss= tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 821 loss= tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch= 822 loss= tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "epoch= 823 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 824 loss= tensor(0.0739, grad_fn=<MseLossBackward0>)\n",
      "epoch= 825 loss= tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch= 826 loss= tensor(0.0742, grad_fn=<MseLossBackward0>)\n",
      "epoch= 827 loss= tensor(0.0733, grad_fn=<MseLossBackward0>)\n",
      "epoch= 828 loss= tensor(0.0745, grad_fn=<MseLossBackward0>)\n",
      "epoch= 829 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 830 loss= tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 831 loss= tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 832 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 833 loss= tensor(0.0773, grad_fn=<MseLossBackward0>)\n",
      "epoch= 834 loss= tensor(0.0768, grad_fn=<MseLossBackward0>)\n",
      "epoch= 835 loss= tensor(0.0741, grad_fn=<MseLossBackward0>)\n",
      "epoch= 836 loss= tensor(0.0743, grad_fn=<MseLossBackward0>)\n",
      "epoch= 837 loss= tensor(0.0732, grad_fn=<MseLossBackward0>)\n",
      "epoch= 838 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 839 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 840 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 841 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 842 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 843 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 844 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 845 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 846 loss= tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 847 loss= tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 848 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 849 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 850 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 851 loss= tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 852 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 853 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 854 loss= tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 855 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 856 loss= tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 857 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 858 loss= tensor(0.0746, grad_fn=<MseLossBackward0>)\n",
      "epoch= 859 loss= tensor(0.0750, grad_fn=<MseLossBackward0>)\n",
      "epoch= 860 loss= tensor(0.0751, grad_fn=<MseLossBackward0>)\n",
      "epoch= 861 loss= tensor(0.0740, grad_fn=<MseLossBackward0>)\n",
      "epoch= 862 loss= tensor(0.0731, grad_fn=<MseLossBackward0>)\n",
      "epoch= 863 loss= tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 864 loss= tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 865 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 866 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 867 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 868 loss= tensor(0.0723, grad_fn=<MseLossBackward0>)\n",
      "epoch= 869 loss= tensor(0.0719, grad_fn=<MseLossBackward0>)\n",
      "epoch= 870 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 871 loss= tensor(0.0707, grad_fn=<MseLossBackward0>)\n",
      "epoch= 872 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 873 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 874 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 875 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 876 loss= tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 877 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 878 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 879 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 880 loss= tensor(0.0735, grad_fn=<MseLossBackward0>)\n",
      "epoch= 881 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 882 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 883 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 884 loss= tensor(0.0728, grad_fn=<MseLossBackward0>)\n",
      "epoch= 885 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 886 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 887 loss= tensor(0.0712, grad_fn=<MseLossBackward0>)\n",
      "epoch= 888 loss= tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 889 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 890 loss= tensor(0.0716, grad_fn=<MseLossBackward0>)\n",
      "epoch= 891 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 892 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 893 loss= tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 894 loss= tensor(0.0709, grad_fn=<MseLossBackward0>)\n",
      "epoch= 895 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 896 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 897 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 898 loss= tensor(0.0706, grad_fn=<MseLossBackward0>)\n",
      "epoch= 899 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 900 loss= tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 901 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 902 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 903 loss= tensor(0.0704, grad_fn=<MseLossBackward0>)\n",
      "epoch= 904 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 905 loss= tensor(0.0721, grad_fn=<MseLossBackward0>)\n",
      "epoch= 906 loss= tensor(0.0738, grad_fn=<MseLossBackward0>)\n",
      "epoch= 907 loss= tensor(0.0727, grad_fn=<MseLossBackward0>)\n",
      "epoch= 908 loss= tensor(0.0734, grad_fn=<MseLossBackward0>)\n",
      "epoch= 909 loss= tensor(0.0722, grad_fn=<MseLossBackward0>)\n",
      "epoch= 910 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 911 loss= tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "epoch= 912 loss= tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "epoch= 913 loss= tensor(0.0699, grad_fn=<MseLossBackward0>)\n",
      "epoch= 914 loss= tensor(0.0717, grad_fn=<MseLossBackward0>)\n",
      "epoch= 915 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 916 loss= tensor(0.0736, grad_fn=<MseLossBackward0>)\n",
      "epoch= 917 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 918 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 919 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 920 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 921 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 922 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 923 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 924 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 925 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 926 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 927 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 928 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 929 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 930 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 931 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 932 loss= tensor(0.0689, grad_fn=<MseLossBackward0>)\n",
      "epoch= 933 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 934 loss= tensor(0.0702, grad_fn=<MseLossBackward0>)\n",
      "epoch= 935 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 936 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 937 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 938 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 939 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 940 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 941 loss= tensor(0.0752, grad_fn=<MseLossBackward0>)\n",
      "epoch= 942 loss= tensor(0.0854, grad_fn=<MseLossBackward0>)\n",
      "epoch= 943 loss= tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "epoch= 944 loss= tensor(0.0847, grad_fn=<MseLossBackward0>)\n",
      "epoch= 945 loss= tensor(0.0770, grad_fn=<MseLossBackward0>)\n",
      "epoch= 946 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 947 loss= tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch= 948 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 949 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 950 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 951 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 952 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 953 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 954 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 955 loss= tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "epoch= 956 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 957 loss= tensor(0.0726, grad_fn=<MseLossBackward0>)\n",
      "epoch= 958 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 959 loss= tensor(0.0714, grad_fn=<MseLossBackward0>)\n",
      "epoch= 960 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 961 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 962 loss= tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "epoch= 963 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 964 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 965 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 966 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 967 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 968 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 969 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 970 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 971 loss= tensor(0.0692, grad_fn=<MseLossBackward0>)\n",
      "epoch= 972 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 973 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 974 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 975 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 976 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 977 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 978 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 979 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 980 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 981 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 982 loss= tensor(0.0696, grad_fn=<MseLossBackward0>)\n",
      "epoch= 983 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 984 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 985 loss= tensor(0.0679, grad_fn=<MseLossBackward0>)\n",
      "epoch= 986 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 987 loss= tensor(0.0673, grad_fn=<MseLossBackward0>)\n",
      "epoch= 988 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 989 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 990 loss= tensor(0.0674, grad_fn=<MseLossBackward0>)\n",
      "epoch= 991 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 992 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 993 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 994 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 995 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 996 loss= tensor(0.0668, grad_fn=<MseLossBackward0>)\n",
      "epoch= 997 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 998 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 999 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1000 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1001 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1002 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1003 loss= tensor(0.0677, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1004 loss= tensor(0.0724, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1005 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1006 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1007 loss= tensor(0.0703, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1008 loss= tensor(0.0737, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1009 loss= tensor(0.0777, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1010 loss= tensor(0.0788, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1011 loss= tensor(0.0784, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1012 loss= tensor(0.0729, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1013 loss= tensor(0.0708, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1014 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1015 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1016 loss= tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1017 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1018 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1019 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1020 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1021 loss= tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1022 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1023 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1024 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1025 loss= tensor(0.0695, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1026 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1027 loss= tensor(0.0718, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1028 loss= tensor(0.0693, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1029 loss= tensor(0.0697, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1030 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1031 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1032 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1033 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1034 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1035 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1036 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1037 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1038 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1039 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1040 loss= tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1041 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1042 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1043 loss= tensor(0.0667, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1044 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1045 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1046 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1047 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1048 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1049 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1050 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1051 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1052 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1053 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1054 loss= tensor(0.0664, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1055 loss= tensor(0.0671, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1056 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1057 loss= tensor(0.0663, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1058 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1059 loss= tensor(0.0661, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1060 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1061 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1062 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1063 loss= tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1064 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1065 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1066 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1067 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1068 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1069 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1070 loss= tensor(0.0681, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1071 loss= tensor(0.0690, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1072 loss= tensor(0.0683, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1073 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1074 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1075 loss= tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1076 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1077 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1078 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1079 loss= tensor(0.0684, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1080 loss= tensor(0.0656, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1081 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1082 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1083 loss= tensor(0.0691, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1084 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1085 loss= tensor(0.0675, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1086 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1087 loss= tensor(0.0686, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1088 loss= tensor(0.0698, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1089 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1090 loss= tensor(0.0678, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1091 loss= tensor(0.0653, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1092 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1093 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1094 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1095 loss= tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1096 loss= tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1097 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1098 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1099 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1100 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1101 loss= tensor(0.0637, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1102 loss= tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1103 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1104 loss= tensor(0.0650, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1105 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1106 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1107 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1108 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1109 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1110 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1111 loss= tensor(0.0638, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1112 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1113 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1114 loss= tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1115 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1116 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1117 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1118 loss= tensor(0.0641, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1119 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1120 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1121 loss= tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1122 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1123 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1124 loss= tensor(0.0631, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1125 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1126 loss= tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1127 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1128 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1129 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1130 loss= tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1131 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1132 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1133 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1134 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1135 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1136 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1137 loss= tensor(0.0662, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1138 loss= tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1139 loss= tensor(0.0654, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1140 loss= tensor(0.0657, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1141 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1142 loss= tensor(0.0643, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1143 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1144 loss= tensor(0.0647, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1145 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1146 loss= tensor(0.0666, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1147 loss= tensor(0.0682, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1148 loss= tensor(0.0685, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1149 loss= tensor(0.0715, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1150 loss= tensor(0.0672, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1151 loss= tensor(0.0680, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1152 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1153 loss= tensor(0.0652, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1154 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1155 loss= tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1156 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1157 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1158 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1159 loss= tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1160 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1161 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1162 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1163 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1164 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1165 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1166 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1167 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1168 loss= tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1169 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1170 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1171 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1172 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1173 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1174 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1175 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1176 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1177 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1178 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1179 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1180 loss= tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1181 loss= tensor(0.0649, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1182 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1183 loss= tensor(0.0660, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1184 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1185 loss= tensor(0.0670, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1186 loss= tensor(0.0655, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1187 loss= tensor(0.0646, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1188 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1189 loss= tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1190 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1191 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1192 loss= tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1193 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1194 loss= tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1195 loss= tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1196 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1197 loss= tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1198 loss= tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1199 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1200 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1201 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1202 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1203 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1204 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1205 loss= tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1206 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1207 loss= tensor(0.0648, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1208 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1209 loss= tensor(0.0624, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1210 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1211 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1212 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1213 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1214 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1215 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1216 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1217 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1218 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1219 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1220 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1221 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1222 loss= tensor(0.0628, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1223 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1224 loss= tensor(0.0620, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1225 loss= tensor(0.0623, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1226 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1227 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1228 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1229 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1230 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1231 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1232 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1233 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1234 loss= tensor(0.0607, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1235 loss= tensor(0.0615, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1236 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1237 loss= tensor(0.0626, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1238 loss= tensor(0.0610, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1239 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1240 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1241 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1242 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1243 loss= tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1244 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1245 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1246 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1247 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1248 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1249 loss= tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1250 loss= tensor(0.0633, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1251 loss= tensor(0.0658, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1252 loss= tensor(0.0694, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1253 loss= tensor(0.0700, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1254 loss= tensor(0.0730, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1255 loss= tensor(0.0676, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1256 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1257 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1258 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1259 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1260 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1261 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1262 loss= tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1263 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1264 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1265 loss= tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1266 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1267 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1268 loss= tensor(0.0603, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1269 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1270 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1271 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1272 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1273 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1274 loss= tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1275 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1276 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1277 loss= tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1278 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1279 loss= tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1280 loss= tensor(0.0619, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1281 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1282 loss= tensor(0.0630, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1283 loss= tensor(0.0624, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1284 loss= tensor(0.0636, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1285 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1286 loss= tensor(0.0644, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1287 loss= tensor(0.0635, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1288 loss= tensor(0.0640, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1289 loss= tensor(0.0625, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1290 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1291 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1292 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1293 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1294 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1295 loss= tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1296 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1297 loss= tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1298 loss= tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1299 loss= tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1300 loss= tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1301 loss= tensor(0.0586, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1302 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1303 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1304 loss= tensor(0.0622, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1305 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1306 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1307 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1308 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1309 loss= tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1310 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1311 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1312 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1313 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1314 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1315 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1316 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1317 loss= tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1318 loss= tensor(0.0581, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1319 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1320 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1321 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1322 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1323 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1324 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1325 loss= tensor(0.0590, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1326 loss= tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1327 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1328 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1329 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1330 loss= tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1331 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1332 loss= tensor(0.0595, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1333 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1334 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1335 loss= tensor(0.0616, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1336 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1337 loss= tensor(0.0687, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1338 loss= tensor(0.0659, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1339 loss= tensor(0.0669, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1340 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1341 loss= tensor(0.0618, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1342 loss= tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1343 loss= tensor(0.0594, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1344 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1345 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1346 loss= tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1347 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1348 loss= tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1349 loss= tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1350 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1351 loss= tensor(0.0581, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1352 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1353 loss= tensor(0.0581, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1354 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1355 loss= tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1356 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1357 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1358 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1359 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1360 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1361 loss= tensor(0.0583, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1362 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1363 loss= tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1364 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1365 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1366 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1367 loss= tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1368 loss= tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1369 loss= tensor(0.0589, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1370 loss= tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1371 loss= tensor(0.0605, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1372 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1373 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1374 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1375 loss= tensor(0.0612, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1376 loss= tensor(0.0621, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1377 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1378 loss= tensor(0.0608, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1379 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1380 loss= tensor(0.0598, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1381 loss= tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1382 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1383 loss= tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1384 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1385 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1386 loss= tensor(0.0557, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1387 loss= tensor(0.0568, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1388 loss= tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1389 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1390 loss= tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1391 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1392 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1393 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1394 loss= tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1395 loss= tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1396 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1397 loss= tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1398 loss= tensor(0.0539, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1399 loss= tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1400 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1401 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1402 loss= tensor(0.0533, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1403 loss= tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1404 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1405 loss= tensor(0.0562, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1406 loss= tensor(0.0554, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1407 loss= tensor(0.0579, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1408 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1409 loss= tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1410 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1411 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1412 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1413 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1414 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1415 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1416 loss= tensor(0.0561, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1417 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1418 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1419 loss= tensor(0.0575, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1420 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1421 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1422 loss= tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1423 loss= tensor(0.0627, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1424 loss= tensor(0.0573, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1425 loss= tensor(0.0600, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1426 loss= tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1427 loss= tensor(0.0563, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1428 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1429 loss= tensor(0.0564, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1430 loss= tensor(0.0593, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1431 loss= tensor(0.0601, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1432 loss= tensor(0.0642, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1433 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1434 loss= tensor(0.0599, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1435 loss= tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1436 loss= tensor(0.0565, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1437 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1438 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1439 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1440 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1441 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1442 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1443 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1444 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1445 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1446 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1447 loss= tensor(0.0545, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1448 loss= tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1449 loss= tensor(0.0549, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1450 loss= tensor(0.0556, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1451 loss= tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1452 loss= tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1453 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1454 loss= tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1455 loss= tensor(0.0553, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1456 loss= tensor(0.0547, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1457 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1458 loss= tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1459 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1460 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1461 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1462 loss= tensor(0.0525, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1463 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1464 loss= tensor(0.0529, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1465 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1466 loss= tensor(0.0538, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1467 loss= tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1468 loss= tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1469 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1470 loss= tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1471 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1472 loss= tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1473 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1474 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1475 loss= tensor(0.0512, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1476 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1477 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1478 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1479 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1480 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1481 loss= tensor(0.0492, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1482 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1483 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1484 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1485 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1486 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1487 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1488 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1489 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1490 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1491 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1492 loss= tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1493 loss= tensor(0.0548, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1494 loss= tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1495 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1496 loss= tensor(0.0613, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1497 loss= tensor(0.0572, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1498 loss= tensor(0.0541, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1499 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1500 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1501 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1502 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1503 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1504 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1505 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1506 loss= tensor(0.0506, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1507 loss= tensor(0.0519, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1508 loss= tensor(0.0524, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1509 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1510 loss= tensor(0.0509, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1511 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1512 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1513 loss= tensor(0.0503, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1514 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1515 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1516 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1517 loss= tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1518 loss= tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1519 loss= tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1520 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1521 loss= tensor(0.0632, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1522 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1523 loss= tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1524 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1525 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1526 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1527 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1528 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1529 loss= tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1530 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1531 loss= tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1532 loss= tensor(0.0514, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1533 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1534 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1535 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1536 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1537 loss= tensor(0.0521, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1538 loss= tensor(0.0528, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1539 loss= tensor(0.0516, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1540 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1541 loss= tensor(0.0493, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1542 loss= tensor(0.0490, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1543 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1544 loss= tensor(0.0500, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1545 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1546 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1547 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1548 loss= tensor(0.0510, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1549 loss= tensor(0.0515, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1550 loss= tensor(0.0550, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1551 loss= tensor(0.0552, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1552 loss= tensor(0.0588, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1553 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1554 loss= tensor(0.0513, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1555 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1556 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1557 loss= tensor(0.0476, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1558 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1559 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1560 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1561 loss= tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1562 loss= tensor(0.0491, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1563 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1564 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1565 loss= tensor(0.0543, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1566 loss= tensor(0.0606, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1567 loss= tensor(0.0629, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1568 loss= tensor(0.0614, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1569 loss= tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1570 loss= tensor(0.0526, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1571 loss= tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1572 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1573 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1574 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1575 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1576 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1577 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1578 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1579 loss= tensor(0.0463, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1580 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1581 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1582 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1583 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1584 loss= tensor(0.0501, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1585 loss= tensor(0.0507, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1586 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1587 loss= tensor(0.0464, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1588 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1589 loss= tensor(0.0530, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1590 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1591 loss= tensor(0.0574, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1592 loss= tensor(0.0537, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1593 loss= tensor(0.0535, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1594 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1595 loss= tensor(0.0495, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1596 loss= tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1597 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1598 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1599 loss= tensor(0.0481, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1600 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1601 loss= tensor(0.0494, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1602 loss= tensor(0.0486, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1603 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1604 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1605 loss= tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1606 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1607 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1608 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1609 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1610 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1611 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1612 loss= tensor(0.0446, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1613 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1614 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1615 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1616 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1617 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1618 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1619 loss= tensor(0.0458, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1620 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1621 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1622 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1623 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1624 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1625 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1626 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1627 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1628 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1629 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1630 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1631 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1632 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1633 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1634 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1635 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1636 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1637 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1638 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1639 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1640 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1641 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1642 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1643 loss= tensor(0.0483, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1644 loss= tensor(0.0520, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1645 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1646 loss= tensor(0.0645, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1647 loss= tensor(0.0651, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1648 loss= tensor(0.0587, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1649 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1650 loss= tensor(0.0433, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1651 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1652 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1653 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1654 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1655 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1656 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1657 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1658 loss= tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1659 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1660 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1661 loss= tensor(0.0482, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1662 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1663 loss= tensor(0.0558, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1664 loss= tensor(0.0522, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1665 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1666 loss= tensor(0.0450, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1667 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1668 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1669 loss= tensor(0.0391, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1670 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1671 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1672 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1673 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1674 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1675 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1676 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1677 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1678 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1679 loss= tensor(0.0489, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1680 loss= tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1681 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1682 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1683 loss= tensor(0.0448, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1684 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1685 loss= tensor(0.0437, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1686 loss= tensor(0.0459, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1687 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1688 loss= tensor(0.0461, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1689 loss= tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1690 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1691 loss= tensor(0.0478, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1692 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1693 loss= tensor(0.0421, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1694 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1695 loss= tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1696 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1697 loss= tensor(0.0424, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1698 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1699 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1700 loss= tensor(0.0534, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1701 loss= tensor(0.0508, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1702 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1703 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1704 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1705 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1706 loss= tensor(0.0417, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1707 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1708 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1709 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1710 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1711 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1712 loss= tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1713 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1714 loss= tensor(0.0504, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1715 loss= tensor(0.0536, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1716 loss= tensor(0.0502, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1717 loss= tensor(0.0505, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1718 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1719 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1720 loss= tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1721 loss= tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1722 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1723 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1724 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1725 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1726 loss= tensor(0.0455, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1727 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1728 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1729 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1730 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1731 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1732 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1733 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1734 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1735 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1736 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1737 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1738 loss= tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1739 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1740 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1741 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1742 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1743 loss= tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1744 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1745 loss= tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1746 loss= tensor(0.0410, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1747 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1748 loss= tensor(0.0472, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1749 loss= tensor(0.0546, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1750 loss= tensor(0.0551, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1751 loss= tensor(0.0604, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1752 loss= tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1753 loss= tensor(0.0566, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1754 loss= tensor(0.0518, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1755 loss= tensor(0.0456, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1756 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1757 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1758 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1759 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1760 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1761 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1762 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1763 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1764 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1765 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1766 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1767 loss= tensor(0.0440, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1768 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1769 loss= tensor(0.0462, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1770 loss= tensor(0.0453, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1771 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1772 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1773 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1774 loss= tensor(0.0403, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1775 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1776 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1777 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1778 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1779 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1780 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1781 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1782 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1783 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1784 loss= tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1785 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1786 loss= tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1787 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1788 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1789 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1790 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1791 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1792 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1793 loss= tensor(0.0475, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1794 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1795 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1796 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1797 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1798 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1799 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1800 loss= tensor(0.0392, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1801 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1802 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1803 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1804 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1805 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1806 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1807 loss= tensor(0.0413, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1808 loss= tensor(0.0428, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1809 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1810 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1811 loss= tensor(0.0416, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1812 loss= tensor(0.0412, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1813 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1814 loss= tensor(0.0405, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1815 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1816 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1817 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1818 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1819 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1820 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1821 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1822 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1823 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1824 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1825 loss= tensor(0.0438, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1826 loss= tensor(0.0454, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1827 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1828 loss= tensor(0.0517, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1829 loss= tensor(0.0474, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1830 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1831 loss= tensor(0.0442, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1832 loss= tensor(0.0466, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1833 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1834 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1835 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1836 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1837 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1838 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1839 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1840 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1841 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1842 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1843 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1844 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1845 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1846 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1847 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1848 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1849 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1850 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1851 loss= tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1852 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1853 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1854 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1855 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1856 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1857 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1858 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1859 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1860 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1861 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1862 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1863 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1864 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1865 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1866 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1867 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1868 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1869 loss= tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1870 loss= tensor(0.0498, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1871 loss= tensor(0.0470, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1872 loss= tensor(0.0527, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1873 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1874 loss= tensor(0.0496, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1875 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1876 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1877 loss= tensor(0.0420, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1878 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1879 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1880 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1881 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1882 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1883 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1884 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1885 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1886 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1887 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1888 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1889 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1890 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1891 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1892 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1893 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1894 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1895 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1896 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1897 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1898 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1899 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1900 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1901 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1902 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1903 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1904 loss= tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1905 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1906 loss= tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1907 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1908 loss= tensor(0.0469, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1909 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1910 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1911 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1912 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1913 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1914 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1915 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1916 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1917 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1918 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1919 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1920 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1921 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1922 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1923 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1924 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1925 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1926 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1927 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1928 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1929 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1930 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1931 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1932 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1933 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1934 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1935 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1936 loss= tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1937 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1938 loss= tensor(0.0445, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1939 loss= tensor(0.0479, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1940 loss= tensor(0.0465, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1941 loss= tensor(0.0441, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1942 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1943 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1944 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1945 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1946 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1947 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1948 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1949 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1950 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1951 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1952 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1953 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1954 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1955 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1956 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1957 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1958 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1959 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1960 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1961 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1962 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1963 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1964 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1965 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1966 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1967 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1968 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1969 loss= tensor(0.0460, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1970 loss= tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1971 loss= tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1972 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1973 loss= tensor(0.0532, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1974 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1975 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1976 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1977 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1978 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1979 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1980 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1981 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1982 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1983 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1984 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1985 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1986 loss= tensor(0.0383, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1987 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1988 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1989 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1990 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1991 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1992 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1993 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1994 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1995 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1996 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1997 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1998 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 1999 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2000 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2001 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2002 loss= tensor(0.0418, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2003 loss= tensor(0.0452, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2004 loss= tensor(0.0388, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2005 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2006 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2007 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2008 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2009 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2010 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2011 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2012 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2013 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2014 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2015 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2016 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2017 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2018 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2019 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2020 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2021 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2022 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2023 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2024 loss= tensor(0.0395, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2025 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2026 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2027 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2028 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2029 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2030 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2031 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2032 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2033 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2034 loss= tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2035 loss= tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2036 loss= tensor(0.0425, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2037 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2038 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2039 loss= tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2040 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2041 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2042 loss= tensor(0.0366, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2043 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2044 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2045 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2046 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2047 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2048 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2049 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2050 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2051 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2052 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2053 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2054 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2055 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2056 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2057 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2058 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2059 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2060 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2061 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2062 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2063 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2064 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2065 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2066 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2067 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2068 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2069 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2070 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2071 loss= tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2072 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2073 loss= tensor(0.0361, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2074 loss= tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2075 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2076 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2077 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2078 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2079 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2080 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2081 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2082 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2083 loss= tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2084 loss= tensor(0.0399, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2085 loss= tensor(0.0378, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2086 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2087 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2088 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2089 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2090 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2091 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2092 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2093 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2094 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2095 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2096 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2097 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2098 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2099 loss= tensor(0.0377, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2100 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2101 loss= tensor(0.0447, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2102 loss= tensor(0.0542, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2103 loss= tensor(0.0411, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2104 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2105 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2106 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2107 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2108 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2109 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2110 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2111 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2112 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2113 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2114 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2115 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2116 loss= tensor(0.0374, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2117 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2118 loss= tensor(0.0387, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2119 loss= tensor(0.0371, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2120 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2121 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2122 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2123 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2124 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2125 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2126 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2127 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2128 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2129 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2130 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2131 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2132 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2133 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2134 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2135 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2136 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2137 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2138 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2139 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2140 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2141 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2142 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2143 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2144 loss= tensor(0.0427, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2145 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2146 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2147 loss= tensor(0.0402, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2148 loss= tensor(0.0393, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2149 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2150 loss= tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2151 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2152 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2153 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2154 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2155 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2156 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2157 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2158 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2159 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2160 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2161 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2162 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2163 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2164 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2165 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2166 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2167 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2168 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2169 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2170 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2171 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2172 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2173 loss= tensor(0.0357, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2174 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2175 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2176 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2177 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2178 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2179 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2180 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2181 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2182 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2183 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2184 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2185 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2186 loss= tensor(0.0375, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2187 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2188 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2189 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2190 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2191 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2192 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2193 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2194 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2195 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2196 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2197 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2198 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2199 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2200 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2201 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2202 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2203 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2204 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2205 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2206 loss= tensor(0.0306, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2207 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2208 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2209 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2210 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2211 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2212 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2213 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2214 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2215 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2216 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2217 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2218 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2219 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2220 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2221 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2222 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2223 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2224 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2225 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2226 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2227 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2228 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2229 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2230 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2231 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2232 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2233 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2234 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2235 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2236 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2237 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2238 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2239 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2240 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2241 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2242 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2243 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2244 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2245 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2246 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2247 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2248 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2249 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2250 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2251 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2252 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2253 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2254 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2255 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2256 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2257 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2258 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2259 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2260 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2261 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2262 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2263 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2264 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2265 loss= tensor(0.0353, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2266 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2267 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2268 loss= tensor(0.0397, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2269 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2270 loss= tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2271 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2272 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2273 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2274 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2275 loss= tensor(0.0330, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2276 loss= tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2277 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2278 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2279 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2280 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2281 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2282 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2283 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2284 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2285 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2286 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2287 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2288 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2289 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2290 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2291 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2292 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2293 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2294 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2295 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2296 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2297 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2298 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2299 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2300 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2301 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2302 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2303 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2304 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2305 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2306 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2307 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2308 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2309 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2310 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2311 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2312 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2313 loss= tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2314 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2315 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2316 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2317 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2318 loss= tensor(0.0349, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2319 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2320 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2321 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2322 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2323 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2324 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2325 loss= tensor(0.0285, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2326 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2327 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2328 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2329 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2330 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2331 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2332 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2333 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2334 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2335 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2336 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2337 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2338 loss= tensor(0.0335, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2339 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2340 loss= tensor(0.0333, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2341 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2342 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2343 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2344 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2345 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2346 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2347 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2348 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2349 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2350 loss= tensor(0.0429, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2351 loss= tensor(0.0488, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2352 loss= tensor(0.0480, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2353 loss= tensor(0.0434, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2354 loss= tensor(0.0362, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2355 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2356 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2357 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2358 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2359 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2360 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2361 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2362 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2363 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2364 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2365 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2366 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2367 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2368 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2369 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2370 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2371 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2372 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2373 loss= tensor(0.0382, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2374 loss= tensor(0.0312, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2375 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2376 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2377 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2378 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2379 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2380 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2381 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2382 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2383 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2384 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2385 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2386 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2387 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2388 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2389 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2390 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2391 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2392 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2393 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2394 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2395 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2396 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2397 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2398 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2399 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2400 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2401 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2402 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2403 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2404 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2405 loss= tensor(0.0307, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2406 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2407 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2408 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2409 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2410 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2411 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2412 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2413 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2414 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2415 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2416 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2417 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2418 loss= tensor(0.0309, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2419 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2420 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2421 loss= tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2422 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2423 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2424 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2425 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2426 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2427 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2428 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2429 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2430 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2431 loss= tensor(0.0327, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2432 loss= tensor(0.0400, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2433 loss= tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2434 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2435 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2436 loss= tensor(0.0328, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2437 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2438 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2439 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2440 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2441 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2442 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2443 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2444 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2445 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2446 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2447 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2448 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2449 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2450 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2451 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2452 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2453 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2454 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2455 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2456 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2457 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2458 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2459 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2460 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2461 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2462 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2463 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2464 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2465 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2466 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2467 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2468 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2469 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2470 loss= tensor(0.0316, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2471 loss= tensor(0.0363, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2472 loss= tensor(0.0385, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2473 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2474 loss= tensor(0.0352, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2475 loss= tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2476 loss= tensor(0.0300, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2477 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2478 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2479 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2480 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2481 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2482 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2483 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2484 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2485 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2486 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2487 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2488 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2489 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2490 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2491 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2492 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2493 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2494 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2495 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2496 loss= tensor(0.0269, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2497 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2498 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2499 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2500 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2501 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2502 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2503 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2504 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2505 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2506 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2507 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2508 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2509 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2510 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2511 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2512 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2513 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2514 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2515 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2516 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2517 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2518 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2519 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2520 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2521 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2522 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2523 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2524 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2525 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2526 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2527 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2528 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2529 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2530 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2531 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2532 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2533 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2534 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2535 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2536 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2537 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2538 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2539 loss= tensor(0.0365, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2540 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2541 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2542 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2543 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2544 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2545 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2546 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2547 loss= tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2548 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2549 loss= tensor(0.0321, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2550 loss= tensor(0.0293, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2551 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2552 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2553 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2554 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2555 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2556 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2557 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2558 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2559 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2560 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2561 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2562 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2563 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2564 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2565 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2566 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2567 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2568 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2569 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2570 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2571 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2572 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2573 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2574 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2575 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2576 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2577 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2578 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2579 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2580 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2581 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2582 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2583 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2584 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2585 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2586 loss= tensor(0.0477, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2587 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2588 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2589 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2590 loss= tensor(0.0369, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2591 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2592 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2593 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2594 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2595 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2596 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2597 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2598 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2599 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2600 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2601 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2602 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2603 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2604 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2605 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2606 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2607 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2608 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2609 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2610 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2611 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2612 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2613 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2614 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2615 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2616 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2617 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2618 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2619 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2620 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2621 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2622 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2623 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2624 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2625 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2626 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2627 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2628 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2629 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2630 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2631 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2632 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2633 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2634 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2635 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2636 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2637 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2638 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2639 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2640 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2641 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2642 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2643 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2644 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2645 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2646 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2647 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2648 loss= tensor(0.0468, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2649 loss= tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2650 loss= tensor(0.0444, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2651 loss= tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2652 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2653 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2654 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2655 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2656 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2657 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2658 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2659 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2660 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2661 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2662 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2663 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2664 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2665 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2666 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2667 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2668 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2669 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2670 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2671 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2672 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2673 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2674 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2675 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2676 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2677 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2678 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2679 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2680 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2681 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2682 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2683 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2684 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2685 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2686 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2687 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2688 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2689 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2690 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2691 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2692 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2693 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2694 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2695 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2696 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2697 loss= tensor(0.0325, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2698 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2699 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2700 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2701 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2702 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2703 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2704 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2705 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2706 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2707 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2708 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2709 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2710 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2711 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2712 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2713 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2714 loss= tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2715 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2716 loss= tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2717 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2718 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2719 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2720 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2721 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2722 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2723 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2724 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2725 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2726 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2727 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2728 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2729 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2730 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2731 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2732 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2733 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2734 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2735 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2736 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2737 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2738 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2739 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2740 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2741 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2742 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2743 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2744 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2745 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2746 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2747 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2748 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2749 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2750 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2751 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2752 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2753 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2754 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2755 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2756 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2757 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2758 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2759 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2760 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2761 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2762 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2763 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2764 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2765 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2766 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2767 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2768 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2769 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2770 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2771 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2772 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2773 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2774 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2775 loss= tensor(0.0266, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2776 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2777 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2778 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2779 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2780 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2781 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2782 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2783 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2784 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2785 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2786 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2787 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2788 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2789 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2790 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2791 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2792 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2793 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2794 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2795 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2796 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2797 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2798 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2799 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2800 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2801 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2802 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2803 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2804 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2805 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2806 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2807 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2808 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2809 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2810 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2811 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2812 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2813 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2814 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2815 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2816 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2817 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2818 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2819 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2820 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2821 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2822 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2823 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2824 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2825 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2826 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2827 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2828 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2829 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2830 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2831 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2832 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2833 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2834 loss= tensor(0.0326, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2835 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2836 loss= tensor(0.0303, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2837 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2838 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2839 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2840 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2841 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2842 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2843 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2844 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2845 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2846 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2847 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2848 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2849 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2850 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2851 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2852 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2853 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2854 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2855 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2856 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2857 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2858 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2859 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2860 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2861 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2862 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2863 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2864 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2865 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2866 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2867 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2868 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2869 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2870 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2871 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2872 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2873 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2874 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2875 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2876 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2877 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2878 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2879 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2880 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2881 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2882 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2883 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2884 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2885 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2886 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2887 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2888 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2889 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2890 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2891 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2892 loss= tensor(0.0350, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2893 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2894 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2895 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2896 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2897 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2898 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2899 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2900 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2901 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2902 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2903 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2904 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2905 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2906 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2907 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2908 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2909 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2910 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2911 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2912 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2913 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2914 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2915 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2916 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2917 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2918 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2919 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2920 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2921 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2922 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2923 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2924 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2925 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2926 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2927 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2928 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2929 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2930 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2931 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2932 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2933 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2934 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2935 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2936 loss= tensor(0.0289, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2937 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2938 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2939 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2940 loss= tensor(0.0406, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2941 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2942 loss= tensor(0.0396, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2943 loss= tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2944 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2945 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2946 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2947 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2948 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2949 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2950 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2951 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2952 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2953 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2954 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2955 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2956 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2957 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2958 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2959 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2960 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2961 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2962 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2963 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2964 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2965 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2966 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2967 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2968 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2969 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2970 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2971 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2972 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2973 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2974 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2975 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2976 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2977 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2978 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2979 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2980 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2981 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2982 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2983 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2984 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2985 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2986 loss= tensor(0.0259, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2987 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2988 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2989 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2990 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2991 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2992 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2993 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2994 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2995 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2996 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2997 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2998 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 2999 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3000 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3001 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3002 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3003 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3004 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3005 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3006 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3007 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3008 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3009 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3010 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3011 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3012 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3013 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3014 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3015 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3016 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3017 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3018 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3019 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3020 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3021 loss= tensor(0.0308, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3022 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3023 loss= tensor(0.0511, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3024 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3025 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3026 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3027 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3028 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3029 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3030 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3031 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3032 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3033 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3034 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3035 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3036 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3037 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3038 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3039 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3040 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3041 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3042 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3043 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3044 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3045 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3046 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3047 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3048 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3049 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3050 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3051 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3052 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3053 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3054 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3055 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3056 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3057 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3058 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3059 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3060 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3061 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3062 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3063 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3064 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3065 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3066 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3067 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3068 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3069 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3070 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3071 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3072 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3073 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3074 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3075 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3076 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3077 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3078 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3079 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3080 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3081 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3082 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3083 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3084 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3085 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3086 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3087 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3088 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3089 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3090 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3091 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3092 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3093 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3094 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3095 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3096 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3097 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3098 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3099 loss= tensor(0.0531, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3100 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3101 loss= tensor(0.0436, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3102 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3103 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3104 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3105 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3106 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3107 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3108 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3109 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3110 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3111 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3112 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3113 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3114 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3115 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3116 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3117 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3118 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3119 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3120 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3121 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3122 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3123 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3124 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3125 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3126 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3127 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3128 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3129 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3130 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3131 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3132 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3133 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3134 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3135 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3136 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3137 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3138 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3139 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3140 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3141 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3142 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3143 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3144 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3145 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3146 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3147 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3148 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3149 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3150 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3151 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3152 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3153 loss= tensor(0.0297, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3154 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3155 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3156 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3157 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3158 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3159 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3160 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3161 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3162 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3163 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3164 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3165 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3166 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3167 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3168 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3169 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3170 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3171 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3172 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3173 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3174 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3175 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3176 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3177 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3178 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3179 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3180 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3181 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3182 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3183 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3184 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3185 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3186 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3187 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3188 loss= tensor(0.0261, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3189 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3190 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3191 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3192 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3193 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3194 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3195 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3196 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3197 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3198 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3199 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3200 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3201 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3202 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3203 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3204 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3205 loss= tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3206 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3207 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3208 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3209 loss= tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3210 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3211 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3212 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3213 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3214 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3215 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3216 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3217 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3218 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3219 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3220 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3221 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3222 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3223 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3224 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3225 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3226 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3227 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3228 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3229 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3230 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3231 loss= tensor(0.0408, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3232 loss= tensor(0.0290, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3233 loss= tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3234 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3235 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3236 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3237 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3238 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3239 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3240 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3241 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3242 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3243 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3244 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3245 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3246 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3247 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3248 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3249 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3250 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3251 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3252 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3253 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3254 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3255 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3256 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3257 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3258 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3259 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3260 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3261 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3262 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3263 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3264 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3265 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3266 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3267 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3268 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3269 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3270 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3271 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3272 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3273 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3274 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3275 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3276 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3277 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3278 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3279 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3280 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3281 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3282 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3283 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3284 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3285 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3286 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3287 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3288 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3289 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3290 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3291 loss= tensor(0.0370, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3292 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3293 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3294 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3295 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3296 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3297 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3298 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3299 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3300 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3301 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3302 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3303 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3304 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3305 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3306 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3307 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3308 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3309 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3310 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3311 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3312 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3313 loss= tensor(0.0284, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3314 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3315 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3316 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3317 loss= tensor(0.0435, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3318 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3319 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3320 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3321 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3322 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3323 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3324 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3325 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3326 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3327 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3328 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3329 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3330 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3331 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3332 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3333 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3334 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3335 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3336 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3337 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3338 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3339 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3340 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3341 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3342 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3343 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3344 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3345 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3346 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3347 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3348 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3349 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3350 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3351 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3352 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3353 loss= tensor(0.0274, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3354 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3355 loss= tensor(0.0301, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3356 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3357 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3358 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3359 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3360 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3361 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3362 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3363 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3364 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3365 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3366 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3367 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3368 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3369 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3370 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3371 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3372 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3373 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3374 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3375 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3376 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3377 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3378 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3379 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3380 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3381 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3382 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3383 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3384 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3385 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3386 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3387 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3388 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3389 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3390 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3391 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3392 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3393 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3394 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3395 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3396 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3397 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3398 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3399 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3400 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3401 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3402 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3403 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3404 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3405 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3406 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3407 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3408 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3409 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3410 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3411 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3412 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3413 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3414 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3415 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3416 loss= tensor(0.0305, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3417 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3418 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3419 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3420 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3421 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3422 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3423 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3424 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3425 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3426 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3427 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3428 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3429 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3430 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3431 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3432 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3433 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3434 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3435 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3436 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3437 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3438 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3439 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3440 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3441 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3442 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3443 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3444 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3445 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3446 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3447 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3448 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3449 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3450 loss= tensor(0.0302, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3451 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3452 loss= tensor(0.0310, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3453 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3454 loss= tensor(0.0242, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3455 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3456 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3457 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3458 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3459 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3460 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3461 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3462 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3463 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3464 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3465 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3466 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3467 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3468 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3469 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3470 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3471 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3472 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3473 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3474 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3475 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3476 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3477 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3478 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3479 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3480 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3481 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3482 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3483 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3484 loss= tensor(0.0329, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3485 loss= tensor(0.0471, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3486 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3487 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3488 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3489 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3490 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3491 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3492 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3493 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3494 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3495 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3496 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3497 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3498 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3499 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3500 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3501 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3502 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3503 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3504 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3505 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3506 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3507 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3508 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3509 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3510 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3511 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3512 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3513 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3514 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3515 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3516 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3517 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3518 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3519 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3520 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3521 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3522 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3523 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3524 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3525 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3526 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3527 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3528 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3529 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3530 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3531 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3532 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3533 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3534 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3535 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3536 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3537 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3538 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3539 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3540 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3541 loss= tensor(0.0275, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3542 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3543 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3544 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3545 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3546 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3547 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3548 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3549 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3550 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3551 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3552 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3553 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3554 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3555 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3556 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3557 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3558 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3559 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3560 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3561 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3562 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3563 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3564 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3565 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3566 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3567 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3568 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3569 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3570 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3571 loss= tensor(0.0336, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3572 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3573 loss= tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3574 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3575 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3576 loss= tensor(0.0273, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3577 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3578 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3579 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3580 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3581 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3582 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3583 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3584 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3585 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3586 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3587 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3588 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3589 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3590 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3591 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3592 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3593 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3594 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3595 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3596 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3597 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3598 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3599 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3600 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3601 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3602 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3603 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3604 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3605 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3606 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3607 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3608 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3609 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3610 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3611 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3612 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3613 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3614 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3615 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3616 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3617 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3618 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3619 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3620 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3621 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3622 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3623 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3624 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3625 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3626 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3627 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3628 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3629 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3630 loss= tensor(0.0364, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3631 loss= tensor(0.0256, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3632 loss= tensor(0.0347, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3633 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3634 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3635 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3636 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3637 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3638 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3639 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3640 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3641 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3642 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3643 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3644 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3645 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3646 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3647 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3648 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3649 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3650 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3651 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3652 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3653 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3654 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3655 loss= tensor(0.0238, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3656 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3657 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3658 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3659 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3660 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3661 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3662 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3663 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3664 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3665 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3666 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3667 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3668 loss= tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3669 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3670 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3671 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3672 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3673 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3674 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3675 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3676 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3677 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3678 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3679 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3680 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3681 loss= tensor(0.0345, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3682 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3683 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3684 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3685 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3686 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3687 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3688 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3689 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3690 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3691 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3692 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3693 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3694 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3695 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3696 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3697 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3698 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3699 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3700 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3701 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3702 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3703 loss= tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3704 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3705 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3706 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3707 loss= tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3708 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3709 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3710 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3711 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3712 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3713 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3714 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3715 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3716 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3717 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3718 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3719 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3720 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3721 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3722 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3723 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3724 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3725 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3726 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3727 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3728 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3729 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3730 loss= tensor(0.0331, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3731 loss= tensor(0.0268, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3732 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3733 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3734 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3735 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3736 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3737 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3738 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3739 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3740 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3741 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3742 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3743 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3744 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3745 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3746 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3747 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3748 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3749 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3750 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3751 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3752 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3753 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3754 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3755 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3756 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3757 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3758 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3759 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3760 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3761 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3762 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3763 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3764 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3765 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3766 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3767 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3768 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3769 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3770 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3771 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3772 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3773 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3774 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3775 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3776 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3777 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3778 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3779 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3780 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3781 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3782 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3783 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3784 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3785 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3786 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3787 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3788 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3789 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3790 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3791 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3792 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3793 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3794 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3795 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3796 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3797 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3798 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3799 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3800 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3801 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3802 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3803 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3804 loss= tensor(0.0215, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3805 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3806 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3807 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3808 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3809 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3810 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3811 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3812 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3813 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3814 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3815 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3816 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3817 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3818 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3819 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3820 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3821 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3822 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3823 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3824 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3825 loss= tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3826 loss= tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3827 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3828 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3829 loss= tensor(0.0276, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3830 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3831 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3832 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3833 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3834 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3835 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3836 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3837 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3838 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3839 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3840 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3841 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3842 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3843 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3844 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3845 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3846 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3847 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3848 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3849 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3850 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3851 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3852 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3853 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3854 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3855 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3856 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3857 loss= tensor(0.0320, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3858 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3859 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3860 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3861 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3862 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3863 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3864 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3865 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3866 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3867 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3868 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3869 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3870 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3871 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3872 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3873 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3874 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3875 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3876 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3877 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3878 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3879 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3880 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3881 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3882 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3883 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3884 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3885 loss= tensor(0.0359, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3886 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3887 loss= tensor(0.0286, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3888 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3889 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3890 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3891 loss= tensor(0.0220, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3892 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3893 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3894 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3895 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3896 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3897 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3898 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3899 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3900 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3901 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3902 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3903 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3904 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3905 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3906 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3907 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3908 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3909 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3910 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3911 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3912 loss= tensor(0.0264, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3913 loss= tensor(0.0265, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3914 loss= tensor(0.0344, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3915 loss= tensor(0.0234, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3916 loss= tensor(0.0281, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3917 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3918 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3919 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3920 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3921 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3922 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3923 loss= tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3924 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3925 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3926 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3927 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3928 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3929 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3930 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3931 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3932 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3933 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3934 loss= tensor(0.0248, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3935 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3936 loss= tensor(0.0299, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3937 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3938 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3939 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3940 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3941 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3942 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3943 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3944 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3945 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3946 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3947 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3948 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3949 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3950 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3951 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3952 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3953 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3954 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3955 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3956 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3957 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3958 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3959 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3960 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3961 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3962 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3963 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3964 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3965 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3966 loss= tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3967 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3968 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3969 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3970 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3971 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3972 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3973 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3974 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3975 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3976 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3977 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3978 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3979 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3980 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3981 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3982 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3983 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3984 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3985 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3986 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3987 loss= tensor(0.0319, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3988 loss= tensor(0.0272, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3989 loss= tensor(0.0351, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3990 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3991 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3992 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3993 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3994 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3995 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3996 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3997 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3998 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 3999 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4000 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4001 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4002 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4003 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4004 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4005 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4006 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4007 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4008 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4009 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4010 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4011 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4012 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4013 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4014 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4015 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4016 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4017 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4018 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4019 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4020 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4021 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4022 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4023 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4024 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4025 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4026 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4027 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4028 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4029 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4030 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4031 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4032 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4033 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4034 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4035 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4036 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4037 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4038 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4039 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4040 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4041 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4042 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4043 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4044 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4045 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4046 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4047 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4048 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4049 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4050 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4051 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4052 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4053 loss= tensor(0.0296, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4054 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4055 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4056 loss= tensor(0.0204, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4057 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4058 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4059 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4060 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4061 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4062 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4063 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4064 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4065 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4066 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4067 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4068 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4069 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4070 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4071 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4072 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4073 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4074 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4075 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4076 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4077 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4078 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4079 loss= tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4080 loss= tensor(0.0311, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4081 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4082 loss= tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4083 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4084 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4085 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4086 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4087 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4088 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4089 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4090 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4091 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4092 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4093 loss= tensor(0.0095, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4094 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4095 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4096 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4097 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4098 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4099 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4100 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4101 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4102 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4103 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4104 loss= tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4105 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4106 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4107 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4108 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4109 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4110 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4111 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4112 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4113 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4114 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4115 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4116 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4117 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4118 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4119 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4120 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4121 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4122 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4123 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4124 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4125 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4126 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4127 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4128 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4129 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4130 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4131 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4132 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4133 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4134 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4135 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4136 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4137 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4138 loss= tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4139 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4140 loss= tensor(0.0295, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4141 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4142 loss= tensor(0.0280, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4143 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4144 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4145 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4146 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4147 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4148 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4149 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4150 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4151 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4152 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4153 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4154 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4155 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4156 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4157 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4158 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4159 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4160 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4161 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4162 loss= tensor(0.0213, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4163 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4164 loss= tensor(0.0278, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4165 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4166 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4167 loss= tensor(0.0322, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4168 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4169 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4170 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4171 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4172 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4173 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4174 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4175 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4176 loss= tensor(0.0091, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4177 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4178 loss= tensor(0.0097, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4179 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4180 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4181 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4182 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4183 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4184 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4185 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4186 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4187 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4188 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4189 loss= tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4190 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4191 loss= tensor(0.0260, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4192 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4193 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4194 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4195 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4196 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4197 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4198 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4199 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4200 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4201 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4202 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4203 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4204 loss= tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4205 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4206 loss= tensor(0.0337, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4207 loss= tensor(0.0355, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4208 loss= tensor(0.0315, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4209 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4210 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4211 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4212 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4213 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4214 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4215 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4216 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4217 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4218 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4219 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4220 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4221 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4222 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4223 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4224 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4225 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4226 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4227 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4228 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4229 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4230 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4231 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4232 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4233 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4234 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4235 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4236 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4237 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4238 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4239 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4240 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4241 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4242 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4243 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4244 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4245 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4246 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4247 loss= tensor(0.0239, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4248 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4249 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4250 loss= tensor(0.0426, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4251 loss= tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4252 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4253 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4254 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4255 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4256 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4257 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4258 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4259 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4260 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4261 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4262 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4263 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4264 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4265 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4266 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4267 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4268 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4269 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4270 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4271 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4272 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4273 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4274 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4275 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4276 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4277 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4278 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4279 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4280 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4281 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4282 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4283 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4284 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4285 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4286 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4287 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4288 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4289 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4290 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4291 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4292 loss= tensor(0.0348, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4293 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4294 loss= tensor(0.0245, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4295 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4296 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4297 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4298 loss= tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4299 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4300 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4301 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4302 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4303 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4304 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4305 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4306 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4307 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4308 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4309 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4310 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4311 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4312 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4313 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4314 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4315 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4316 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4317 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4318 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4319 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4320 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4321 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4322 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4323 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4324 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4325 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4326 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4327 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4328 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4329 loss= tensor(0.0354, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4330 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4331 loss= tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4332 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4333 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4334 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4335 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4336 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4337 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4338 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4339 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4340 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4341 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4342 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4343 loss= tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4344 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4345 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4346 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4347 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4348 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4349 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4350 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4351 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4352 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4353 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4354 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4355 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4356 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4357 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4358 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4359 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4360 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4361 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4362 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4363 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4364 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4365 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4366 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4367 loss= tensor(0.0249, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4368 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4369 loss= tensor(0.0246, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4370 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4371 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4372 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4373 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4374 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4375 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4376 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4377 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4378 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4379 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4380 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4381 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4382 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4383 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4384 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4385 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4386 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4387 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4388 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4389 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4390 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4391 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4392 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4393 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4394 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4395 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4396 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4397 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4398 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4399 loss= tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4400 loss= tensor(0.0386, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4401 loss= tensor(0.0292, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4402 loss= tensor(0.0339, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4403 loss= tensor(0.0212, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4404 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4405 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4406 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4407 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4408 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4409 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4410 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4411 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4412 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4413 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4414 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4415 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4416 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4417 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4418 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4419 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4420 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4421 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4422 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4423 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4424 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4425 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4426 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4427 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4428 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4429 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4430 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4431 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4432 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4433 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4434 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4435 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4436 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4437 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4438 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4439 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4440 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4441 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4442 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4443 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4444 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4445 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4446 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4447 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4448 loss= tensor(0.0252, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4449 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4450 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4451 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4452 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4453 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4454 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4455 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4456 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4457 loss= tensor(0.0168, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4458 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4459 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4460 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4461 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4462 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4463 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4464 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4465 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4466 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4467 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4468 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4469 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4470 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4471 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4472 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4473 loss= tensor(0.0111, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4474 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4475 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4476 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4477 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4478 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4479 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4480 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4481 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4482 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4483 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4484 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4485 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4486 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4487 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4488 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4489 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4490 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4491 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4492 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4493 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4494 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4495 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4496 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4497 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4498 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4499 loss= tensor(0.0207, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4500 loss= tensor(0.0313, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4501 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4502 loss= tensor(0.0423, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4503 loss= tensor(0.0271, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4504 loss= tensor(0.0324, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4505 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4506 loss= tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4507 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4508 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4509 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4510 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4511 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4512 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4513 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4514 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4515 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4516 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4517 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4518 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4519 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4520 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4521 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4522 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4523 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4524 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4525 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4526 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4527 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4528 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4529 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4530 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4531 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4532 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4533 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4534 loss= tensor(0.0206, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4535 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4536 loss= tensor(0.0217, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4537 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4538 loss= tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4539 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4540 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4541 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4542 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4543 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4544 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4545 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4546 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4547 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4548 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4549 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4550 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4551 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4552 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4553 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4554 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4555 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4556 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4557 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4558 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4559 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4560 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4561 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4562 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4563 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4564 loss= tensor(0.0227, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4565 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4566 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4567 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4568 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4569 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4570 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4571 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4572 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4573 loss= tensor(0.0193, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4574 loss= tensor(0.0198, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4575 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4576 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4577 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4578 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4579 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4580 loss= tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4581 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4582 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4583 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4584 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4585 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4586 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4587 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4588 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4589 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4590 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4591 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4592 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4593 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4594 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4595 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4596 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4597 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4598 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4599 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4600 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4601 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4602 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4603 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4604 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4605 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4606 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4607 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4608 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4609 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4610 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4611 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4612 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4613 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4614 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4615 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4616 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4617 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4618 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4619 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4620 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4621 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4622 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4623 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4624 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4625 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4626 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4627 loss= tensor(0.0211, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4628 loss= tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4629 loss= tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4630 loss= tensor(0.0419, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4631 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4632 loss= tensor(0.0244, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4633 loss= tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4634 loss= tensor(0.0219, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4635 loss= tensor(0.0181, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4636 loss= tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4637 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4638 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4639 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4640 loss= tensor(0.0157, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4641 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4642 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4643 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4644 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4645 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4646 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4647 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4648 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4649 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4650 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4651 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4652 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4653 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4654 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4655 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4656 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4657 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4658 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4659 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4660 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4661 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4662 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4663 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4664 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4665 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4666 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4667 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4668 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4669 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4670 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4671 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4672 loss= tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4673 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4674 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4675 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4676 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4677 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4678 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4679 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4680 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4681 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4682 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4683 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4684 loss= tensor(0.0210, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4685 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4686 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4687 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4688 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4689 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4690 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4691 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4692 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4693 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4694 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4695 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4696 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4697 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4698 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4699 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4700 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4701 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4702 loss= tensor(0.0205, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4703 loss= tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4704 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4705 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4706 loss= tensor(0.0258, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4707 loss= tensor(0.0338, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4708 loss= tensor(0.0230, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4709 loss= tensor(0.0294, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4710 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4711 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4712 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4713 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4714 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4715 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4716 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4717 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4718 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4719 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4720 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4721 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4722 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4723 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4724 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4725 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4726 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4727 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4728 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4729 loss= tensor(0.0192, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4730 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4731 loss= tensor(0.0226, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4732 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4733 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4734 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4735 loss= tensor(0.0231, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4736 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4737 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4738 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4739 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4740 loss= tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4741 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4742 loss= tensor(0.0098, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4743 loss= tensor(0.0105, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4744 loss= tensor(0.0089, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4745 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4746 loss= tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4747 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4748 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4749 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4750 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4751 loss= tensor(0.0138, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4752 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4753 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4754 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4755 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4756 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4757 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4758 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4759 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4760 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4761 loss= tensor(0.0221, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4762 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4763 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4764 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4765 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4766 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4767 loss= tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4768 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4769 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4770 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4771 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4772 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4773 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4774 loss= tensor(0.0170, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4775 loss= tensor(0.0237, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4776 loss= tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4777 loss= tensor(0.0407, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4778 loss= tensor(0.0457, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4779 loss= tensor(0.0334, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4780 loss= tensor(0.0279, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4781 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4782 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4783 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4784 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4785 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4786 loss= tensor(0.0109, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4787 loss= tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4788 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4789 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4790 loss= tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4791 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4792 loss= tensor(0.0093, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4793 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4794 loss= tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4795 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4796 loss= tensor(0.0099, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4797 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4798 loss= tensor(0.0104, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4799 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4800 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4801 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4802 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4803 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4804 loss= tensor(0.0160, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4805 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4806 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4807 loss= tensor(0.0229, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4808 loss= tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4809 loss= tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4810 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4811 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4812 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4813 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4814 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4815 loss= tensor(0.0162, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4816 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4817 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4818 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4819 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4820 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4821 loss= tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4822 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4823 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4824 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4825 loss= tensor(0.0199, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4826 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4827 loss= tensor(0.0228, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4828 loss= tensor(0.0191, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4829 loss= tensor(0.0223, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4830 loss= tensor(0.0179, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4831 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4832 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4833 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4834 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4835 loss= tensor(0.0156, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4836 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4837 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4838 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4839 loss= tensor(0.0124, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4840 loss= tensor(0.0117, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4841 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4842 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4843 loss= tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4844 loss= tensor(0.0110, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4845 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4846 loss= tensor(0.0153, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4847 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4848 loss= tensor(0.0287, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4849 loss= tensor(0.0203, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4850 loss= tensor(0.0314, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4851 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4852 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4853 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4854 loss= tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4855 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4856 loss= tensor(0.0187, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4857 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4858 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4859 loss= tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4860 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4861 loss= tensor(0.0100, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4862 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4863 loss= tensor(0.0103, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4864 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4865 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4866 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4867 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4868 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4869 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4870 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4871 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4872 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4873 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4874 loss= tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4875 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4876 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4877 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4878 loss= tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4879 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4880 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4881 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4882 loss= tensor(0.0176, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4883 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4884 loss= tensor(0.0154, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4885 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4886 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4887 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4888 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4889 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4890 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4891 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4892 loss= tensor(0.0247, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4893 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4894 loss= tensor(0.0257, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4895 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4896 loss= tensor(0.0235, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4897 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4898 loss= tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4899 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4900 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4901 loss= tensor(0.0135, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4902 loss= tensor(0.0158, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4903 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4904 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4905 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4906 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4907 loss= tensor(0.0126, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4908 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4909 loss= tensor(0.0129, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4910 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4911 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4912 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4913 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4914 loss= tensor(0.0145, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4915 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4916 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4917 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4918 loss= tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4919 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4920 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4921 loss= tensor(0.0123, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4922 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4923 loss= tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4924 loss= tensor(0.0133, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4925 loss= tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4926 loss= tensor(0.0132, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4927 loss= tensor(0.0113, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4928 loss= tensor(0.0139, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4929 loss= tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4930 loss= tensor(0.0141, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4931 loss= tensor(0.0120, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4932 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4933 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4934 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4935 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4936 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4937 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4938 loss= tensor(0.0167, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4939 loss= tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4940 loss= tensor(0.0202, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4941 loss= tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4942 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4943 loss= tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4944 loss= tensor(0.0232, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4945 loss= tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4946 loss= tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4947 loss= tensor(0.0291, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4948 loss= tensor(0.0163, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4949 loss= tensor(0.0188, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4950 loss= tensor(0.0131, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4951 loss= tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4952 loss= tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4953 loss= tensor(0.0180, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4954 loss= tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4955 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4956 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4957 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4958 loss= tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4959 loss= tensor(0.0184, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4960 loss= tensor(0.0144, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4961 loss= tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4962 loss= tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4963 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4964 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4965 loss= tensor(0.0190, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4966 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4967 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4968 loss= tensor(0.0146, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4969 loss= tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4970 loss= tensor(0.0147, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4971 loss= tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4972 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4973 loss= tensor(0.0177, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4974 loss= tensor(0.0149, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4975 loss= tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4976 loss= tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4977 loss= tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4978 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4979 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4980 loss= tensor(0.0121, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4981 loss= tensor(0.0151, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4982 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4983 loss= tensor(0.0148, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4984 loss= tensor(0.0118, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4985 loss= tensor(0.0152, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4986 loss= tensor(0.0125, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4987 loss= tensor(0.0182, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4988 loss= tensor(0.0150, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4989 loss= tensor(0.0225, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4990 loss= tensor(0.0172, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4991 loss= tensor(0.0250, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4992 loss= tensor(0.0159, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4993 loss= tensor(0.0194, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4994 loss= tensor(0.0142, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4995 loss= tensor(0.0174, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4996 loss= tensor(0.0130, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4997 loss= tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4998 loss= tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch= 4999 loss= tensor(0.0140, grad_fn=<MseLossBackward0>)\n",
      "epoch= 5000 loss= tensor(0.0115, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# GIFアニメーションを作成\n",
    "def create_gif(in_dir, out_filename):\n",
    "    path_list = sorted(glob.glob(os.path.join(*[in_dir, '*'])))  # ファイルパスをソートしてリストする\n",
    "    imgs = []  # 画像をappendするための空配列を定義\n",
    "\n",
    "    # ファイルのフルパスからファイル名と拡張子を抽出\n",
    "    for i in range(len(path_list)):\n",
    "        img = Image.open(path_list[i])  # 画像ファイルを1つずつ開く\n",
    "        imgs.append(img)  # 画像をappendで配列に格納していく\n",
    "\n",
    "    # appendした画像配列をGIFにする。durationで持続時間、loopでループ数を指定可能。\n",
    "    imgs[0].save(out_filename,\n",
    "                 save_all=True, append_images=imgs[1:], optimize=False, duration=100, loop=0)\n",
    "\n",
    "# 線形回帰ネットワークのclassをnn.Moduleの継承で定義\n",
    "class Regression(nn.Module):\n",
    "    # コンストラクタ(インスタンス生成時の初期化)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    # メソッド(ネットワークをシーケンシャルに定義)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.linear1(x))\n",
    "        x = nn.functional.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "# トレーニング関数\n",
    "def train(model, optimizer, E, iteration, x, y):\n",
    "    # 学習ループ\n",
    "    losses = []\n",
    "    for i in range(iteration):\n",
    "        optimizer.zero_grad()                   # 勾配情報を0に初期化\n",
    "        y_pred = model(x)                       # 予測\n",
    "        loss = E(y_pred.reshape(y.shape), y)    # 損失を計算(shapeを揃える)\n",
    "        loss.backward()                         # 勾配の計算\n",
    "        optimizer.step()                        # 勾配の更新\n",
    "        losses.append(loss.item())              # 損失値の蓄積\n",
    "        print('epoch=', i+1, 'loss=', loss)\n",
    "\n",
    "        #グラフ描画\n",
    "        X1 = np.arange(0, 11, 0.5)                                                # x軸を作成\n",
    "        X2 = np.arange(0, 11, 0.5)                                                # y軸を作成\n",
    "        X, Y = np.meshgrid(X1, X2)                                                # x軸とy軸からグリッドデータを作成\n",
    "\n",
    "        X2 = torch.from_numpy(X.ravel().astype(np.float32)).float()  # xをテンソルに変換\n",
    "        Y2 = torch.from_numpy(Y.ravel().astype(np.float32)).float() # xをテンソルに変換\n",
    "        Input = torch.stack([torch.ones(len(X.ravel())), X2, Y2], 1)  # xに切片用の定数1配列を結合\n",
    "\n",
    "        # 50計算毎にプロットを保存\n",
    "        if (i + 1) % 50 == 0:\n",
    "            Z = test(model, Input).reshape(X.shape)\n",
    "            plot_3d(x.T[1], x.T[2], y, X, Y, Z, losses, 'out', i+1)\n",
    "    return model, losses\n",
    "\n",
    "def test(model, x):\n",
    "    y_pred = model(x).data.numpy()  # 予測\n",
    "    return y_pred\n",
    "\n",
    "# グラフ描画関数\n",
    "def plot_3d(x1, x2, z, X, Y, Z, losses, dir, index):\n",
    "    # ここからグラフ描画-------------------------------------------------\n",
    "    # フォントの種類とサイズを設定する。\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "    # 目盛を内側にする。\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "    # グラフの上下左右に目盛線を付ける。\n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.yaxis.set_ticks_position('both')\n",
    "    ax1.xaxis.set_ticks_position('both')\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.yaxis.set_ticks_position('both')\n",
    "    ax2.xaxis.set_ticks_position('both')\n",
    "\n",
    "    # 軸のラベルを設定する。\n",
    "    ax1.set_xlabel('x1')\n",
    "    ax1.set_ylabel('x2')\n",
    "    ax1.set_zlabel('y')\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('E')\n",
    "\n",
    "    # スケール設定\n",
    "    ax1.set_xlim(0, 10)\n",
    "    ax1.set_ylim(0, 10)\n",
    "    ax1.set_zlim(-2, 2)\n",
    "    ax2.set_xlim(0, 5000)\n",
    "    ax2.set_ylim(0.001, 10)\n",
    "    ax2.set_yscale('log')\n",
    "\n",
    "    # データプロット\n",
    "    ax1.scatter3D(x1, x2, z, label='dataset')\n",
    "    ax1.plot_wireframe(X, Y, Z, color='red', label='PyTorch result')\n",
    "    ax2.plot(np.arange(0, len(losses), 1), losses)\n",
    "    ax2.scatter(len(losses), losses[len(losses) - 1], color='red')\n",
    "    ax2.text(600, 0.3, 'Loss=' + str(round(losses[len(losses)-1], 2)), fontsize=16)\n",
    "    ax2.text(600, 0.5, 'Iteration=' + str(round(len(losses), 1)), fontsize=16)\n",
    "\n",
    "    # グラフを表示する。\n",
    "    ax1.legend(bbox_to_anchor=(0, 1), loc='upper left')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # dirフォルダが無い時に新規作成\n",
    "    if os.path.exists(dir):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(dir)\n",
    "\n",
    "    # 画像保存パスを準備\n",
    "    path = os.path.join(*[dir, str(\"{:05}\".format(index)) + '.png'])\n",
    "\n",
    "    # 画像を保存する\n",
    "    plt.savefig(path)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------\n",
    "\n",
    "# トレーニングデータ\n",
    "x1 = np.random.uniform(0, 10, 30)                                     # ノイズを含んだx軸を作成\n",
    "x2 = np.random.uniform(0, 10, 30)                                     # ノイズを含んだy軸を作成\n",
    "grid_x, grid_y = np.meshgrid(x1, x2)                                  # Gridデータを作成\n",
    "z = np.sin(grid_x.ravel()) * np.cos(grid_y.ravel())                   # ノイズを含んだ平面点列データを作成\n",
    "\n",
    "grid_x = torch.from_numpy(grid_x.ravel().astype(np.float32)).float()  # grid_xをテンソルに変換\n",
    "grid_y = torch.from_numpy(grid_y.ravel().astype(np.float32)).float()  # grid_yをテンソルに変換\n",
    "z = torch.from_numpy(z.astype(np.float32)).float()                    # yをテンソルに変換\n",
    "X = torch.stack([torch.ones(len(grid_x)), grid_x, grid_y], 1)  # xに切片用の定数1配列を結合\n",
    "\n",
    "# ネットワークのインスタンスを生成\n",
    "net = Regression()\n",
    "\n",
    "# 最適化アルゴリズムと損失関数を設定\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)                # 最適化にRMSpropを設定\n",
    "E = nn.MSELoss()                                                    # 損失関数にMSEを設定\n",
    "\n",
    "# トレーニング\n",
    "net, losses = train(model=net, optimizer=optimizer, E=E, iteration=5000, x=X, y=z)\n",
    "\n",
    "# GIFアニメーションを作成する関数を実行する\n",
    "create_gif(in_dir='out', out_filename='pytorch-2d-sincos-regression.gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
