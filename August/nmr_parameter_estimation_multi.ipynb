{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルからデータを読み込む例\n",
    "data1 = pd.read_csv('xy(1).csv')\n",
    "data2 = pd.read_csv('xy(2).csv')\n",
    "data3 = pd.read_csv('xy(3).csv')\n",
    "\n",
    "x1 = torch.tensor(data1['x'].values, dtype=torch.float32)\n",
    "y1 = torch.tensor(data1['y'].values, dtype=torch.float32)\n",
    "x2 = torch.tensor(data2['x'].values, dtype=torch.float32)\n",
    "y2 = torch.tensor(data2['y'].values, dtype=torch.float32)\n",
    "x3 = torch.tensor(data3['x'].values, dtype=torch.float32)\n",
    "y3 = torch.tensor(data3['y'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_data_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 91\u001b[0m\n\u001b[1;32m     88\u001b[0m p2_grads \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# データとラベルを結合\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m x_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[43mx_data_combined\u001b[49m, labels_combined])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, (x, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x_labels):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# 1つのx値に対してモデルを計算\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     y_p[j] \u001b[38;5;241m=\u001b[39m model(x[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m], k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_data_combined' is not defined"
     ]
    }
   ],
   "source": [
    "def cross_product(v1, v2):\n",
    "    return torch.cross(v1, v2, dim=0)\n",
    "\n",
    "def magnetic(axis, vec, theta):\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    \n",
    "    axis = axis.unsqueeze(0)  # (1, 3)\n",
    "    vec = vec.unsqueeze(0)    # (1, 3)\n",
    "    \n",
    "    rotated_vecs = []\n",
    "    for i in range(theta.size(0)):\n",
    "        theta_i = theta[i]\n",
    "        cos_theta_i = cos_theta[i]\n",
    "        sin_theta_i = sin_theta[i]\n",
    "        \n",
    "        axis_i = axis[0]\n",
    "        vec_i = vec[0]\n",
    "        \n",
    "        rotated_vec = vec_i * cos_theta_i + cross_product(axis_i, vec_i) * sin_theta_i + axis_i * (torch.matmul(axis_i.unsqueeze(1).T, vec_i.unsqueeze(1)).squeeze() * (1 - cos_theta_i))\n",
    "        rotated_vecs.append(rotated_vec)\n",
    "    \n",
    "    return torch.stack(rotated_vecs)\n",
    "\n",
    "def model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    rad = torch.pi / 180.0  # Conversion factor from degrees to radians\n",
    "    nx = torch.cos(p1 * rad) * torch.sin(t1 * rad)\n",
    "    ny = torch.sin(p1 * rad) * torch.sin(t1 * rad)\n",
    "    nz = torch.cos(t1 * rad)\n",
    "    sx = torch.cos(p2 * rad) * torch.sin(t2 * rad)\n",
    "    sy = torch.sin(p2 * rad) * torch.sin(t2 * rad)\n",
    "    sz = torch.cos(t2 * rad)\n",
    "    theta = x * rad\n",
    "    \n",
    "    E = np.eye(3)\n",
    "    C3 = rotation_matrix([0,0,1], 2.0*np.pi/3.0) # for Te3.\n",
    "    C3i = C3.T # for Te2.\n",
    "    Rs = [E, C3i, C3]\n",
    "    \n",
    "    nt = cross_product([nx,ny,nz], [sx,sy,sz])\n",
    "    h = magnetic(torch.stack([nx, ny, nz]), torch.stack([sx, sy, sz]), theta)\n",
    "    ht = magnetic(torch.stack([nt]), torch.stack([sx,sy,sz]), theta)\n",
    "    K = torch.stack([\n",
    "    torch.stack([k1, k6, k5]),\n",
    "    torch.stack([k6, k2, k4]),\n",
    "    torch.stack([k5, k4, k3])\n",
    "    ])    \n",
    "    # 63個のスカラー結果を得るための計算\n",
    "    Ks = [torch.einsum(R, K, R.T) for R in Rs]\n",
    "    return Ks\n",
    "\n",
    "Ks = model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "\n",
    "def model_K1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    K1 = torch.einsum('ij,jk,ik->i', h, Ks[0], h)\n",
    "    return K1\n",
    "\n",
    "def model_K2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    K2 = torch.einsum('ij,jk,ik->i', h, Ks[1], h)\n",
    "    return K2\n",
    "\n",
    "def model_K3(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    K3 = torch.einsum('ij,jk,ik->i', h, Ks[2], h)\n",
    "    return K3\n",
    "\n",
    "# パラメータの定義\n",
    "k1 = torch.tensor(-8.572, requires_grad=True)\n",
    "k2 = torch.tensor(1.146, requires_grad=True)\n",
    "k3 = torch.tensor(0.0, requires_grad=True)\n",
    "k4 = torch.tensor(8.830, requires_grad=True)\n",
    "k5 = torch.tensor(0.0, requires_grad=True)\n",
    "k6 = torch.tensor(0.0, requires_grad=True)\n",
    "t1 = torch.tensor(0.0, requires_grad=True)\n",
    "p1 = torch.tensor(0.0, requires_grad=True)\n",
    "t2 = torch.tensor(90.0, requires_grad=True)\n",
    "p2 = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "# 各xに対する勾配計算の準備\n",
    "k1_grads = []\n",
    "k2_grads = []\n",
    "k3_grads = []\n",
    "k4_grads = []\n",
    "k5_grads = []\n",
    "k6_grads = []\n",
    "t1_grads = []\n",
    "p1_grads = []\n",
    "t2_grads = []\n",
    "p2_grads = []\n",
    "\n",
    "# データとラベルを結合\n",
    "x_labels = np.vstack([x_data_combined, labels_combined]).T\n",
    "\n",
    "\n",
    "for j, (x, label) in enumerate(x_labels):\n",
    "    # 1つのx値に対してモデルを計算\n",
    "    y_p[j] = model(x[i:i+1], k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)[0]\n",
    "    \n",
    "    # 勾配計算のためのテンソル\n",
    "    v = torch.ones_like(y_p)\n",
    "    \n",
    "    # 勾配計算\n",
    "    y_p.backward(v, retain_graph=True)\n",
    "    \n",
    "    # 各パラメータの勾配を保存\n",
    "    k1_grads.append(k1.grad.item())\n",
    "    k2_grads.append(k2.grad.item())\n",
    "    k3_grads.append(k3.grad.item())\n",
    "    k4_grads.append(k4.grad.item())\n",
    "    k5_grads.append(k5.grad.item())\n",
    "    k6_grads.append(k6.grad.item())\n",
    "    t1_grads.append(t1.grad.item())\n",
    "    p1_grads.append(p1.grad.item())\n",
    "    t2_grads.append(t2.grad.item())\n",
    "    p2_grads.append(p2.grad.item())\n",
    "        \n",
    "    # 勾配のリセット\n",
    "    k1.grad.zero_()\n",
    "    k2.grad.zero_()\n",
    "    k3.grad.zero_()\n",
    "    k4.grad.zero_()\n",
    "    k5.grad.zero_()\n",
    "    k6.grad.zero_()\n",
    "    t1.grad.zero_()\n",
    "    p1.grad.zero_()\n",
    "    t2.grad.zero_()\n",
    "    p2.grad.zero_()\n",
    "\n",
    "# リストをtorch.tensorに変換\n",
    "k1_grads = torch.tensor(k1_grads)\n",
    "k2_grads = torch.tensor(k2_grads)\n",
    "k3_grads = torch.tensor(k3_grads)\n",
    "k4_grads = torch.tensor(k4_grads)\n",
    "k5_grads = torch.tensor(k5_grads)\n",
    "k6_grads = torch.tensor(k6_grads)\n",
    "t1_grads = torch.tensor(t1_grads)\n",
    "p1_grads = torch.tensor(p1_grads)\n",
    "t2_grads = torch.tensor(t2_grads)\n",
    "p2_grads = torch.tensor(p2_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(y_p, y):\n",
    "    squared_diffs = (y_p - y)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34.8626, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(y_p, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "loss_rate_of_change_k1 = \\\n",
    "    (loss_fn(model(x, k1 + delta, k2, k3, k4, k5, k6, t1, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1 - delta, k2, k3, k4, k5, k6, t1, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "k1 = k1 - learning_rate * loss_rate_of_change_k1\n",
    "\n",
    "loss_rate_of_change_k2 = \\\n",
    "    (loss_fn(model(x, k1, k2 + delta, k3, k4, k5, k6, t1, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2 - delta, k3, k4, k5, k6, t1, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "k2 = k2 - learning_rate * loss_rate_of_change_k2\n",
    "\n",
    "loss_rate_of_change_k3 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3 + delta, k4, k5, k6, t1, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3 - delta, k4, k5, k6, t1, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "k3 = k3 - learning_rate * loss_rate_of_change_k3\n",
    "\n",
    "loss_rate_of_change_k4 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4 + delta, k5, k6, t1, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4 - delta, k5, k6, t1, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "k4 = k4 - learning_rate * loss_rate_of_change_k4\n",
    "\n",
    "loss_rate_of_change_k5 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4, k5 + delta, k6, t1, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4, k5 - delta, k6, t1, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "k5 = k5 - learning_rate * loss_rate_of_change_k5\n",
    "\n",
    "loss_rate_of_change_k6 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4, k5, k6 + delta, t1, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4, k5, k6 - delta, t1, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "k6 = k6 - learning_rate * loss_rate_of_change_k6\n",
    "\n",
    "loss_rate_of_change_t1 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1 + delta, p1, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1 - delta, p1, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "t1 = t1 - learning_rate * loss_rate_of_change_t1\n",
    "\n",
    "loss_rate_of_change_p1 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1, p1 + delta, t2, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1, p1 - delta, t2, p2), y)) / (2.0 * delta)\n",
    "\n",
    "p1 = p1 - learning_rate * loss_rate_of_change_p1\n",
    "\n",
    "loss_rate_of_change_t2 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2 + delta, p2), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2 - delta, p2), y)) / (2.0 * delta)\n",
    "\n",
    "t2 = t2 - learning_rate * loss_rate_of_change_t2\n",
    "\n",
    "loss_rate_of_change_p2 = \\\n",
    "    (loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2 + delta), y) - \n",
    "     loss_fn(model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2 - delta), y)) / (2.0 * delta)\n",
    "\n",
    "p2 = p2 - learning_rate * loss_rate_of_change_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def dloss_fn(y_p, y):\n",
    "    dsq_diffs = 2 * (y_p - y) / y_p.size(0)  # <1>\n",
    "    return dsq_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmodel_dk1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return k1_grads\n",
    "\n",
    "def dmodel_dk2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return k2_grads\n",
    "\n",
    "def dmodel_dk3(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return k3_grads\n",
    "\n",
    "def dmodel_dk4(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return k4_grads\n",
    "\n",
    "def dmodel_dk5(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return k5_grads\n",
    "\n",
    "def dmodel_dk6(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return k6_grads\n",
    "\n",
    "def dmodel_dt1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return t1_grads\n",
    "\n",
    "def dmodel_dp1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return p1_grads\n",
    "\n",
    "def dmodel_dt2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return t2_grads\n",
    "\n",
    "def dmodel_dp2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    return p2_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def grad_fn(x, y, y_p, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2):\n",
    "    dloss_dyp = dloss_fn(y_p, y)\n",
    "    dloss_dk1 = dloss_dyp * dmodel_dk1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dk2 = dloss_dyp * dmodel_dk2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dk3 = dloss_dyp * dmodel_dk3(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dk4 = dloss_dyp * dmodel_dk4(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dk5 = dloss_dyp * dmodel_dk5(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dk6 = dloss_dyp * dmodel_dk6(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dt1 = dloss_dyp * dmodel_dt1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dp1 = dloss_dyp * dmodel_dp1(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dt2 = dloss_dyp * dmodel_dt2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    dloss_dp2 = dloss_dyp * dmodel_dp2(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)\n",
    "    return torch.stack([dloss_dk1.sum(), dloss_dk2.sum(), dloss_dk3.sum(), dloss_dk4.sum(), dloss_dk5.sum(), dloss_dk6.sum(), dloss_dt1.sum(), dloss_dp1.sum(), dloss_dt2.sum(), dloss_dp2.sum()])  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, x, y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        k1, k2, k3, k4, k5, k6, t1, p1, t2, p2 = params\n",
    "\n",
    "        y_p = model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)  # <1>\n",
    "        loss = loss_fn(y_p, y)\n",
    "        grad = grad_fn(x, y, y_p, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)  # <2>\n",
    "        \n",
    "        print(grad)\n",
    "        print(grad.shape)\n",
    "\n",
    "        params = params - learning_rate * grad\n",
    "\n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss))) # <3>\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, x, y,\n",
    "                  print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        k1, k2, k3, k4, k5, k6, t1, p1, t2, p2 = params\n",
    "\n",
    "        y_p = model(x, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)  # <1>\n",
    "        loss = loss_fn(y_p, y)\n",
    "        grad = grad_fn(x, y, y_p, k1, k2, k3, k4, k5, k6, t1, p1, t2, p2)  # <2>\n",
    "\n",
    "        params = params - learning_rate * grad\n",
    "\n",
    "        if epoch in {1, 2, 3, 10, 11, 99, 100, 4000, 5000}:  # <3>\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "            if print_params:\n",
    "                print('    Params:', params)\n",
    "                print('    Grad:  ', grad)\n",
    "        if epoch in {4, 12, 101}:\n",
    "            print('...')\n",
    "\n",
    "        if not torch.isfinite(loss).all():\n",
    "            break  # <3>\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.023659\n",
      "    Params: tensor([-8.5706e+00,  1.1475e+00,  5.6215e-18,  8.8300e+00, -1.6268e-10,\n",
      "         1.8661e-03,  2.9293e-04,  0.0000e+00,  8.9999e+01,  3.1652e-04],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-1.4471e-01, -1.4950e-01, -5.6215e-16,  1.6465e-08,  1.6268e-08,\n",
      "        -1.8661e-01, -2.9293e-02,  0.0000e+00,  5.8052e-02, -3.1652e-02],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Epoch 2, Loss 0.022834\n",
      "    Params: tensor([-8.5691e+00,  1.1490e+00,  1.1134e-17,  8.8300e+00, -3.2214e-10,\n",
      "         3.6919e-03,  5.8059e-04,  0.0000e+00,  8.9999e+01,  6.2619e-04],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-1.4190e-01, -1.4663e-01, -5.5129e-16,  1.6140e-08,  1.5946e-08,\n",
      "        -1.8258e-01, -2.8767e-02,  0.0000e+00,  5.6905e-02, -3.0968e-02],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Epoch 3, Loss 0.022041\n",
      "    Params: tensor([-8.5677e+00,  1.1504e+00,  1.6541e-17,  8.8300e+00, -4.7845e-10,\n",
      "         5.4782e-03,  8.6310e-04,  0.0000e+00,  8.9998e+01,  9.2917e-04],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-1.3915e-01, -1.4381e-01, -5.4064e-16,  1.5821e-08,  1.5631e-08,\n",
      "        -1.7863e-01, -2.8251e-02,  0.0000e+00,  5.5780e-02, -3.0298e-02],\n",
      "       grad_fn=<StackBackward0>)\n",
      "...\n",
      "Epoch 10, Loss 0.017321\n",
      "    Params: tensor([-8.5587e+00,  1.1597e+00,  5.1583e-17,  8.8300e+00, -1.4896e-09,\n",
      "         1.6942e-02,  2.7048e-03,  0.0000e+00,  8.9995e+01,  2.8736e-03],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-1.2138e-01, -1.2563e-01, -4.7197e-16,  1.3763e-08,  1.3597e-08,\n",
      "        -1.5316e-01, -2.4921e-02,  0.0000e+00,  4.8525e-02, -2.5977e-02],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Epoch 11, Loss 0.016751\n",
      "    Params: tensor([-8.5575e+00,  1.1610e+00,  5.6212e-17,  8.8300e+00, -1.6229e-09,\n",
      "         1.8440e-02,  2.9496e-03,  0.0000e+00,  8.9994e+01,  3.1277e-03],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-1.1905e-01, -1.2324e-01, -4.6294e-16,  1.3493e-08,  1.3330e-08,\n",
      "        -1.4981e-01, -2.4483e-02,  0.0000e+00,  4.7571e-02, -2.5409e-02],\n",
      "       grad_fn=<StackBackward0>)\n",
      "...\n",
      "Epoch 99, Loss 0.003378\n",
      "    Params: tensor([-8.5065e+00,  1.2143e+00,  2.5569e-16,  8.8300e+00, -7.2088e-09,\n",
      "         7.3568e-02,  1.4359e-02,  0.0000e+00,  8.9974e+01,  1.2478e-02],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-2.4928e-02, -2.6522e-02, -9.8305e-17,  2.5722e-09,  2.5671e-09,\n",
      "        -1.5718e-02, -6.6465e-03,  0.0000e+00,  9.0689e-03, -2.6660e-03],\n",
      "       grad_fn=<StackBackward0>)\n",
      "Epoch 100, Loss 0.003361\n",
      "    Params: tensor([-8.5062e+00,  1.2146e+00,  2.5666e-16,  8.8300e+00, -7.2340e-09,\n",
      "         7.3720e-02,  1.4424e-02,  0.0000e+00,  8.9974e+01,  1.2504e-02],\n",
      "       grad_fn=<SubBackward0>)\n",
      "    Grad:   tensor([-2.4552e-02, -2.6130e-02, -9.6837e-17,  2.5284e-09,  2.5242e-09,\n",
      "        -1.5193e-02, -6.5728e-03,  0.0000e+00,  8.9142e-03, -2.5769e-03],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-8.5062e+00,  1.2146e+00,  2.5666e-16,  8.8300e+00, -7.2340e-09,\n",
       "         7.3720e-02,  1.4424e-02,  0.0000e+00,  8.9974e+01,  1.2504e-02],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 100, \n",
    "    learning_rate = 1e-2, \n",
    "    params = torch.tensor([-8.572, 1.146, 0.0, 8.830, 0.0, 0.0, 0.0, 0.0, 90.0, 0.0]), \n",
    "    x = x, \n",
    "    y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.023659\n",
      "Epoch 2, Loss 0.022834\n",
      "Epoch 3, Loss 0.022041\n",
      "...\n",
      "Epoch 10, Loss 0.017321\n",
      "Epoch 11, Loss 0.016751\n",
      "...\n",
      "Epoch 99, Loss 0.003378\n",
      "Epoch 100, Loss 0.003361\n",
      "...\n",
      "Epoch 4000, Loss 0.001944\n",
      "Epoch 5000, Loss 0.001944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-8.4307e+00,  1.2911e+00,  5.4793e-16,  8.8300e+00, -1.5164e-08,\n",
       "        -1.0930e-02,  3.9535e-02,  0.0000e+00,  8.9962e+01, -1.8539e-03],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = training_loop(\n",
    "    n_epochs = 5000, \n",
    "    learning_rate = 1e-2, \n",
    "    params = torch.tensor([-8.572, 1.146, 0.0, 8.830, 0.0, 0.0, 0.0, 0.0, 90.0, 0.0]), \n",
    "    x = x, \n",
    "    y = y,\n",
    "    print_params = False)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 各データセットのプロット\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mx_data_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mnumpy(), y_data_1\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData 1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_data_2\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), y_data_2\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_data_3\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), y_data_3\u001b[38;5;241m.\u001b[39mnumpy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData 3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'detach'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3840x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(dpi=600)\n",
    "\n",
    "# 各データセットのプロット\n",
    "plt.plot(x_data_1.detach().numpy(), y_data_1.numpy(), 'o', label='Data 1')\n",
    "plt.plot(x_data_2.detach().numpy(), y_data_2.numpy(), 'x', label='Data 2')\n",
    "plt.plot(x_data_3.detach().numpy(), y_data_3.numpy(), 's', label='Data 3')\n",
    "plt.plot(x_data_4.detach().numpy(), y_data_4.numpy(), 'h', label='Data 4')\n",
    "plt.plot(x_data_5.detach().numpy(), y_data_5.numpy(), 'd', label='Data 5')\n",
    "plt.plot(x_data_6.detach().numpy(), y_data_6.numpy(), 'p', label='Data 6')\n",
    "\n",
    "# フィッティング結果のプロット\n",
    "x_all = np.linspace(min(x_data_combined), max(x_data_combined), 100)\n",
    "for label in [1, 2, 3, 4, 5, 6]:\n",
    "    y_p = [model(x, *params, label) for x in x_all]\n",
    "    plt.plot(x_all.detach().numpy(), y_p.detach().numpy(), label=f'Fit Label {label}')\n",
    "\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Knight shift')\n",
    "plt.title('Fitting Results')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
