{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9026161d",
   "metadata": {},
   "source": [
    "### This NoteBook provides some Notes about Classification for Custom DataSet using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556af90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7e2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "## config (デバイスの設定)\n",
    "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09952371",
   "metadata": {},
   "source": [
    "### Read and prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b0fe7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>Knight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.387291</td>\n",
       "      <td>-1.353185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500177</td>\n",
       "      <td>-8.408062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.479996</td>\n",
       "      <td>-1.029240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.740224</td>\n",
       "      <td>-8.442742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.313055</td>\n",
       "      <td>-0.818826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x    Knight\n",
       "0  0.387291 -1.353185\n",
       "1  0.500177 -8.408062\n",
       "2  1.479996 -1.029240\n",
       "3  2.740224 -8.442742\n",
       "4  3.313055 -0.818826"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the data \n",
    "file_path = os.path.join(os.getcwd(), 'x', 'Knight', 'xy.csv')\n",
    "\n",
    "# ()はファイルのパス\n",
    "df_train = pd.read_csv(r'./xy.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c56197aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## split the data (特徴量とラベルにデータを分割し、さらにトレーニングデータと検証データに分ける)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m X_train, X_valid, y_train, y_valid \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[1;32m      6\u001b[0m                                                       shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert Class String labels into Integers\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ラベルのエンコードとデータの標準化\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'y'"
     ]
    }
   ],
   "source": [
    "## split the data (特徴量とラベルにデータを分割し、さらにトレーニングデータと検証データに分ける)\n",
    "X = df_train.iloc[:, 1:-1]\n",
    "y = df_train['y']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
    "                                                      shuffle=True, random_state=42)\n",
    "\n",
    "# Convert Class String labels into Integers\n",
    "# ラベルのエンコードとデータの標準化\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_valid_encoded = encoder.transform(y_valid)\n",
    "\n",
    "## reshape them（）\n",
    "y_train_encoded = y_train_encoded.reshape(-1, 1)\n",
    "y_valid_encoded = y_valid_encoded.reshape(-1, 1)\n",
    "\n",
    "# Normalize the input features of the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "## convert to float32 then to tensors（テンソルへの変換）\n",
    "X_train_scaled = torch.from_numpy(X_train_scaled.astype(np.float32))\n",
    "X_valid_scaled = torch.from_numpy(X_valid_scaled.astype(np.float32))\n",
    "y_train_encoded = torch.from_numpy(y_train_encoded.astype(np.float32))\n",
    "y_valid_encoded = torch.from_numpy(y_valid_encoded.astype(np.float32))\n",
    "\n",
    "##  for target  --> this is a MUST\n",
    "y_train_encoded = y_train_encoded.type(torch.LongTensor)\n",
    "y_valid_encoded = y_valid_encoded.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you do not do that you will catch an error\n",
    "y_train_encoded = torch.squeeze(y_train_encoded)\n",
    "y_valid_encoded = torch.squeeze(y_valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ba6fa",
   "metadata": {},
   "source": [
    "#### Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad4fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started __________________________________ \n",
      "\n",
      "Training finished ____________________________________ \n",
      "\n",
      "Training Accuracy is --> 91.496 %\n"
     ]
    }
   ],
   "source": [
    "## Create a class for Logistic Regression（ロジスティック回帰モデルの定義）\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_features, 7) ## --> 1 output class\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)  ## no Softmax for multiclass --< CrossEtropy handles this\n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "\n",
    "## intance \n",
    "log_reg = LogisticRegression(input_features=X_train_scaled.shape[1])\n",
    "\n",
    "\n",
    "## Training\n",
    "print('Training started __________________________________ \\n')\n",
    "\n",
    "## criteria\n",
    "learning_rate = 0.01\n",
    "n_epochs = 10000\n",
    "\n",
    "loss = nn.CrossEntropyLoss()   \n",
    "optimizer = torch.optim.SGD(log_reg.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ## predicting\n",
    "    y_pred_train = log_reg(X_train_scaled)\n",
    "    ## loss\n",
    "    l = loss(y_pred_train, y_train_encoded)\n",
    "    ## backpropagation\n",
    "    l.backward()\n",
    "    ## optimizaion step\n",
    "    optimizer.step()\n",
    "    ## empty the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "\n",
    "print('Training finished ____________________________________ \\n') \n",
    "\n",
    "_, y_pred_train_cls = torch.max(y_pred_train, dim=1)\n",
    "train_acc = (y_pred_train_cls==y_train_encoded).sum()/y_train_encoded.shape[0]\n",
    "print(f'Training Accuracy is --> {train_acc*100:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4cb56",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd73d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy is --> 92.432 %\n"
     ]
    }
   ],
   "source": [
    "## when you evaluate you must stop gradients to not kick the requires_grad=True\n",
    "with torch.no_grad():\n",
    "    y_pred_valid = log_reg(X_valid_scaled)\n",
    "    \n",
    "    _, y_pred_valid_cls = torch.max(y_pred_valid, dim=1)\n",
    "    valid_acc = (y_pred_valid_cls==y_valid_encoded).sum()/y_valid_encoded.shape[0]\n",
    "    \n",
    "    print(f'Validation Accuracy is --> {valid_acc*100:.3f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc73e89",
   "metadata": {},
   "source": [
    "### Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
